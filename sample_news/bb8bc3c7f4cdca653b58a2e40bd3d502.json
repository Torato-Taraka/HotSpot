{"Type": "article", "Time": "2020-10-08", "Headline": "Misinformation Watch", "Text": "We created Misinformation Watch to provide CNN readers a destination for misinformation-related U.S. election coverage. With the election process having come to a close, this is our last post on Misinformation Watch. It is far from the end of our coverage of misinformation, though.  In the few short months of this project’s operation, a conspiracy theory took root within misinformation communities that had long thrived online. Former U.S. President Donald Trump did not lose the election, the theory falsely posited — it was stolen. The theory moved through well trod channels of misinformation -- QAnon groups, conspiratorial hashtags, fringe YouTube personalities, the former President’s social media accounts -- growing more complex as it spread. Eventually, the theory was so varied and multi-pronged that it was all but impossible to disprove to those who subscribed to it. It spilled out into the physical world and, eventually, its adherents spilled blood. We watched, in real time, both the birth and the ultimate destructive power of that false reality. It was the perfect storm of misinformation, and it was another warning. Misinformation is not simply the result of conspiratorial internet posters or grifters sowing fear to make a buck. Though it thrives under tech giants’ uneven content moderation policies, it will not be stamped out solely by more robust self-policing by these platforms. Misinformation’s impact has as much to do with the ways in which we are served online content as the content itself. It is a consequence of how social media and internet companies are built and how they profit. A company that can both collect an unfathomable amount of information about a person – where they live, who they love, if they are happy, if they have a job, what secret questions they ask, if they might be interested in buying a bulletproof vest – is able to target content and advertisements at them precisely. When that company’s ultimate goal is simply to keep that person scrolling, to keep them returning to the platform, then the alternative realities we have seen emerge are inevitable. In the wake of the Capitol insurrection, panicked tech titans took broad action against purveyors of lies and conspiracy, ousting tens of thousands of accounts, including ones belonging to then-President Donald Trump. It was a moment of real change. Misinformation and conspiracy communities that were pushed out of mainstream homes like Facebook and Twitter found safe haven on Parler, which was, in turn, pushed off its web hosting service. “Stop the Steal” conspiracy theorists, QAnon believers, and other fringe communities scattered and splintered as they sought new homes online. The impact of this exodus for the internet and the rest of the US is yet to be known.  While this project has come to an end, we’ll continue to cover both the origins and impact of misinformation. It is a topic of vital importance and we’re committed to covering it. Thanks for reading, and please keep coming back for more of our coverage of the issue — we’ve got a lot more in mind.   The moment of reckoning promised by the QAnon conspiracy theory never came. Now, many believers feel confused, duped, and uncertain of what comes next. For years, believers of the QAnon conspiracy theory had been waiting for the moment when a grand plan would be put into action and secret members of a supposed Satanic pedophilia ring at the highest ranks of government and Hollywood would suddenly be exposed, rounded up and possibly even publicly executed. They were nearly always sure it was right around the corner, but \"The Storm\" never came — and the moment of Joe Biden's inauguration was the last possible opportunity for President Donald Trump to put the plan in motion. But as Biden raised his hand and swore an oath to defend the Constitution, becoming the nation's 46th president — nothing happened. The anti-climax sent QAnon adherents into a frenzy of confusion and disbelief, almost instantly shattering a collective delusion that had been nurtured and amplified by many on the far right. Now, in addition to being scattered to various smaller websites after Facebook (FB) and Twitter (TWTR) cracked down on QAnon-related content, believers risked having their own topsy-turvy world turned upside down, or perhaps right-side up. Members of a QAnon-focused Telegram channel, and some users of the image board 4chan, vowed to keep the faith. Others proclaimed they were renouncing their beliefs. Still others devised new theories that purported to push the ultimate showdown further into the future. One of the ideology's most visible icons, Ron Watkins — who goes by the online moniker CodeMonkeyZ — told supporters to \"go back to our lives.\" Read more here Facebook said Tuesday that since August it has removed about 18,300 Facebook profiles and 27,300 accounts on Facebook-owned Instagram for violating its policies against QAnon. The company has also removed 10,500 groups and 510 events for the same reason. In a blog post, updated on the eve of the inauguration, the company said it had taken action on tens of thousands of “militarized social movements” and self-described militias since last summer. “As of January 12, 2021, we have identified over 890 militarized social movements to date,\" the company said. Facebook has come under scrutiny for the role its platform played in the lead-up to the deadly insurrection at the Capitol earlier this month. Groups and individuals spreading lies about the 2020 election and calling to protest the outcome continued to hide in plain sight on Facebook even after the Capitol riots.  Facebook announced it would crack down on QAnon last summer. The baseless conspiracy theory has been circulating since 2017. People identifying as part of QAnon were part of the mob of Trump supporters who stormed the Capitol.  Last week, Twitter announced it had suspended more than 70,000 accounts for promoting QAnon. Despite crackdowns, the conspiracy theory continues to spread on Twitter, Facebook and fringe social platforms, according to new research from nonpartisan nonprofit Advance Democracy.  Over the holiday weekend, more than 1,280 accounts related to QAnon posted on Twitter about 67,000 times, peddling conspiracy theories about the election and President-Elect Joe Biden, according to the research.  For example, one QAnon account shared a 45-second video rife with false claims about election fraud. The video racked up about 360,000 views. After CNN Business flagged the video, Twitter took down the account for violating its rules against ban evasion. ##Facebook## ##Twitter## Less than 24 hours before Joe Biden is set to become president, Facebook continues to show ads for tactical gear despite vowing to ban those promotions ahead of the inauguration. A review by CNN and other internet users this week showed that ads for body armor, holsters and other equipment were being displayed on the platform as late as Tuesday afternoon.  Often, the advertised products are pictured alongside guns, ammunition, or people clad in camouflage fatigues.  The ads have frequently appeared in the timelines of military veterans and contribute to a false narrative of an imminent violent conflict in the United States, according to Kristofer Goldsmith, founder and president of High Ground Veterans Advocacy.  “They’re selling the idea of pending violence, or inevitable violence, and that’s the kind of thing that becomes a self-fulfilling prophecy,” said Goldsmith.  In one example still on Facebook Tuesday afternoon, a pair of noise-reducing earbuds was being advertised as a form of active hearing protection, shown inserted in the ears of a gunman aiming down his rifle sights.  Another ad, for body armor, promises consumers that the product can shield them from bullets, knives, stun guns and other threats.  A third series of ads, for hard-knuckled gloves, showed a man wearing desert camouflage and a tactical rig performing various tests on the gloves, including punching concrete walls, breaking a glass bottle by hand and rubbing broken glass on the gloves’ palms. “They put people in combat gear in a civilian setting,” Goldsmith said of the ads. \"They’re promoting this image of, ‘You need to get ready for combat.’” Asked for comment, Facebook referred CNN to its earlier blog post announcing that it will ban “ads that promote weapon accessories and protective equipment” in the United States through at least Jan. 22.  \"We already prohibit ads for weapons, ammunition and weapon enhancements like silencers,\" Facebook said in the blog post. \"But we will now also prohibit ads for accessories such as gun safes, vests and gun holsters in the US.\" After Facebook introduced the ban on Saturday, BuzzFeed News reported the following day that some ads for tactical gear were still active. Many of the ads observed by CNN had been active, in some cases, for months. Others had been launched within the past week. Facebook appears to have removed some of the advertisements CNN found, including a series of ads for armored plates and plate carriers. The plates had, in some cases, been shown being held by heavily muscular individuals dressed in fatigues or being inserted into camouflage-patterned backpacks. Despite having seemingly removed some of the advertisers' ads, Facebook has allowed other ads for the same products, by the same advertisers, to persist on the platform. Another now-removed series of body armor ads included marketing copy that claimed specific levels of protection under the rubric established by the National Institute of Justice.  Veterans are a popular target for misinformation and conspiracy theorists, Goldsmith said, because as a group they enjoy political and social authority. An endorsement by a veteran can reinforce a conspiracy theory's apparent credibility. “If you change the mind of a veteran, there’s a good chance you change the minds of those within that veteran’s immediate circle — friends, family, coworkers,” said Goldsmith.  ##Facebook## Groups and individuals spreading lies about the 2020 election and calling to protest the outcome have continued to hide in plain sight on Facebook, even as COO Sheryl Sandberg this week tried to downplay the platform's role in the Capitol riots.  From altering the names of their online forums to abusing the core features of Facebook's own services, conspiracy theorists have worked to evade content moderators despite the company's vows of a crackdown, new research shows.  These groups' efforts to remain undetected highlight the sophisticated threat confronting Facebook, despite its insistence the situation has been less of a problem compared to on other platforms. It also raises new concerns that the groups' persistence on these mainstream social networks could spark a new cycle of violence that stretches well into Joe Biden's presidency.  The latest examples surfaced on Thursday, as extremism experts at the activist group Avaaz identified 90 public and private Facebook groups that have continued to circulate baseless myths about the election, with 166,000 total members.  Of those, a half-dozen groups appeared to have successfully evaded Facebook's restrictions on \"stop the steal\" content, according to Avaaz. Though many initially had \"stop the steal\" in their names, the groups have since altered their profiles, according to page histories reviewed by CNN Business — allowing them to blend in with other Facebook activity.  \"So instead of 'Stop the Steal,' they became 'Stop the Fraud' or 'Stop the Rigged Election' or 'Own the Vote,'\" said Fadi Quran, campaign director at Avaaz. Read more here. ##Election## ##Facebook## YouTube is working with top health organizations to create authoritative medical videos for the platform in an effort to crackdown on Covid-19 misinformation. The new health partnership team will be headed by Dr. Garth Graham, YouTube’s new director and global head of healthcare and public health partnerships. Graham was most recently the chief community health officer at CVS Health. YouTube will work with organizations including the American Public Health Association, Cleveland Clinic and the Forum at the Harvard School of Public Health to make “high-quality health content” for its users, according to a blog post.  Like other tech platforms, YouTube has had to tackle the spread of misinformation about Covid-19. In October, the Google-owned platform said it would take down videos that include misinformation about Covid-19 vaccines. It previously took action on other content containing falsehoods about the virus, such as videos disputing Covid-19 exists. At the time, the company said it had removed more than 200,000 videos containing dangerous or misleading information about Covid-19 since February 2020. The messaging app Zello said it has removed more than 2,000 channels on its platform related to armed extremism, and banned all “militia-related channels,” after it found evidence that some of its users participated in the Capitol riots.  Zello, a voice messaging app that provides a walkie-talkie-like function, condemned the violence in a blog post on Wednesday. “It is with deep sadness and anger that we have discovered evidence of Zello being misused by some individuals while storming the United States Capitol building last week,” the company said. “Looking ahead, we are concerned that Zello could be misused by groups who have threatened to organize additional potentially violent protests and disrupt the U.S. Presidential Inauguration Festivities on January 20th.” Zello added that “a large proportion” of the channels it removed on Wednesday had been dormant for months and in some cases years. The company is further analyzing the groups on its platform to determine whether any may violate its terms of service. But it added that because it does not store message content, the task is not as simple as running searches for keywords or hashtags and blocking them. The messaging app Telegram is battling an increase in violent extremism on its platform amid a surge in new users, the company acknowledged to CNN Wednesday.  In the last 24 hours, the company has shut down \"dozens\" of public forums that it said in a statement had posted \"calls to violence for thousands of subscribers.\" But the effort has turned into a game of cat and mouse, as many of the forum's users set up copycats just as soon as their old haunts were disabled. Screenshots and Telegram groups monitored by CNN show that a number of channels containing white supremacy, hate and other extremism have been shut down, but that at least some have been replaced by new channels. And at least one meta-channel has emerged that maintains lists of deactivated groups and that redirects visitors to the replacements. One now-defunct group that CNN reviewed had more than 10,000 members. \"Our moderators are reviewing an increased number of reports related to public posts with calls to violence, which are expressly forbidden by our Terms of Service,\" Telegram spokesperson Remi Vaughn told CNN. \"In the past 24 hours we have blocked dozens of public channels that posted calls to violence for thousands of subscribers.\"  Vaughn added: \"Telegram uses a consistent approach to protests and political debate across the globe, from Iran and Belarus to Thailand and Hong Kong. We welcome peaceful discussion and peaceful protests, but routinely remove publicly available content that contains direct calls to violence.\"  Telegram has surpassed half a billion active users worldwide. The company announced Tuesday that it had grown by 25 million users over the past several days -- with about 3 percent of that growth, or 750,000 new signups, occurring in the United States alone, Telegram told CNN. Apps such as Telegram, Signal and MeWe have experienced explosive growth in recent days after WhatsApp sent a notification to its users reminding them that it shares user data with its parent, Facebook -- and following the suspension of President Donald Trump and the alternative social network Parler from many major tech platforms.  One of the people who has been reporting violent channels to Telegram is Gwen Snyder, a Philadelphia-based activist who said she has been monitoring far-right extremists on the platform since 2019. Earlier this week, as Telegram was witnessing a surge in new users, Snyder enacted a plan to organize mass pressure against Telegram’s content moderators. “We started two days ago calling for Apple and Google to deplatform Telegram if they refused to enforce their terms of service,” Snyder told CNN. “We had dozens if not hundreds of relatively large-follower Twitter accounts amplifying the campaign.” It’s difficult to determine whether Telegram’s actions may have been a direct result of the activism; Snyder said she never heard from Telegram or from Apple or Google, either.  But at least some of the Telegram channels affected by the crackdown appeared to believe that Snyder’s efforts were responsible — and soon began posting her personal information online and targeting her with death threats. “That’s my home address,” Snyder said in a public tweet, attaching a redacted screenshot of an extremist Telegram channel that had shared her information. Addressing Telegram, she added: “You're okay with this? ENFORCE YOUR OWN TERMS OF SERVICE.” Facebook has seen online signals, on its platform and elsewhere, indicating the potential for more violence following last week’s insurrection, a company spokesperson told CNN Wednesday.  The company is working with organizations that track terrorists and dangerous groups to monitor conversation on other platforms, like 8Kun (formerly 8chan) and 4chan, in an effort to prevent talk of violence from those platforms becoming popular on Facebook, the spokesperson said. One example of work Facebook is doing on this, according to the spokesperson, is collecting and indexing promotional fliers being distributed on other sites for more demonstrations this weekend and on Inauguration Day. Indexing promotional material like this can help make it easier for Facebook to identify and remove that material from its platforms or prevent it from being posted in the first place. The spokesperson said Facebook is monitoring and removing praise of or support for last week’s storming of the US Capitol from its platform.  Facebook has passed on information to the FBI and is cooperating with the agency’s efforts to identify members of last week’s insurrection, the spokesperson said.  Google will temporarily ban all political advertising on multiple platforms after formally designating the Capitol riots, the impeachment process and the inauguration as \"sensitive events\" under its policies, the company said Wednesday. The pause will last from Jan. 14 until at least the day after the inauguration next week, the company said in a letter to marketers, which was obtained by CNN Business. Google said in the letter that it will restrict advertising \"referencing candidates, the election, its outcome, the upcoming presidential inauguration, the ongoing presidential impeachment process, violence at the US Capitol, or future planned protests on these topics.\" \"There will not be any carveouts in this policy for news or merchandise advertisers,\" Google continued in the letter. Ads will be banned from Google as well as YouTube, according to the letter. In a statement to CNN Business, a Google spokesperson said the ban is driven by last week's Capitol violence. \"Given the events of the past week, we will expand our Sensitive Event policy enforcement to temporarily pause all political ads in addition to any ads referencing impeachment, the inauguration, or protests at the US Capitol,\" Google said in the statement. \"We regularly pause ads over unpredictable, 'sensitive' events when ads can be used to exploit the event or amplify misleading information. Beyond this, we have long-standing policies blocking content that incites violence or promotes hate and we will be extremely vigilant about enforcing on any ads that cross this line.” Google imposed a similar \"sensitive events\" ad blackout surrounding Election Day and for several weeks after. The company lifted its election-related moratorium on political advertising on Dec. 10, indicating in a letter to advertisers obtained by CNN Business that \"we no longer consider the post-election period to be a sensitive event.\" But the events of the past several weeks, culminating in last week's riots, suggest that determination may have been premature. ##Election## A video that shows an agitated man in an airport terminal, complaining that he had been kicked off a plane and insulted, has now been viewed more than 20 million times on Twitter. Why has the 18-second video gone so viral? In part because someone on Twitter -- not the person who actually recorded the video -- added a caption that suggested that the man had been put on a no-fly list for being part of the insurrection at the US Capitol. \"People who broke into the Capitol Wednesday are now learning they are on No-Fly lists pending the full investigation. They are not happy about this,\" the tweeter, who goes by the handle @RayRedacted, said in the caption.  Facts First: The Twitter caption was inaccurate: The airport incident was not about the Capitol insurrection. Rather, the man in the video had been asked to get off a Charlotte-to-Denver flight for refusing to comply with American Airlines' mandatory mask policy, airline spokesman Curtis Blessing told CNN. Read more here. ##Twitter## YouTube is suspending President Donald Trump's channel for at least one week, and potentially longer, after his channel earned a strike under the platform's policies, the company said Tuesday evening. A recent video on Trump's channel had incited violence, YouTube told CNN Business. That video has now been removed. YouTube declined to share details of the video that earned Trump the strike, but said that after the one-week timeout, it will revisit the decision. YouTube also removed content from the White House's channel for violating policy, the company told CNN Business, but the channel itself has not been suspended or been given a strike -- just a warning. Until now, YouTube had been the only remaining major social media platform not to have suspended Trump in some fashion. Facebook has suspended Trump's account \"indefinitely,\" while Twitter has banned Trump completely. Read more here. ##Trump## A viral tweet claims that impeaching President Donald Trump for a second time would mean he would lose the ability to run for president in 2024. That's not true. Nor are other claims in the tweet. The tweet was posted on Friday, two days after a Capitol insurrection by a mob of Trump supporters sparked a new impeachment push from House Democrats. As of early Monday, it had more than 181,000 retweets and 725,000 likes. When we called Ben Costiloe, the person behind the tweet, to tell him that we were planning a fact check and that much of the tweet was inaccurate, he said good-naturedly: \"Tear it a new one. Go for it, baby.\" He said he is \"nobody,\" a man who lives with diabetes in Texas and did the tweet because he had seen the information pop up somewhere on his Facebook feed and \"it made me feel good.\"  He said he was never sure the content was correct and was amazed the tweet went so viral. He said he had only 200 Twitter followers at the time he posted it.  \"I don't want to mess up the world. I just wanted to make me feel good,\" he said. \"It turns out it made a lot of people feel good.\" Read more here. ##Election## ##Twitter## Since Friday, Twitter has suspended more than 70,000 accounts from its platform for promoting the baseless QAnon conspiracy theory, the company said in a blog post Monday evening.  The social media platform has been on an enforcement spree in recent days as it has removed major QAnon adherents including Michael Flynn and Sidney Powell. Many of the banned account-holders operated multiple accounts, Twitter said. The moves have contributed to major fluctuations in some users’ Twitter accounts, the company acknowledged.  “In some cases, these actions may have resulted in follower count changes in the thousands,” Twitter said.  The company’s blog post also goes over other steps the company has taken in recent days to limit the spread of violent rhetoric on its platform, including making it impossible for any tweets “labeled for violations of our civic integrity policy to be replied to, Liked or Retweeted.”  Parler, the alternative social media platform popular with conservatives, has been banned from the Google Play Store, Google told CNN Business Friday evening.  Google said its app store has long required that apps displaying user generated content have moderation policies in place to prevent the spread of violent rhetoric.  \"We're aware of continued posting in the Parler app that seeks to incite ongoing violence in the US,\" a Google spokesperson said. \"We recognize that there can be reasonable debate about content policies and that it can be difficult for apps to immediately remove all violative content, but for us to distribute an app through Google Play, we do require that apps implement robust moderation for egregious content. In light of this ongoing and urgent public safety threat, we are suspending the app's listings from the Play Store until it addresses these issues.\"  The decision marks a major blow to President Donald Trump's supporters, many of whom have found a home on the Parler platform. But it does not completely deny them access to the app. Because Android allows for third-party app stores, Parler can still be hosted on app stores not operated by Google.  Google's decision follows a report by BuzzFeed News that Apple has threatened to remove Parler from the iOS App Store. (Apple declined to comment on the report.) Parler is among a group of relatively new platforms that have billed themselves as free speech alternatives in hopes of courting conservatives who believe larger platforms are censoring their views.  Read more here. ##Parler## YouTube has banned Steve Bannon's \"War Room\" podcast channel after earning three strikes on the platform in the last 90 days, the company told CNN. Bannon's first strike came in November after he called for putting Dr. Anthony Fauci's head \"on a pike.\"  Two other videos were removed on Friday afternoon for violating YouTube's policies against questioning the 2020 election outcome, YouTube said, resulting in two additional strikes. Under YouTube's policy, a channel may be permanently banned after three strikes. \"In accordance with our strikes system, we have terminated Steve Bannon’s channel 'War room' and one associated channel for repeatedly violating our Community Guidelines,\" a YouTube spokesperson said.  \"As we said yesterday, any channel posting new videos with misleading content that alleges widespread fraud or errors changed the outcome of the 2020 U.S. Presidential election in violation of our policies will receive a strike, a penalty which temporarily restricts uploading or live-streaming.\" Twitter has suspended President Donald Trump from its platform, the company said Friday evening. \"After close review of recent Tweets from the @realDonaldTrump account and the context around them we have permanently suspended the account due to the risk of further incitement of violence,\" Twitter said. \"In the context of horrific events this week, we made it clear on Wednesday that additional violations of the Twitter Rules would potentially result in this very course of action.\" Twitter's decision followed two tweets by Trump Friday afternoon that would end up being his last. The tweets violated the company's policy against glorification of violence, Twitter said, and \"these two Tweets must be read in the context of broader events in the country and the ways in which the President's statements can be mobilized by different audiences, including to incite violence, as well as in the context of the pattern of behavior from this account in recent weeks.\" The first tweet was about Trump's supporters. \"The 75,000,000 great American Patriots who voted for me, AMERICA FIRST, and MAKE AMERICA GREAT AGAIN, will have a GIANT VOICE long into the future. They will not be disrespected or treated unfairly in any way, shape or form!!!\" The second indicated Trump did not plan to attend Joe Biden's inauguration. Read more here ##Twitter## Twitter said Friday it has banned Michael Flynn, Sidney Powell and the administrator of 8kun, the online forum that has incubated QAnon claims, as part of a crackdown of accounts that have spread the baseless QAnon conspiracy theory. Twitter said it launched the crackdown, which affects thousands of accounts, under its policy against coordinated harmful activity, amid concerns that QAnon supporters could seek to incite violence. \"We've been clear that we will take strong enforcement action on behavior that has the potential to lead to offline harm,\" Twitter said in a statement, \"and given the renewed potential for violence surrounding this type of behavior in the coming days, we will permanently suspend accounts that are solely dedicated to sharing QAnon content.\" NBC News was first to report the sweep. The move caps off a tumultuous week in which Twitter, in response to Wednesday's Capitol riots, imposed a temporary lock on President Donald Trump's accounts. Trump is currently able to tweet again but Twitter warned that future violations its rules \"will result\" in Trump being booted off the platform. The crackdown on Friday affects some of Trump's most loyal allies, whom Twitter said it was removing for sharing QAnon claims. Flynn served as Trump’s national security adviser before he was convicted of lying to the FBI and then pardoned by the President. Powell is a lawyer who helped the Trump campaign spread baseless theories of election fraud. ##Twitter## President Donald Trump's tweeting privileges have now been restored following Twitter's temporary lock on his account this week for inciting what became a violent insurrection at the US Capitol. In his first tweet since being let out of the penalty box, Trump shared a video conceding that he will be a one-term president.  But for Twitter, the challenge of what to do about Trump's account may only be getting more difficult, not less. As Trump reemerges, the company now faces a test of its commitment that any further violations of its policies by the President will result in a permanent ban. Even one more transgression could land Trump in Twitter jail — forever.  It's a game of chicken that Trump, whose entire presidency has been devoted to breaking rules and testing boundaries, is sure to play.  For the last four years, Twitter has been central to Trump's presidency, a fact that has also benefited the company in the form of countless hours of user engagement. Twitter took a light-touch approach to moderating his account, often arguing that as a public official, Trump must be given wide latitude to speak. But as Trump nears the end of his term — and as public pressure has grown against the platform — the balance may be shifting. Last spring, the company began applying warning labels to Trump's tweets in an attempt to correct his misleading claims ahead of the election; it arguably had the opposite effect, prompting Trump to retaliate with an executive order and ever more baseless claims of election fraud.  With those claims having reached their zenith by spurring a full-blown riot, Wednesday saw the most aggressive moves yet by Twitter and other companies to rein Trump in. For the first time in four years, it seems, Trump will need to appease Twitter more than Twitter needs to appease him. Read more here. ##Trump## ##Twitter## Twitch said Thursday it has disabled President Donald Trump's channel on the gaming service, making it the latest tech platform to crack down on the president's accounts after his supporters stormed the US Capitol building. “In light of yesterday’s shocking attack on the Capitol, we have disabled President Trump’s Twitch channel,\" the company said in a statement. \"Given the current extraordinary circumstances and the President's incendiary rhetoric, we believe this is a necessary step to protect our community and prevent Twitch from being used to incite further violence.\" The move from the Amazon-owned gaming service comes as other platforms escalate their restrictions on the president's accounts.  On Thursday, Facebook banned Trump's account from posting on the platform for at least the duration of his term in office, and possibly \"indefinitely.\" A day earlier, Twitter locked Trump’s account temporarily, and warned for the first time that it could suspend him permanently. Trump has a significantly smaller audience on Twitch than he does on Twitter and Facebook.  ##Election## ##Trump## E-commerce platform Shopify said on Thursday that it had shut down stores on its website affiliated with President Trump, including shops run by the Trump campaign and the Trump Organization. A Shopify spokesperson said in an email that “based on recent events,” Trump's \"actions\" violated the company’s policy prohibiting the promotion or support of \"organizations, platforms or people that threaten or condone violence to further a cause.”  Visitors to Trumpstore.com and shop.donaldjtrump.com Thursday were met with a message that said the shops were unavailable. Shopify did not say how many sites tied to Trump it had shut down in total. Major social media platforms have taken their harshest steps to date to restrict the president's use of their sites after a mob of pro-Trump supporters overran the Capitol building Wednesday.  Twitter and Facebook locked Trump's accounts on their platforms Wednesday, and Facebook chief executive Mark Zuckerberg said on Thursday that the ban on Trump posting to his account would last for at least two weeks, through the inauguration of President-elect Joe Biden. ##Twitter## ##Facebook## ##Trump## YouTube announced Thursday that it is accelerating its timeline for penalizing channels that promote false claims of voter fraud surrounding the 2020 election, a move that could lead to President Donald Trump’s permanent suspension from the platform if he continues to spread baseless claims that the election was stolen.  Last month, YouTube said it would begin removing content that made false claims of election fraud, but that it would not begin assigning strikes to channels under its three-strike rule until after Inauguration Day. This “grace period” is standard policy, YouTube told CNN.  Now, however, the video platform will begin imposing strikes right away instead of waiting until after Jan. 20, shortening the grace period by two weeks. “Due to the disturbing events that transpired yesterday, and given that the election results have been certified, any channel posting new videos with these false claims in violation of our policies will now receive a strike, a penalty which temporarily restricts uploading or live-streaming,” said Alex Joseph, a YouTube spokesperson. “Channels that receive three strikes in the same 90-day period will be permanently removed from YouTube.” The decision in light of Wednesday’s violent Capitol riots follows moves by Twitter and Facebook to limit Trump’s account, and a decision by Facebook to ban Trump from its platform for at least the remainder of his term.  ##Election## ##YouTube## Facebook will ban President Donald Trump's account from posting for at least the remainder of his term in office and perhaps \"indefinitely,\" CEO Mark Zuckerberg said in a blog post on Thursday. \"We believe the risks of allowing the President to continue to use our service during this period are simply too great,\" Zuckerberg wrote in the post. \"Therefore, we are extending the block we have placed on his Facebook and Instagram accounts indefinitely and for at least the next two weeks until the peaceful transition of power is complete.\" The decision marks a major escalation by Facebook as it and other platforms have come under intense pressure from advocacy groups and prominent figures to ban Trump following his inflammatory rhetoric encouraging insurrection. Facebook and Twitter took the extraordinary step on Wednesday of temporarily locking President Donald Trump's account on their platforms after his supporters stormed the Capitol building to protest the election. If the latest restrictions hold, Facebook could be the first major platform to remove Trump permanently. Read more here. ##Election## ##Facebook## President Donald Trump has removed the three tweets from his profile that prompted a temporary lock of his account on Wednesday, a Twitter spokesperson told CNN Business. The move clears the way for Trump to regain control of his tweeting privileges as early as Thursday.  The official confirmation comes after Trump appeared to comply Wednesday evening with Twitter’s requirement that he delete the tweets or face a continued lock on his account.  Earlier on Wednesday, Twitter said Trump’s account would be placed in a temporary time out for policy violations, lasting for 12 hours from the moment he deleted the tweets. Twitter also threatened Trump with a permanent ban from the platform for further violations. No sitting president has ever been banned from Twitter. Asked what time Trump will be able to tweet again, Twitter declined to comment. Twitter and Facebook both took the extraordinary step on Wednesday of locking Trump's account on their platforms after his supporters stormed the Capitol building to protest the election. ##Election## ##Twitter## Donald Trump appears to have deleted three tweets that violated Twitter's policies, a move that means the President could be tweeting again by mid-morning Eastern time on Thursday, if not sooner. Twitter had announced Wednesday evening that it would lock Trump’s account for a period of 12 hours that would begin once he had deleted three tweets that violated the company’s policies. Twitter had hidden the tweets from view behind a public notice saying, “This tweet is no longer available.\" However, it had not actually deleted the tweets from Trump’s profile, Twitter told CNN. It is Twitter’s standard procedure to require that locked account owners voluntarily delete violative tweets as a condition of returning to normal service. When a locked account owner deletes violative tweets, Twitter said, the platform updates the attached notices to read: “This tweet is no longer available because it violated the Twitter Rules.” That is the notice that now sits in place of Trump’s violative tweets, indicating that Trump’s account has complied with Twitter’s requirement. Asked by CNN, Twitter declined to say when the Trump tweets were deleted or what time Trump will be allowed to tweet again. Twitter’s initial statement about the lock and the requirement that Trump delete his tweets was met with some initial confusion as the company’s announcement came after the tweets had already vanished from public view. Twitter’s clarification that it simply masked Trump’s tweets without formally removing them explains why it said Trump must delete the tweets in order to continue tweeting. ##Election## ##Twitter## Facebook said Wednesday evening it is “searching for and removing” content from its platform that praises or supports the Capitol riots, in an expanded statement following its decision to remove President Trump’s video addressed to supporters.  The social media giant also said it will remove calls for armed gatherings as well as incitement and encouragement of further protests and violence in Washington.  Company executives said in a blog post that the labels Facebook applies to false claims of election fraud will now state more clearly that Joe Biden won the election.  The blog post said: “The new text reads that the results are final and certified: ‘Joe Biden has been elected President with results that were certified by all 50 states. The US has laws, procedures, and established institutions to ensure the peaceful transfer of power after an election.’” While many Americans were stunned as they watched rioters descend on the Capitol and clash with police, there has been chatter for days on various social media platforms about the prospect of Wednesday's protests turning violent. Ahead of protests organized to contest the formal counting of electoral votes in Washington DC, calls for violence could be found in discussions on Twitter, TikTok, right-wing platform Parler and an online forum formed last year in support of Donald Trump, according to research from nonpartisan nonprofit Advance Democracy. On Wednesday afternoon, a pro-Trump mob stormed the Capitol, pushing through barriers set up around the building and tussling with officers in full riot gear. One woman was shot. Windows were broken. At least one Trump supporter was pictured standing at the Senate dais, while another breached House Speaker Nancy Pelosi's office. A Capitol police officer in the House chamber told lawmakers that they may need to duck under their chairs. Before the protest, several TikTok videos promoting violence racked up thousands of views, with one user advocating for protestors to take their \"mother-[expletive] guns\" to DC, according to Advance Democracy. One TikTok video containing violent rhetoric had nearly 280,000 views. On Twitter, there were more than 1,250 posts from accounts related to the QAnon conspiracy theory about Wednesday's protests containing terms of violence since January 1.  Read more here ##Election## ##Twitter## ##QAnon## Facebook has now removed President Donald Trump’s video from earlier this afternoon addressing his supporters in the wake of riots at the US Capitol, company spokesman Andy Stone told CNN Business.  In the video, Trump had urged Capitol rioters to “go home” but struck a sympathetic tone and reiterated his debunked claims of election fraud. \"This is an emergency situation and we are taking appropriate emergency measures, including removing President Trump's video,\" Guy Rosen, Facebook’s VP of integrity, said in a tweet. \"We removed it because on balance we believe it contributes to rather than diminishes the risk of ongoing violence.\" Facebook, Twitter and other tech platforms faced growing calls Wednesday afternoon to take action on President Donald Trump's social media accounts for his role in instigating riots at the Capitol. On Wednesday afternoon, Twitter moved to restrict engagement with tweets by President Donald Trump and others that have been labeled “due to a risk of violence.” The announcement comes after hours of silence from the president as violent rioters descended on the US Capitol, and amid mounting calls by the Anti-Defamation League and others for Trump’s Twitter account to be suspended outright.  Twitter did not directly address those calls, but said that the restrictions on sharing and engagement are part of its efforts to monitor the “ongoing situation in Washington.\" Likes and replies have been disabled on Trump’s tweet that claimed Vice President Mike Pence “didn’t have the courage to do what should have been done.” Retweets of the tweet have been restricted, prompting users to add a comment rather than simply amplifying Trump’s remarks. Those same restrictions were also applied to a video Trump shared of himself late Wednesday afternoon addressing the rioters. “In regard to the ongoing situation in Washington, D.C., we are working proactively to protect the health of the public conversation occurring on the service and will take action on any content that violates the Twitter Rules,” Twitter said.  Read more here. Election officials in Georgia are working overtime to debunk false claims by President Donald Trump and his allies that the Senate runoff results are untrustworthy. The most visible pushback has come from Gabriel Sterling, a Republican who is a top state official overseeing the ballot counting. On Wednesday, Sterling rejected Trump’s claim that officials “just happened to find 50,000 ballots late last night.” “No Mr. President, there weren’t ‘found’ ballots,” Sterling tweeted. “We have known the number of advanced votes since this weekend. We saw record Election Day turnout. As of Monday 970,000 absentees had been accepted. 31k more were added in yesterday’s totals. That leaves 60k that came in yesterday.” For Trump, baseless claims of “found” ballots — and the insinuation that they are unfairly responsible for giving Democrats an edge on Election Night — has been a persistent theme stretching back to the November presidential elections. But Trump’s logic depends on either a fundamental misunderstanding of how elections work, or a cynical exploitation of the ballot counting process to generate the false impression that something is being stolen from its rightful owner. The reality is this: There may be “leads” on Election Night and those “leads” may shift back and forth, but they are a result of how we count votes — but the ballots are already in or on their way in and there is already a winner and a loser, even if we don’t know who it is yet. Over the course of Tuesday evening, Trump tweeted and retweeted several complaints about the ballot counting in Georgia.  “Just happened to have found another 4000 ballots from Fulton County. Here we go!” Trump tweeted. He also shared a tweet by White House press secretary Kayleigh McEnany that falsely implied that “Democrat Chatham County” had halted its vote count for nefarious reasons, as if county officials were afraid to keep counting for fear of having to add Republican votes.  Sterling pushed back on those claims. “Chatham County didn’t just stop,” he tweeted. Instead, Sterling explained, what happened was that Chatham County ran out of ballots to count and were waiting for more to come in. “They completed the counting of everything they have in. That includes Election Day, Advanced, & all of the absentees they had in. The last left will be the absentee by mail that came in today.” By transparently explaining the process over the course of the evening, Sterling revealed the logical fallacy at the heart of Trump’s objections. “Found” ballots are not a thing, but it is the case that ballots come in and are counted in batches — which, if you are watching the returns live, can lead to big swings in which candidate appears to be “ahead.”  This is how what may appear to be a healthy Republican lead at 8 p.m. can transform into a Democratic victory closer to midnight. It is only when the vote count nears completion that the true result becomes clear.  Watching results come in can be a thrill. It’s democracy in action! But don’t let it fool you: The winners were decided the moment the polls closed. Nobody is ahead or behind, except in the drama as it unfolds in real time.  Case in point: Weeks after Joe Biden was projected as the winner of the presidential race, his margin of victory has continued to grow — by millions of votes. It was never a close outcome. ##Election## Facebook will restore its ban on political ads in Georgia following Tuesday’s runoff election, according to the social media company.  In a Monday update to a December blog post outlining its approach to the Georgia race, Facebook said the state will again be covered under the company’s ongoing nationwide moratorium on political ads.  “Following the Georgia runoff elections, Georgia will re-join the existing nationwide pause on social issue, elections and political ads,” Facebook product manager Sarah Schiff said in the blog post. The company released further details in a separate blog post update. “Any ads about the Georgia runoff elections will be paused and advertisers will no longer be able to create new ads about social issues, elections, or politics,” the update said. “In the interim, you can continue to post organically and run ads that are not about social issues, elections, or politics and that do not require a disclaimer.”  Facebook didn’t immediately respond to a request for comment. The company has come under heavy criticism for its political ads, which allow politicians to lie. Facebook CEO Mark Zuckerberg announced in September that the company would not accept new political ads in the final week of the 2020 campaign. Facebook later extended the ban beyond the election. After Facebook temporarily lifted its political ad restrictions for the runoffs, the platform witnessed a fresh wave of misinformation targeting Georgia voters, according to the activist watchdog group Avaaz. Roughly 100 ads by political candidates and super PACs containing debunked claims were allowed to run on Facebook in the final weeks of December, Avaaz said this week in its analysis of Facebook’s political ad library. Avaaz said Wednesday morning that Facebook has removed 18 of the 104 ads it flagged as problematic. ##Election## Dalton, Georgia — \"Mr. President, the problem you have with social media, they — people can say anything,\" Georgia Secretary of State Brad Raffensperger, a Republican, tried to explain to President Trump in a call last Saturday. In Trump's world, however, that isn't a bug — it's a feature. Throughout his presidency and during his failed re-election campaign, Trump trafficked in internet rumors, doctored videos, and helped propel fringe conspiracy theories into the national conversation. Now he's using the same tactics to try an overturn an American election. And, as his supporters outside the rally he held in Georgia Monday night made clear to me, those tactics are working, convincing people of blatant untruths about the presidential election and undermining American democracy in a real and potentially dangerous way. \"Biden is not the next president, Trump is the next president,\" one Georgia voter who was in line early for Trump's rally told me. Another said she had booked her trip to Washington DC for the inauguration to before the election and still planned on going because she still believed, wrongly, that Trump would be the one sworn in rather than Biden. Read more here ##Election## ##Election## A top Georgia election official debunked President Donald Trump's baseless voter fraud claims in a press conference Monday on the eve of the high-stakes runoff elections in the state. Gabriel Sterling, the voting systems implementation manager for the Georgia Secretary of State's office, stood next to a sign that said “Claim vs Fiction” and declared it was \"anti-disinformation Monday.\"  He refuted several conspiracy theories and baseless claims floated by Trump and others, including the false claim that ballots were shredded and that thousands of ballots were found in warehouses. \"This is all easily proven false, yet the president persists,\" Sterling said. \"And by doing so undermines Georgians' faith in the election system.\" Sterling also encouraged people in Georgia to vote in Tuesday's runoff elections, which will determine the balance of power in the United States Senate.  “If you care about the value and direction of the nation you want to see, it is your obligation to turn out and vote tomorrow,” Sterling said.  He added that he is telling those who believe their votes were stolen or that there was voter fraud, “If you believe in your heart of hearts that there was, the best thing for you to do is to turn out and vote and make it harder for them to steal,” he said. The press conference comes one day after CNN and The Washington Post obtained audio of a one-hour phone call in which Trump pushed Georgia Secretary of State Brad Raffensperger to \"find\" votes to overturn the election results and repeatedly touted baseless claims of election fraud. A high-stakes runoff election in Georgia. An hours-long spectacle as members of Congress oppose certifying President-elect Joe Biden's victory. And the continued rollout of the Covid-19 vaccine in the US and abroad. This week is shaping up to be a perfect storm for misinformation to spread online and offline. And it will once again test the social media companies who have struggled to effectively crack down on baseless claims spread by President Donald Trump and others on their platforms in recent months. \"We are in a propaganda cyclone, across the country and in Georgia,\" said Jennifer Grygiel, an assistant professor of communication at Syracuse University focused on social media who is critical of how the platforms have handled misinformation so far. In the past week, Twitter conversations about Georgia have been “dominated” by false claims and misinformation about the presidential election results and the upcoming runoffs, according to a new report from nonpartisan nonprofit Advance Democracy. For example, 4 of the top 5 posts on Twitter in the past week about Georgia were from Trump -- and all 4 promoted baseless voter fraud claims about the election. Meanwhile, two months of unsubstantiated claims of widespread voter fraud from Trump and others paved the way for the upcoming \"Stop the Steal\" protest in Washington DC this week, timed with the certification of Biden's win in Congress. Over the weekend, Twitter began showing a warning to users who clicked on a link for one of the websites for Wednesday's “Stop the Steal” protests. Twitter's pop-up message says, \"Warning: this link may be unsafe.\" It lists several possible reasons, including “spammy links” that mislead people or “violent or misleading content that could lead to real-world harm.” “It’s so vague,\" Grygiel said. \"It really just shows that these companies weren’t ready for this.\" The companies did implement a number of measures to cut down on the spread of election misinformation, but last month Facebook and Twitter confirmed they had begun relaxing some of them, despite Trump and his allies continuing to push baseless allegations of election fraud. Facebook, in particular, scaled back its so-called “break glass” measure implemented to prevent the spread of misinformation, a reversal that suggested the company believed the country is past the point of crisis.  This week may test that assumption. In the waning days of his presidency, Donald Trump continues to spread nonsense conspiracies over the 2020 election and the officials who oversaw it, attacking Georgia's governor and secretary of state on Twitter Tuesday.  Following Secretary of State Brad Raffensperger's announcement that a ballot signature match audit found no evidence of absentee voter fraud in Cobb County, Georgia, Trump tweeted a conspiracy theory linking Raffensperger to the Chinese government.  Trump tweeted that Raffensperger has a brother who \"works for China,\" insinuating some nefarious, pro-China plot to have Trump lose the race in Georgia.  \"Now it turns out that Brad R's brother works for China, and they definitely don't want 'Trump'. So disgusting!\" the President tweeted after attacking Georgia's Republican Gov. Brian Kemp. Facts First: This is false. A spokesperson for Raffensperger told CNN that the secretary of state has no siblings who work for China, as Trump baselessly alleged.  Read more here ##Election## A fake Queen Elizabeth danced across TV screens on Christmas as part of a \"deepfake\" speech aired by a British broadcaster. The real British monarch traditionally delivers a Christmas Day speech aired around the world. But her speech on Friday at 3 p.m. was followed by a digitally-created fake of the Queen, aired on Channel 4 and voiced by an actor, warning viewers to question \"whether what we see and hear is always what it seems.\" The broadcaster said the video was supposed to offer \"a stark warning about the advanced technology that is enabling the proliferation of misinformation and fake news in a digital age.\" Read more here All throughout Monday, Newsmax viewers were treated to a short — yet remarkable — disclosure from the network's hosts: That Newsmax has no evidence Dominion or Smartmatic manipulated votes in the 2020 election; that Newsmax has no evidence Dominion or Smartmatic has any relationship with George Soros; that Newsmax has no evidence Dominion uses Smartmatic's software or vice versa; and that Smartmatic is a US company, not owned by the Venezuelan government. Newsmax framed the disclosure as a \"clarification,\" though the network maintained it itself had never peddled any conspiracy theories about the companies. The extraordinary about-face came after Smartmatic sent a blistering legal threat to Newsmax and other right-wing media outlets earlier this month. Ben Rhodes summed up the Monday messages succinctly, tweeting, \"So, we're going to spread massive amounts of total disinformation like cancer metastasizing through American democracy, but we also don't want to get sued so we're offering this clarification.\" Read more here ##Election## People who tuned into Fox News over the weekend may have seen something unexpected: a point-by-point fact-check to wild election fraud claims made by some of the network's popular hosts. After voting technology company Smartmatic sent Fox News a blistering legal threat that accused the network of participating in a \"disinformation campaign\" against it, the network aired a remarkable news package debunking claims its hosts and guests have propagated. The package aired for the first time Friday night on Lou Dobbs' show. The same package then aired Saturday night on Jeanine Pirro's program as well as Sunday morning on Maria Bartiromo's show. All three hosts, who use their platforms to air pro-Trump propaganda, are close with the President. Read more here ##Election## Facebook and Twitter are relaxing some of their measures intended to reduce the spread of misinformation around the election even as President Donald Trump and his allies continue to push baseless allegations of election fraud.  Facebook confirmed to CNN Business on Thursday that it is scaling back a so-called “break glass” measure implemented to prevent the spread of misinformation during the election, a reversal that suggests the company believes the country is past the point of crisis.  The emergency measure, first teased by the company's executives in September, tweaked Facebook’s algorithms to prioritize content from more authoritative publishers as determined by an internal metric called “news ecosystem quality.”  The New York Times first reported the rollback. “This was a temporary change we made to help limit the spread of inaccurate claims about the election,” Andy Stone, a spokesperson for Facebook, said in a statement. “News stories make up a small portion of what people see on Facebook overall, and political news makes up a smaller fraction of that news content.\" \"We’re still ensuring that people see authoritative and informative news on Facebook, especially during major news cycles and around important global topics like elections, COVID-19, and climate change,\" Stone added. After the election, Facebook employees were also told the change was never meant to be permanent, according to the Times. On Wednesday, Twitter announced it had also reverted a change designed to slow down retweets on its service.  The initial product change, issued in October, prompted users to add a comment before retweeting a post, creating what the company calls a quote tweet. In its post-election review, however, Twitter concluded that this tweak did more harm than good.  “Our goal with prompting QTs (instead of Retweets) was to encourage more thoughtful amplification,” Twitter said. “We don’t believe that this happened, in practice. The use of Quote Tweets increased, but 45% of them included single-word affirmations and 70% had less than 25 characters.” Twitter also said that the intervention reduced overall sharing on its platform, which is why it reversed the change.  Last week, Google lifted its moratorium on political advertising, saying that the “sensitive events” designation it had applied to election ads for roughly a month was no longer necessary.  “While we no longer consider this post-election period to be a sensitive event,” Google spokesperson Charlotte Smith said in a statement at the time, “we will continue to rigorously enforce our ads policies, which strictly prohibit demonstrably false information that could significantly undermine trust in elections or the democratic process.” ##Election## ##Facebook## The Electoral College officially confirmed President-elect Joe Biden's win Monday, yet President Donald Trump has continued to insist the results are fraudulent. Shortly after Biden crossed the electoral vote threshold necessary to secure his win, Trump took to Twitter to tout a recently released report from Allied Security Operations Group, an organization that was involved with the Trump campaign lawsuits in battleground states. According to Trump, the report claims that analysis of the election results in Antrim County, Michigan, \"shows massive fraud\" on a level that could change the results of the election. The report has received pushback from state officials. Excluding retweets, Trump seemingly referenced the report in five of his nine tweets on Tuesday, all of which Twitter flagged as containing disputed claims about the election. Echoing the report, Trump tweeted that voting machines from the election technology company Dominion Voting Systems had \"changed the results\" of a landslide election and that Michigan's voting machines in particular had a \"68% error rate.\" Facts First: Trump's characterizations of the report are false and misleading. The report, which was released to the public Monday, claimed Antrim County, not the state's voting machines as a whole, had an error rate of approximately 68%. Both Trump and the report are unclear as to what this supposed error rate actually encompasses but Michigan officials and elections experts, including federal employees in the Trump administration, have found no evidence supporting the report's claims. Read more here ##Election## ##Trump## Twitter will start removing false and misleading information about Covid-19 vaccines from next week onwards, the company announced Wednesday.  Tweets subject to removal include those suggesting vaccines \"are used to intentionally cause harm to or control populations\" as well as \"false claims which have been widely debunked about the adverse impacts or effects of receiving vaccinations\" and claims that vaccines are unnecessary because \"Covid-19 is not real or not serious,\" Twitter said in a blog post.  The new rules are an expansion of Twitter's existing policies against misinformation about the coronavirus — the company began removing tweets that could cause a \"direct risk to people's health or well being\" in March and started applying warning labels to other misleading coronavirus tweets in May.  Twitter will also add labels or warnings to tweets that spread \"unsubstantiated rumors, disputed claims, as well as incomplete or out-of-context information about vaccines\" starting early next year, it said.  Social media sites are gearing up for an uptick in misinformation and disinformation as coronavirus vaccines begin to be administered across the United States and other countries.  Facebook, Twitter and other platforms have their work cut out for them: The coronavirus and Covid-19 vaccines have already been the subject of numerous conspiracy theories. Platforms have scrambled to take action or create policies to combat the spread of coronavirus-related misinformation. ##Coronavirus## It started with a Tweet from a QAnon supporter at 2:09 in the morning: #SubpoenaObama. Though devoid of context, the cryptic message made sense to anyone in tune with the groundless conspiracy theory that the Obama administration -- prior to leaving office in 2017 -- had taken active measures to undermine the incoming Trump presidency. Within a minute, the same Twitter account sent another tweet encouraging others to push the hashtag, adding that if they do, \"good things will happen.\" Dozens of QAnon enthusiasts obliged, and before long the hashtag was on fire, at times racking up roughly 4,000 tweets per hour, according to the Network Contagion Research Institute (NCRI), which tracks misinformation across social media channels. Along the way #SubpoenaObama was tweeted by conservative influencers such as Glenn Beck and former Fox Nation personalities Diamond and Silk. By the next day, May 14, the hashtag had apparently caught the eye of President Trump, who used Twitter to urge Republican Sen. Lindsey Graham of South Carolina -- chairman of the Senate Judiciary Committee -- to call Obama to testify. \"He knew EVERYTHING,\" Trump tweeted, referring to Obama. \"Just do it.\" Later that day, Graham announced a probe into the matter -- although he begged off Trump's request to subpoena Obama himself. The example highlights a little-known facet of QAnon, experts at the NCRI said. Rather than being a nebulous group that amplifies messages organically at the grassroots level, QAnon appears to also be an occasional architect of messages that, through coordinated behavior, make their way to the most powerful factions of the Republican Party. Read more here ##Election## Facebook has begun proactively notifying users after they have interacted with misinformation about the coronavirus that has been removed under the platform's rules. The social media giant said Tuesday that users will receive a notification in their feeds that displays a thumbnail of the removed posts, and that the notification will inform users that the posts contained false claims. The notices will also explain to users where they first encountered the posts and how they engaged with it, according to a blog post.  The new notifications are an update to an existing coronavirus misinformation policy, and reflect how Facebook is moving more aggressively to combat coronavirus misinformation as the vaccine rollout begins.  Experts have said that social media platforms will need to work to counter misinformation about the coronavirus vaccine as it becomes available. ##Facebook## ##Coronavirus## Facebook said Tuesday it will allow political ads to run on its platform ahead of the runoff elections in Georgia next month while continuing to ban political ads in the rest of the country. Starting Wednesday, Facebook will allow ads in the state from advertisers who are approved to run ads about social issues, elections or politics.  The January 5 runoffs in Georgia are for two Senate seats that will determine control of the US Senate. Early voting began on Monday.  \"In recent weeks we’ve heard feedback from experts and advertisers across the political spectrum about the importance of expressing voice and using our tools to reach voters ahead of Georgia’s runoff elections,\" Facebook said in a blog post on Tuesday.  Facebook also said it would \"prohibit any ad that includes content debunked by third-party fact-checkers or delegitimizes the Georgia runoff elections.\" The move is the latest example of tech companies rethinking their broad bans on political advertising around the election. Last week, Google lifted its election-related moratorium on political ads, saying the election is no longer a \"sensitive event.\" Facebook still won't allow ads on social issues, elections or politics elsewhere in the US, as part of a previous policy announcement.  The company has come under heavy criticism for its political ads, which allow politicians to lie. Facebook CEO Mark Zuckerberg announced in September that the company would not accept new political ads in the final week of the 2020 campaign. \"It's important that campaigns can run get out the vote campaigns, and I generally believe the best antidote to bad speech is more speech, but in the final days of an election there may not be enough time to contest new claims,\" Zuckerberg said in a Facebook post at the time. Facebook later announced extending the ad ban for an extra month after the election. Facebook accused people linked to the French military on Tuesday of running a covert online influence operation targeting parts of Africa. It is the first time Facebook has publicly linked a campaign like this to individuals connected to a Western military. The deceptive tactics allegedly used, which include using Facebook to pose as locals in the targeted countries, mirror misinformation campaigns run by the Russian government. Facebook staff told reporters on a press call Tuesday that the company could not say if the operation was directed by the French military itself -- they only said it was run by \"individuals associated\" with the military. According to Facebook, the operations targeted the \"Central African Republic and Mali, and to a lesser extent Niger, Burkina Faso, Algeria, Cote d'Ivoire and Chad.\" Facebook removed the accounts and also announced on Tuesday that it had removed accounts, also posing as Africans, that were linked to Russian troll group. In some cases, Facebook said, the fake French and Russian accounts even interacted with each other. Read more here ##Facebook## A voting technology company swept up in baseless conspiracy theories about the 2020 election said on Monday that it had sent legal notices to Fox News and two other right-wing media companies for participating in a \"disinformation campaign\" aimed at damaging it. The company, Smartmatic, said that Fox News, One America News, and Newsmax have helped spread false and defamatory claims that are not supported by real evidence and could easily have been debunked with basic research. \"They have no evidence to support their attacks on Smartmatic because there is no evidence,\" Smartmatic chief executive Antonio Mugica said in a statement. \"This campaign was designed to defame Smartmatic and undermine legitimately conducted elections.\" As President Donald Trump continues to attack the integrity of the voting system, some of his allies have homed in on Smartmatic because of the services it provided Los Angeles County for the 2020 election. The baseless conspiracy theories peddled about Smartmatic, which mimic those pushed against Dominion Voting Systems, falsely suggest that the company's technology allowed the November vote to be rigged against Trump. Some strains of the conspiracy theory have aimed to tie the company to the late Venezuelan leader Hugo Chávez and George Soros, the billionaire philanthropist who is portrayed as a boogeyman in right-wing media. In its legal notice to Fox News, Smartmatic identified several instances in which such theories were spread on its air by either Trump lawyer Rudy Giuliani or former Trump campaign lawyer Sidney Powell. The legal notice, which stated assertions made about Chavez and Soros have no truth to them, also identified instances in which the network's pro-Trump propagandists, such as Lou Dobbs and Maria Bartiromo, helped spread false information. Read more here Right-wing news outlets, including Fox, Newsmax and OAN, are perpetuating the myth that President Donald Trump won the 2020 election. Why? To make their audiences feel better. \"Fox News and OAN and Newsmax are not telling their viewers what they need to hear,\" SE Cupp told CNN Chief Media Correspondent Brian Stelter on \"Reliable Sources\" Sunday. \"They're telling them what they want to hear. That's fan fiction.\" Cupp added that news outlets are obligated to \"tell facts as they exist, even if they are not what your viewers want to hear.\" The misinformation is taking a toll on conservative media viewers: More than two-thirds of Republicans think the election was stolen from Trump, according to a new Fox poll. Read more here  Texas Attorney General Ken Paxton has petitioned the United States Supreme Court to take up a lawsuit against Wisconsin, Pennsylvania, Michigan and Georgia, claiming that there are voting irregularities in each state that still require investigation. The Supreme Court has already rejected a separate request to block certification of Pennsylvania's election results which CNN legal expert Steve Vladeck said is a signal the court may not want to get involved in election-related disputes. The filing from Texas contains numerous false claims of voter fraud, most of which have been repeatedly touted by President Donald Trump and his allies. Here's a look at several of those claims. 1. Ballot dumps The filing cites witness claims of \"mysterious late night dumps of thousands of ballots at tabulation centers\" as an example of the alleged \"rampant lawlessness\" present throughout the election process. Facts First: There's nothing inherently suspicious or mysterious about large batches of votes being reported late at night or even after Election Day. 2. Poll watchers According to the filing, video shows \"poll watchers being blocked from entering vote counting centers—despite even having a court order to enter.\" Facts First: There is no evidence supporting claims that poll watchers were shut out of the process. There have been some instances where poll workers did not understand the rules but for the most part, registered poll watchers have been allowed at polling places. 3. Suitcases of ballots The filing says there is video of \"suitcases full of ballots being pulled out from underneath tables after poll watchers were told to leave.\" Facts First: The brief is likely referring to viral video footage of a ballot counting location in Fulton County, Georgia. After a review of the footage, state and county officials determined the events in the video were part of the normal process, not fraud. Though observers weren't present at the time captured in the video, there was no announcement made telling them to leave, according to Fulton County Elections Director Richard Barron. And the objects pulled from under the table were ballot bins, not suitcases, according to election officials. 4. Michigan \"glitch\" The brief also suggests that a \"glitch\" occurred in Michigan, implying that Dominion voting machines were possibly at fault. \"In Michigan, which also employed the same Dominion voting system,\" the brief says, \"on November 4, 2020, Michigan election officials have admitted that a purported 'glitch' caused 6,000 votes for President Trump to be wrongly switched to Democrat Candidate Biden.\" Facts First: There was no technical glitch. It was human error and the issue was corrected and never affected the official vote total, according to state election officials. 5. Mail-in ballots Under a section titled \"Facts,\" the brief claims \"Absentee and mail-in voting are the primary opportunities for unlawful ballots to be cast\" and suggest the expansion of mail-in voting in the election played a role in creating \"a massive opportunity for fraud.\" The insinuation -- that mail-in ballots are potentially rife with fraud -- is one of the main themes touched upon throughout the lawsuit. Facts First: Election experts have told CNN time and again that mail-in ballots are a safe form of voting and not subject to widespread fraud. There have been no reports from state election officials of either party of widespread voter fraud from mail-in ballots. Read more here ##Election## Google is rolling out a new feature in search that it hopes will help combat misinformation about Covid-19 vaccines. When people search for information on the topic, Google will show a list of authorized vaccines near them and informational panels on each of the vaccines. At first, this feature will only be available in the United Kingdom.  Earlier this week, the UK became the first nation to start vaccinating its citizens with an authorized Covid-19 vaccine. As other health authorities authorize vaccines, Google said it would introduce the same feature to more countries. \"As the world turns its focus to the deployment of vaccines, the type of information people need will evolve. Communities will be vaccinated at an unprecedented pace and scale. This will require sharing information to educate the public, including addressing vaccine misperceptions and hesitance, and helping to surface official guidance to people on when, where and how to get vaccinated,\" Google said in a blog post on Thursday. Tech companies, particularly social media networks, have struggled for years to combat vaccine misinformation. As Covid-19 vaccines become available around the world, the stakes for them to get it right couldn't be higher.  Google, which owns YouTube, said Covid-19 information panels on the video-sharing platform have been viewed 400 billion times since their March launch. The panels appear on YouTube's homepage and on videos and in search results related to the pandemic. The panels will be updated to point users to vaccine information and to health authorities.  ##Coronavirus## In the wake of the US election, conservatives flocked to alternative social networks including Parler over complaints that Facebook and Twitter censored their voices.  There, some people found an alternate reality, and a platform rife with misinformation, including a stream of baseless allegations of voter fraud. At one point, Parler hit the number one spot overall on Apple's US App Store, ahead of big names like TikTok and YouTube. In about a week, the app saw more than 4.5 million new people sign up for accounts, according to a letter from Parler CEO John Matze. Now that bump appears to be fading. New downloads for Parler have plummeted and are approaching the same levels as before the election, according to data from Apptopia, which tracks mobile apps. While Parler's daily active users, a key metric of how engaged people are in the service, remains higher than before the election, the number is decreasing, Apptopia says. Parler, founded in 2018, bills itself as \"unbiased social media\" and a place where people can \"speak freely\" without fear of being \"deplatformed,\" according to its website and App Store description. It looks like a mashup of Twitter and Instagram, with a main feed, follower metrics and ways to share posts and links.  \"The data trends resemble a fad, and a short-lived one at that,\" said Adam Blacker, VP of insights at Apptopia. \"Parler had a very good spike. People were interested, it's in the news, it receives downloads. ... But it appears, in our data, that there is no staying power.\" Read more here ##Election##  ##Coronavirus## Georgia, currently the center of the American political universe, is so awash with misinformation that some supporters of President Donald Trump here believe that he did not lose the presidential election. Some are not sure if they will be able to trust the results of the state's runoff election next month that will decide which party controls the US Senate. Since Trump's loss here in November, the Peach state has become a key focus in a disinformation campaign pushed by the President and his allies and believed by some of his supporters in the state. A parallel universe has been created. One where, without evidence, some Trump supporters believe the Republican Governor, who formally recognized the certification of President-elect Joe Biden's win here, is actually a shill for the Chinese government. Where voting equipment used in this state has something to do with the late former Venezuelan President Hugo Chavez. And where innocuous videos of Georgian election officials doing their job are supposedly evidence of election fraud. The bogus claims have resulted in threats against local officials who worked on November's election. \"We had an entire ad campaign on disinformation that we did in the state to explain to people, 'A lot of what you're going to hear is not going to be real.' The problem is we have to combat it from the president of the United States, which makes it much more difficult,\" Gabriel Sterling, voting systems implementation manager for the Georgia secretary of state's office, told me earlier this week. Trump traveled here last Saturday, ostensibly to campaign for Republican Senators Kelly Loeffler and David Perdue who are running in next month's runoff election. While Trump did tell Georgians to go vote, he spent much of his rally lamenting, falsely claiming he hadn't actually lost the state of Georgia in the presidential election. The disinformation and misinformation is not all being pushed by, or exclusively being believed by Georgians. It's part of a national effort to confuse, but it is having an impact here. While the vast majority of Trump supporters I spoke to in Valdosta told me they are planning to vote next month (despite believing the presidential election was rigged and that Trump didn't lose), some told me it was reasonable for Georgians to consider sitting out the runoff election. Read more here ##Election##  Google plans to lift its election-related moratorium on political ads beginning Dec. 10, the company informed advertisers on Wednesday.  The tech giant said in a letter to advertisers obtained by CNN that Google will lift its “sensitive event” designation for the US election and restore its standard policies surrounding election ads. The moratorium, which was announced ahead of the election, was expected to last for at least a week following Election Day but has gone on for roughly a month. In a statement, company spokesperson Charlotte Smith said that Google regularly pauses ads surrounding events it deems sensitive, in an effort to prevent bad actors from exploiting the circumstances. “While we no longer consider this post-election period to be a sensitive event,” Smith said, “we will continue to rigorously enforce our ads policies, which strictly prohibit demonstrably false information that could significantly undermine trust in elections or the democratic process.” The change in ad policy was first reported by Axios. Google’s decision comes as its subsidiary YouTube announced Wednesday it will now remove new content that seeks to undermine the election outcome. YouTube is taking belated action on election misinformation: The company said it would now remove misleading videos that claim widespread fraud or other errors changed the outcome of the US presidential election. Google-owned YouTube announced that it would begin enforcing against this content on Wednesday, citing Tuesday's safe harbor deadline for the US election, which is the date after which state election results cannot effectively be challenged. YouTube said that enough states have certified their election results to determine a President-elect. National news outlets have universally projected that Joe Biden will be the next President. As an example of content that would be banned, YouTube said it would take down videos claiming that a presidential candidate won the election due to widespread software glitches or errors in counting votes. It will begin enforcing the policy starting Wednesday, and said it would \"ramp up\" efforts in the weeks to come. It will still allow videos including news coverage and commentary to remain on the platform if they have enough context. Any videos in violation of the policy that were posted prior to Wednesday, will remain up even though they now break YouTube's rules. They will feature an information panel that says election results have been certified. When asked why YouTube did not implement these policies ahead of or during the election, a YouTube spokesperson cited Tuesday's safe harbor deadline as its reasoning. During the election, YouTube arguably took the least aggressive action on election-related misinformation. For example, a video claiming that President Trump won four more years in office and spouting baseless claims that Democrats are \"tossing Republican ballots, harvesting fake ballots, and delaying the results to create confusion\" was allowed to remain on the platform. At the time, YouTube said the video did not violate its rules and would not be removed. Read more here Millions of Americans in the right-wing media universe are every day consuming coverage on television, on radio, and online denouncing the election as a fraud. Lies that the election was rigged and stolen from President Trump have absolutely dominated coverage in that world for more than a month — an unsettling reality that cannot be stressed enough. And, unfortunately, there are no signs of such coverage letting up. So as we inch closer to Inauguration Day, it's worth considering: How does this end? It's as if a pot of water has been heated to a violent boil over the last few weeks. Will folks like Sean Hannity and Rush Limbaugh just flip the switch on the stove off and let the temperature cool down? Probably not. Will the water simply evaporate over time, naturally dissipating? Perhaps. But there is also a more frightening scenario: that the water grows to a more and more violent boil, eventually spilling over into civil unrest. Let's hope that such a scenario does not play out, but riling up a chunk of the electorate can have dangerous consequences. Read more here A pair of tweets by the Arizona Republican Party asking supporters if they are willing to sacrifice their lives to challenge the official presidential election results do not violate Twitter’s rules, a company spokesperson told CNN Tuesday.  In the early morning hours of Dec. 8, the Twitter account @AZGOP quote-tweeted an activist associated with the so-called #StoptheSteal movement, which is devoted to opposing the election outcome — despite statements by many election officials that the 2020 election was among the most secure in history.  “I am willing to give my life for this fight,” tweeted Ali Alexander, an organizer of the movement.   Arizona Republicans then followed up by quoting Alexander’s tweet. “He is. Are you?” @AZGOP tweeted. The account then shared, in a now-deleted tweet, a quote and video clip from the 2008 film “Rambo IV:” “Live for nothing, or die for something.” “The Republican Party of Arizona condemns all forms of violence in the strongest terms,\" Arizona GOP spokesman Zachery Henry told CNN Business. \"Fictional movie scenes should be weighed in their proper context. However, due to concerns about copyright and fair use law, this clip has been removed.” The tweets by the Arizona Republican Party sparked immediate horror from some critics.  “You're asking people to die for this conspiracy theory? What in the living hell is wrong with you people?” tweeted Arizona state senator Martín Quezada.  Some Twitter users who replied to the @AZGOP tweets claimed to have reported the account to the FBI and to Arizona Attorney General Mark Brnovich for incitement to violence. But others appeared to take the account’s suggestion as a serious proposal.   “I agree. This is the hill to die on,” one respondent said. “IM WILLING TO GIVE MY LIFE,” wrote another.  According to Twitter’s policies, glorification of violence is prohibited on the platform, as well as specific threats of violence and wishing death on an individual or group of people. Twitter’s rules also prohibit the promotion of violent extremism and suicide. \"This includes celebrating any violent act in a manner that may inspire others to replicate it or any violence where people were targeted because of their membership in a protected group,” the policies say.  Asked about @AZGOP’s specific tweets, however, Twitter confirmed to CNN that the tweets are not in violation of the rules. The company spokesperson did not elaborate on the company’s reasoning.  ##Election## Around the election, social media platforms including Facebook and Twitter were praised for how quickly and widely they applied warning labels to misinformation. But President Donald Trump's 46-minute video last week, which was riddled with election misinformation and conspiracy theories discredited by his own officials and the courts, has made unmistakably clear what many digital democracy experts have been warning for months: labels are not enough. Social media platforms' misinformation labels, they've said, are inadequate and ill-matched for the torrent of false claims that continue to divide Americans and jeopardize their faith in democratic processes. Within minutes of Trump's posts going up on Facebook and Twitter, the social media platforms sprang into action. Beneath the video, Facebook reminded users that Joe Biden \"is the projected winner\" of the election, citing Reuters and other reporting agencies. Twitter applied a warning label beneath the tweet containing the video clip, saying \"This claim about election fraud is disputed.\" Google's YouTube informed users in a label that the Associated Press had called the race for Biden. Read more here In the month since the election, President Donald Trump has grasped for seemingly any theory to explain why he lost to Joe Biden, no matter how outlandish -- dead people voted, poll watchers were illegally removed, foreign countries influenced the tabulation of the votes! Yet as his explanations have changed, they remain consistently untrue. Over the course of the four weeks following the election, Trump sent around 500 tweets, 171 of which were flagged by Twitter for containing false or misleading information about the election. Despite repeated denials of any wrongdoing from federal and state officials, there's evidence Trump's onslaught is having an effect. A recent Pew survey found only 35% of Trump voters say they are \"very confident\" their vote was counted accurately, much lower than the 82% of Biden voters. Read more here ##Election## Following Sunday’s Georgia Senate run-off debate, some social media users falsely claimed that Republican Sen. Kelly Loeffler was wearing an earpiece, implying that she may have been fed answers.  It’s a truly unoriginal conspiracy theory. The same baseless claim was lobbed at President-elect Joe Biden during his first debate with President Donald Trump and has circulated about different elections, even those before the social media age.  Peddlers of the conspiracy theory pointed to a lock of Loeffler’s hair on Sunday night to claim it was a wire.  The Atlanta Press Club, which hosted the debate, responded to the online claims Monday morning, tweeting that the candidates “had no audio assistance from their campaigns.” Some of the accounts that pushed the nonsense racked up thousands of retweets overnight and at least one online outlet uncritically echoed the conspiracy theory in a headline. But there is a stark difference between who is pushing this baseless allegation compared to the similar claims made about Biden. The Trump campaign peddled the idea that Biden would wear an earpiece prior to the first presidential debate as did Trump-friendly media outlets like Fox News. One video on Twitter promoting the conspiracy theory after the debate had 4 million views alone.  While the conspiracy theory about Loeffler’s hair is circulating among some social media users, it is not a Democratic Party talking point, and it is not being pushed and embraced by influential Democrats in Georgia or around the country.  But it does demonstrate how misinformation is not an entirely partisan affair, even though a barrage of baseless and false claims since the election have disproportionately come from the right. People on the left can be duped or eagerly embrace misinformation if it fits their biases.  Stephen Lawson, Loeffler’s deputy campaign manager, responded on Twitter to one person who pushed the conspiracy on Sunday night. “You’re literally too dumb to insult,” he said. Loeffler's campaign declined to comment to CNN. On the debate stage Loeffler refused to disavow a different baseless conspiracy theory pushed by President Trump that he didn’t lose the election in Georgia. “The President has the right to pursue every legal recourse to make sure that this was a free and fair election in Georgia,” she said. The false claim that Trump didn’t lose Georgia has gotten a great deal of traction as it’s been propped up by a huge eco-system of hyperpartisan online outlets and TV networks with little regard for the truth. But it could backfire, some Republicans fear, as Georgia voters who believe the presidential election was rigged may not turn out to vote for Loeffler and Sen. David Perdue in the Georgia Senate runoff in January.  CNN's Kyung Lah contributed reporting. Twitter conversations about Georgia are full of unsubstantiated claims that the state’s upcoming runoff election will be fraudulent as well as other misinformation about the 2020 election, according to a new report from non-partisan research organization Advance Democracy. From November 26 through December 2, four of the top five posts on Twitter about Georgia made baseless allegations about the election, according to the research.  Advance Democracy determined that Twitter posts included in the analysis were about Georgia if they contained at least one of a long list of terms and hashtags, including “Georgia,” “#gapol,” run-offs, #Dems4GA,” and the names of the candidates in the race.  \"Citizens of the State of Georgia, who are about to decide what party controls the US Senate, are being bombarded by election-related disinformation on social media,\" said Daniel J. Jones, a former FBI analyst and Senate investigator, who is president of Advance Democracy. \"Much of that disinformation revolves around the idea that the election is pre-ordained or 'rigged.' It’s hard to imagine that the prevalence of this rhetoric and the outright lies about voting will not have real-world consequences on January 5th.\" Other key findings from the research: Five of the top 10 hashtags used in tweets about Georgia in the last week implied voter fraud, including “#stopthesteal,” “#fightback” and “#dominionwatch,” the latter two referring to fighting back against election fraud and watching Dominion voting machines for election fraud, respectively.\nSeven of the top 10 most shared links in tweets about Georgia in the last week were links to websites promoting election fraud, including right-wing sites. \nTwitter accounts related to the baseless QAnon conspiracy theory continue to appear and helped amplify hashtags insinuating voter fraud.  \nAs of Thursday, there are more than 97,200 active QAnon-related accounts on Twitter, despite the platform’s crackdown on such content, per the new report.  Twitter did not immediately respond to a request for comment. ##Twitter## ##Election## Facebook failed to apply fact-check labels on some election misinformation related to  Georgia, according to a report from activist group Avaaz.  Facebook has relied on fact-checking and contextual labels as a centerpiece of its strategy for combating misinformation about elections and voting, and it uses artificial intelligence to help determine what posts should get a label. Avaaz's report highlights some of the shortcomings of these systems as Georgia heads for a contentious Senate runoff on January 5. Researchers at the non-profit analyzed 204 Facebook posts promoting 12 different disinformation claims that had been independently fact-checked and found that only 40% of them had a fact check label applied. Meanwhile, 30% of the posts had just a generic information label about the election and 30% had no label at all. The posts were found between November 18 and 20. In addition to stating that information is false, fact-checking labels are vital because the spread of false posts is curtailed by Facebook’s algorithm.  “Georgia voters are just weeks away from deciding the direction of the US Senate - and the direction of the country - and their News Feeds are being overrun with misinformation that could further erode trust in the election process and suppress turnout,” Avaaz Campaign Director, Fadi Quran said in a press release.  From March 1 through Election Day, Facebook displayed warnings on more than 180 million pieces of content viewed on Facebook by people in the U.S that were debunked by third party fact checkers, the company has said. “We remain the only company to partner with more than 80 fact-checking organizations, using AI to scale their fact-checks to millions of duplicate posts, and we are working to improve our ability to action on similar posts,” Facebook spokesperson Kevin McAllister told CNN in response to Avaaz’s report. “There is no playbook for a program like ours and we’re constantly working to improve it.” ##Facebook## ##Election## President Donald Trump's nominee to become a senior Pentagon official spread debunked conspiracies on Twitter that called Trump's election loss to Joe Biden a \"coup\" attempt and shared tweets that suggest Trump should declare martial law. Scott O'Grady, a former fighter pilot and Trump loyalist, repeatedly retweeted tweets that falsely stated Trump won the election in \"landslide fashion\" and that millions of votes were stolen from the President. On November 25, O'Grady retweeted a tweet that said, \"Trump won & Biden & his Comrades will now attempt a coup,\" next to a photoshopped image of Biden beside Xi Jinping, the President of China. On December 2, he retweeted an account that shared an article that said former national security adviser Michael Flynn had shared a petition that called for martial law. He then retweeted the same account which suggested that Trump should declare martial law. \"I don't know who needs to hear this,\" the account said, \"But calling for martial law is not a bad idea when there is an attempted coup against the president and this country happening right now.\" Read more here The Cybersecurity and Infrastructure Security Agency will continue publishing to its election-related “rumor control” website through the Georgia runoffs, according to Brandon Wales, the agency’s top official. CISA, an arm of the Department of Homeland Security, gained prominence in 2020 for its work to secure the 2020 elections — and after President Donald Trump fired its now-former director, Christopher Krebs, in apparent retaliation for Krebs’ insistence that the election unfolded securely. CISA launched the rumor control website in late October to debunk misinformation about the election. Since then, it has tackled over 20 rumors, including misinformation promoted by President Donald Trump and his allies. On Wednesday, the website was updated with  information about two new rumors. The agency will not be letting down its guard until at least the end of January, said Wales, CISA’s acting director, during the Aspen Cyber Summit on Thursday. “What I’ve told our staff is that our election security missions … will continue until all the elections are complete,” Wales said. “We will keep issuing rumor control entries as we think that the situation warrants it, and where we think we can have an impact. We’ll do that through the end of this cycle.” Wales’ remarks reflect his second public appearance since taking the reins from Krebs last month. Wales testified on Wednesday before the Senate Homeland Security committee. ##Election## Facebook said Thursday that it will begin removing false claims about coronavirus vaccines that have been debunked by public health officials.  The move is an extension of Facebook's coronavirus misinformation policy and comes as experts worry that conspiracy theories and baseless claims about vaccines could limit the number of people who get them.  Facebook said in a blog post that it would potentially take action against \"false claims about the safety, efficacy, ingredients or side effects of the vaccines.\" \"For example, we will remove false claims that COVID-19 vaccines contain microchips, or anything else that isn’t on the official vaccine ingredient list,\" the company said in the blog post. \"We will also remove conspiracy theories about COVID-19 vaccines that we know today are false: like specific populations are being used without their consent to test the vaccine’s safety.” Previously, Facebook's policies banned misinformation about coronavirus that \"contributes to the risk of imminent violence or physical harm.\" Facebook said that its new enforcement on vaccine misinformation will happen gradually. The company has historically struggled to handle anti-vaccine misinformation on its platform. In the wake of a measles outbreak in the US nearly two years ago, Facebook promised to take action on anti-vaxx misinformation, including making it less prominent in the news feed and not recommending related groups. But even then, anti-vaxxer information was easily searchable on Facebook-owned Instagram.  Facebook recently booted a large private group dedicated to anti-vaccine content. But many groups dedicated to railing against vaccines remain. A recent cursory search by CNN Business found at least a dozen Facebook groups advocating against vaccines, with membership ranging from a few hundred to tens of thousands of users. At least one group was specifically centered around opposition to a Covid-19 vaccine. ##Facebook## ##Coronavirus## After years of standing idly by, companies like Facebook and Twitter are, to varying degrees, calling bullshit on some of President Donald Trump's lies — most prominently, his false claim that he didn't lose the election. These social media platforms are still awash with misinformation and hate — and many critics of Big Tech on the left say the platforms still aren't doing enough about it — but to Trump's supporters, the steps Big Tech has taken to slow the spread of misinformation amounts to censorship. And some have begun seeking alternative homes online. In the days after the election, Parler topped the charts of the Apple and Android app stores, and the platform has become a hub of Trump-backed conspiracy theories casting doubt on the election of President-elect Biden. Among the top trending topics on the platform this week are #TrumpWon, #VoterFraud and #NeverQuit. ##Trump## Read more here.  President Donald Trump has repeatedly insisted the election results in Georgia were rigged while state election officials maintain there's no evidence of widespread fraud. In an effort to promote the falsehoods, Trump and his allies have continued to call for a signature audit of the absentee ballot envelopes in Georgia, while making false or misleading claims about the potential process. Even after Georgia election official Gabriel Sterling angrily warned that \"it's all gone too far\" and \"it has to stop\" before someone gets hurt or killed, Trump continued to perpetuate unsubstantiated claims of fraud. In response to a video clip of Sterling calling for the President and senators to \"step up,\" Trump tweeted on Tuesday night, \"Rigged Election. Show signatures and envelopes. Expose the massive voter fraud in Georgia.\" A week earlier, Trump falsely claimed on Twitter that an audit would uncover \"tens of thousands of fraudulent and illegal votes,\" and suggested that a signature audit would ultimately benefit both himself and the two Republican senatorial candidates in the state. Despite certifying the state's election results, Georgia's Republican Gov. Brian Kemp has also joined Republicans' calls demanding the secretary of state carry out a signature audit, saying \"it seems simple enough to conduct a sample audit of signatures on the absentee ballot envelopes\" in order to address any lingering concerns Georgians may have about the integrity of the voting system. Facts First: It's misleading for Kemp, Georgia's former secretary of state, to suggest that a signature audit after an election would be \"simple,\" even if it's just for a sample of ballots. Georgia's current secretary of state, Brad Raffensperger, a Republican, told CNN a signature audit is outside his office's legal purview. It would need to be ordered by a court, and currently, there is no basis to conduct one. Read more here Facebook has asked its independent Oversight Board for a ruling on how to handle misleading claims about hydroxychloroquine, which has been baselessly promoted by President Donald Trump and his allies as a treatment for Covid-19. The referral comes as  public health experts and policymakers fret about Facebook’s role in spreading misinformation about the pandemic. Experts warn that false claims about Covid-19 vaccines could hinder efforts to administer it. The case involves Facebook’s decision to take down a user’s post that claimed the anti-malaria drug hydroxychloroquine was being used to save lives. Facebook said it removed the post under its violence and incitement policy, under which the platform may remove content that it says poses a “genuine risk of physical harm or direct threats to public safety.” Both the National Institutes of Health and US Food and Drug Administration warn against using hydroxychloroquine for the treatment of Covid-19. A decision by the Oversight Board, which would be binding on Facebook, could powerfully shape the platform’s handling of Covid-19 posts moving forward. The case is among the first to be considered by the Oversight Board, an entity proposed by CEO Mark Zuckerberg in 2018 and which launched this fall. The organization consists of academics and experts on human rights and ethics. It has received funding from Facebook but has stressed its independence from the company through a number of guardrails. ##Coronavirus## ##Facebook## A British member of Parliament blasted Facebook on Wednesday over its handling of anti-vaccine content and warned that the social media platform risks undermining Covid-19 vaccines just as vaccination programs are getting underway.  “Today in the UK, the Pfizer vaccine has received regulatory approval and the first doses will be administered next week,” said MP Damian Collins, former Chair of the UK House of Commons Digital, Culture, Media and Sport Select Committee. “One of the greatest risks to the success of this program is anti-vaccine disinformation warning people not to take it.” Collins’ remarks came during a public session of the International Grand Committee on Disinformation, a body that includes government officials from the United States, the UK, Canada, Germany, Ireland, India, Brazil and several other countries. The US was represented by Rep. David Cicilline, a leading tech critic and chairman of the House Judiciary Committee’s antitrust panel, and Rep. Jan Schakowsky, who chairs the House Energy and Commerce Committee’s consumer protection subcommittee. Citing research reports on anti-vaccine content on Facebook, Collins said the platform’s “own algorithms are pushing anti-vax content over authentic health information. The impact of this is declining trust in the vaccine.” “This is not just a public health challenge, but why legislation to combat harmful disinformation is so necessary,” he added. Next year, Collins, said, the UK parliament is expected to debate a bill that could establish a new regulator for online harms modeled after similar agencies that govern tech platforms’ handling of user data and privacy. Facebook spokesman Andy Stone said the company removes misinformation about the coronavirus that could lead to “imminent physical harm” and directs users to Facebook’s Covid-19 information center, which is available in 189 countries. Stone added that Facebook has banned advertisements that discourage people from getting vaccines. On Monday, during a livestream with Dr. Anthony Fauci, Facebook CEO Mark Zuckerberg said the company is “planning a push” to provide users with authoritative sources of vaccine information. Zuckerberg said that Facebook has already reached out to President-elect Joe Biden’s transition team about helping with the pandemic response. ##Facebook## ##Coronavirus## Nearly two years ago, public health experts blamed social media platforms for contributing to a measles outbreak by allowing false claims about the risks of vaccines to spread. Facebook pledged to take tougher action on anti-vaccine misinformation, including making it less prominent in the news feed and not recommending related groups. But shortly after, Facebook-owned Instagram continued to serve up posts from anti-vaccine accounts and hashtags to anyone searching for the word \"vaccines.\" Despite actions against anti-vaccine content since then — some as recent as last month -- Facebook has failed to totally quash the movement on its platforms. Now, with Covid-19 vaccines potentially making their way to some Americans as soon as this month, the tech companies will face their biggest test on this front yet. The stakes for them to get it right, after years of struggling to combat vaccine misinformation, couldn't be higher. \"To beat this pandemic, we also have to defeat the parallel pandemic of distrust,\" Francesco Rocca, president of the International Federation of Red Cross and Red Crescent Societies, said on Monday. Some social networks have already put policies in place specifically against Covid-19 vaccine misinformation; others are still deciding on the best approach or are leaning on existing policies for Covid-19 and vaccine-related content. But making a policy is the easy part -- enforcing it consistently is where platforms often fall short. Facebook, Twitter and other platforms have their work cut out for them: The coronavirus and pending vaccines have already been the subject of numerous conspiracy theories, which platforms have taken action on or created policies about. Some have made false claims about the effectiveness of masks or baseless assertions that microchips will be implanted in people who get the vaccine. Earlier this month, Facebook booted a large private group dedicated to anti-vaccine content. But many groups dedicated to railing against vaccines remain. A cursory search by CNN Business found at least a dozen Facebook groups advocating against vaccines, with membership ranging from a few hundred to tens of thousands of users. At least one group was specifically centered around opposition to a Covid-19 vaccine. Brooke McKeever, an associate communications professor at the University of South Carolina who has studied vaccine misinformation and social media, expects a rise of anti-vaxxer content and said it's a \"big problem.\" \"The speed at which [these vaccines] were developed is a concern for some people, and the fact that we don't have a history with this vaccine, people are going to be scared and uncertain about it,\" she said. \"They might be more likely or prone to believing misinformation because of that.\" That has real world consequences. McKeever's fear: that people won't get the vaccine and Covid-19 will continue to spread. Public health experts say vaccines are extremely safe, and serious adverse reactions are very rare. Moderna says it will ask US and European regulators to allow emergency use of its COVID-19 vaccine as new study results confirm the shots offer strong protection. But anti-vaccination posts continue to find a large audience. A July report from the Center for Countering Digital Hate (CCDH) found anti-vaxxers have a following of about 58 million people, based primarily in the US, as well as in the UK, Canada and Australia. \"The decision [of social media platforms] to continue hosting known misinformation content and actors left online anti-vaxxers ready to pounce on the opportunity presented by coronavirus,\" the report said. The report said social media platforms have done the \"absolute minimum.\" Here's where the platforms stand on combating Covid-19 vaccine misinformation so far. Read more here ##Coronavirus## ##Facebook## ##Twitter## ##YouTube## Covid-19 vaccines are fast approaching, but a second pandemic might impede efforts to recover from the first, according to the president of a global humanitarian aid group. That second pandemic: \"fake news\" about those very vaccines. Francesco Rocca, president of the International Federation of Red Cross and Red Crescent Societies, said in a virtual briefing to the UN Correspondents Association on Monday that governments and institutions needed to implement measures to combat growing mistrust and misinformation. \"To beat Covid-19, we also need to defeat the parallel pandemic of mistrust that has consistently hindered our collective response to this disease, and that could undermine our shared ability to vaccinate against it,\" he said. The leader of the world's largest humanitarian aid network said his organization shares \"the sense of relief and optimism\" that developments in Covid-19 vaccines bring. But governments and institutions \"have to build trust in the communities\" where misinformation has taken root, he added. There is growing hesitancy about vaccines around the world, particularly the Covid-19 vaccine, said Rocca. Read more here. ##Coronavirus##  In his first interview since Donald Trump fired him by tweet earlier this month, Christopher Krebs, the former top cybersecurity official, reaffirmed his stance that the 2020 Election was the “most secure in history.” On CBS' \"60 Minutes\" Sunday, the former director of the Cybersecurity and Infrastructure Security Agency, which was charged with protecting the election against hacking and other disruptions, said his team “did a good job. We did it right. I’d do it a thousand times over.” President Donald Trump and has allies have peddled a range of conspiracy theories around voter fraud, often focusing on Dominion Voting Systems, a company that provides software to many local governments. They have claimed, without evidence, that glitches in the Dominion software led to miscast ballots, that it counted phony ballots, and that it ran an algorithm “to take a certain percentage of votes from President Trump and flip them to President Biden.” CBS’ Scott Pelley asked Krebs for his reaction to some of the unfounded claims of fraud, and specifically the conspiracy theory vocalized by attorney Sidney Powell at the recent press conference led by Trump attorney Rudy Giuliani about an alleged algorithm used by Dominion to swing votes in favor of President-elect Joe Biden.  Powell said that Dominion software \"can set and run an algorithm that probably ran all over the country to take a certain percentage of votes from President Trump and flip them to President Biden.” (The Trump campaign has since cut ties with Powell.)  “If there was an algorithm that was flipping votes or changing votes, it didn’t work,” said Krebs. “I think the more likely explanation though is that there was no algorithm, that the systems performed as intended, that the series of security controls before, during, and after an election protected those systems from any sort of misbehavior,” he added. There have been no credible reports that the company's machines affected vote counts. As CNN previously reported, one county in Georgia experienced delays reporting its results due to apparent problems with Dominion software but other issues that were allegedly connected to Dominion were actually caused by human error. Trump has used his Twitter account to perpetuate theories around unproven misuse of Dominion software as part of his broader voter fraud claims, which continue. The President has been fixated on Georgia, where a statewide audit recently concluded and confirmed a victory for President-elect Joe Biden and found no widespread fraud. Trump, who objected to the recount in a Tweet on November 16, calling it “fake” and adding misleading claims about the state’s signature-matching processes.  Trump reiterated misleading claims about the processes on Twitter Monday, suggesting that Governor Brian Kemp should “quickly check the number of envelopes versus the number of ballots. You may just find that there are many more ballots than there are envelopes. So simple, and so easy to do.”  Twitter labeled all of the above Trump tweets as disputed. All eyes are on the state as it gears up for runoff elections in January that will determine which party rules the Senate. ##Election##  After a day picking cranberries at a California farm, Josefino Cervantes Alvarado sat down for dinner to a unique mix of voices and music filling the room. \"Greetings to everybody tuning in to Radio Indígena 94.1 FM,\" said a voice coming from the radio's speakers in Spanish. Moments later, he heard another voice speaking in Mixteco — one of several indigenous languages from southern Mexico. \"I used to feel ashamed of speaking Mixteco,\" Cervantes Alvarado, 40, whose first language is Mixteco, said in Spanish. \"Whenever I listen to (the radio), I feel proud of who I am and don't want my children to forget that.\" When the Covid-19 pandemic first hit the United States, the hosts of Radio Indígena were among the first people who could explain Covid-19 to indigenous Mexican farmworkers in Ventura County, thanks to their ability to switch between Spanish, Mixteco and other indigenous languages. As the months passed, they took to debunking coronavirus misinformation. Read more here ##Coronavirus## Trump is Trump. There's nothing new to say about the man. But there is still lots to learn about his enablers. So many people, from GOP functionaries to Fox News hosts, are helping him to undermine democracy by denying the election and attacking reality. So many people are complicit. People like Maria Bartiromo. Formerly an acclaimed journalist, known around the world for making CEOs tell the truth, now she tees up Trump to recite lie after lie. Her Sunday morning call with Trump on Fox News was his first \"interview\" since he lost the election, but it wasn't a real interview at all. He wasn't ready to acknowledge that he lost, and neither was she. He displayed delusional weakness. She was complicit. And she's far from the only one. Read more here ##Election## While many Americans were enjoying Thanksgiving dinner, President Trump was tweeting against a law known as Section 230 and railing against Twitter's trending section.  \"For purposes of National Security, Section 230 must be immediately terminated!!!\" Trump tweeted on Thursday evening.   The reasoning behind Trump's claim -- without evidence or further detail -- that Section 230 must be repealed for national security reasons is unclear. Section 230 protects tech companies' ability to moderate content as they see fit. For years, many of the biggest names in tech have relied on the little-known law to avoid being held responsible for some of the most controversial content on their platforms. But as social media networks have become hotbeds for hate and misinformation, an increasing number of voices, including Republicans, are advocating for changes to the law.  Trump also attacked Twitter's \"Trends\" section, saying it has \"absolutely nothing to do with what is really trending in the world. They make it up, and only negative 'stuff'. Same thing will happen to Twitter as is happening to @FoxNews daytime. Also, big Conservative discrimination!\"  And he was still at it on Friday morning, retweeting and tweeting a spate of falsehoods.  He retweeted his own post from Thursday, which said: \"Just saw the vote tabulations. There is NO WAY Biden got 80,000,000 votes!!! This was a 100% RIGGED ELECTION.\"  There is no evidence of widespread election fraud. Joe Biden received 80,026,721 votes. Twitter quickly added a label to the tweet that said, \"This claim about election fraud is disputed.\"  Even as key states certify election results indicating — as national news networks have reported — that Joe Biden will be the next President, Donald Trump continues to spread baseless claims of voter fraud on Twitter. On Tuesday, Trump reposted a tweet from a user falsely claiming that “fake Biden votes”  were uncovered in Arizona.  “Report: 6K fake Biden votes found in Arizona ‘lead’ drops to 4K,” the Twitter user posted, later adding a screenshot of the pro-Trump outlet One America News Network with the same “report” in text running along the bottom of the screen.  The report, however, is absolute bunk, and the Tweet has been labeled as \"disputed\" by Twitter. The claim appears to refer to a temporary tally change that occurred in the unofficial election results because of an uploading issue with one county’s results, according to election officials. A tweet from Arizona’s Secretary of State Katie Hobbs clarified the issue hours before the claim was posted. “Unofficial election results were displaying incorrectly briefly today due to an uploading error that posted Greenlee County's results multiple times while uploading write-in candidate info,” she posted on Twitter Tuesday. “The error has been corrected.” Garrett Archer, a data analyst for ABC15 in Arizona, also posted about the uploading error on Tuesday, noting in a follow-up tweet that “Stuff like this happens from time to time. No, the results didn't change.”  Archer’s original tweet flagging the issue has been incorrectly used by many Trump supporters to falsely allege fraud in the Arizona election. Arizona will certify its election results on November 30. Biden currently holds a narrow margin of more than 10,000 votes. ##Election## ##Twitter## ##Trump## Few holidays underscore America's unhealthy info diet more than Thanksgiving. While this year's holiday will certainly be different, and hopefully gatherings will be kept small or scrubbed entirely to limit the health risk, my suspicion is that in one way or another, this will prove true yet again, either through Zoom gatherings or at in-person dinners. In fact, fresh off the heels of a heated election and amid a surging pandemic, it might even prove to be worse than usual. I suspect that quite a few families will have relatives who believe that the election was rigged or stolen. Other families might encounter members who refuse to wear masks or abide by other safety protocols. And some might see their loved ones espouse QAnon-related rhetoric. Certainly, Fox News and talk radio certainly play a role in this. There is no question about that. But social media platforms such as Facebook and YouTube also factor heavily into the equation. Not only do these platforms empower bad faith and dishonest actors, but they algorithmically encourage them. These sites were once places that you'd sign on to and see some family photos or a funny viral video. Now, they're both loaded with disinformation and hyper-partisan rhetoric that circulates and influences the people we care most about. Read more here One America News Network, one of President Trump’s favorite media outlets, has been banned from posting new videos to YouTube for a week for spreading Covid-19 misinformation, YouTube said on Tuesday. News of the temporary ban was first reported by Axios.  \"After careful review, we removed a video from OANN and issued a strike on the channel for violating our Covid-19 misinformation policy, which prohibits content claiming there’s a guaranteed cure,\" Ivy Choi, a YouTube spokesperson, told CNN in a statement. \"Additionally, due to repeated violations of our Covid-19 misinformation policy and other channel monetization policies, we've suspended the channel from the YouTube Partner Program and as a result, its monetization on YouTube,” Choi added. OANN, which has become a hub of conspiracy theories undermining the integrity of the election, is also carried by major cable operators, including DirecTV, which is owned by CNN’s parent company AT&T.  CNN has reached out to OANN for comment. ##YouTube## ##Coronavirus## A few weeks before the election, I went to a meeting of QAnon fanatics in Scottsdale, Arizona. The groupthink there: President Trump was not only going to win the election — he was going to win it in a landslide. Anything other than that result would be evidence of mass election fraud. That, of course, didn't happen. And on Monday evening the Trump administration green-lit the transition to the Biden presidency. But for some Trump supporters, especially those who believe in QAnon conspiracy theories either knowingly or not, that move is meaningless. For three weeks they've been clinging to the idea that a miracle was coming, that Trump would emerge victorious and liberals would be left in tears. They haven't changed their minds yet. Read more here ##QAnon## As false claims of voter fraud continue to spread on Twitter, the company will expand its labeling efforts once again. Now Twitter will warn users that a tweet potentially contains misinformation before they can like it. The new warning will pop up when users press like on a tweet that has been labeled as potentially false or misleading. For example, trying to like a Tuesday morning tweet from President Donald Trump baselessly alleging election fraud produces a warning that says \"This claim about election fraud is disputed\" and offers a link to more information. From there, users can proceed to like the tweet.   “Giving context on why a labeled Tweet is misleading under our election, COVID-19, and synthetic and manipulated media rules is vital,” Twitter said in a tweet sent from its Support account on Monday. The move follows an effort before the election to warn users of disputed information before they retweet certain posts. \"These prompts helped decrease Quote Tweets of misleading information by 29%, so we're expanding them to show when you tap to like a labeled Tweet,\" the Twitter account added. Twitter previously said it had applied contextual labels to about 300,000 tweets for content that was disputed or potentially misleading during a two-week period covering the election.  In a press conference Thursday, President Donald Trump’s personal lawyer, Rudy Giuliani, claimed to have evidence of voter fraud in Michigan based on sworn affidavits from four individuals. According to Giuliani, those four affiants reported seeing \"thousands and thousands\" of Biden ballots in what appeared to be a food truck hauled into the Detroit, Michigan polling center at 4:30 a.m after all Republican inspectors had left the site.    \"What they swear to is that at 4:30 in the morning a truck pulled up to the Detroit center where they were counting ballots. The people thought it was food so they all ran to the truck. Wasn't food. It was thousands and thousands of ballots,\" Giuliani said.     Facts First: A Michigan judge ruled that such affidavits claiming widespread voter fraud were baseless.    In a ruling on November 13, Judge Timothy Kenny of the Third Judicial Circuit Court of Michigan invalidated the affidavits Giuliani mentioned. The judge ruled that the claims regarding the nature and quantity of the ballots were speculations at best and sinister at worst.  Republican challenger Andrew Sitto implied the \"tens of thousands of ballots\" he saw cast for former vice president Joe Biden were proof of fraud, but the judge considered those ballots \"not surprising.\"   \"It is not surprising that many of the votes being observed by Mr. Sitto were votes cast for Mr. Biden in light of the fact that former Vice President Biden received approximately 220,000 more votes than President Trump,\" Judge Kenny wrote in his ruling.  Sitto also suggested that the batch of ballots referenced previously were somehow different because they were brought in through the back from vehicles with out-of-state license plates.   State Elections Director Christopher Thomas, who was present at the TCF Center in Detroit where ballots were being counted, refuted the allegations in an affidavit submitted to the judge and cited in the ruling. According to the judge’s ruling, Thomas stated that all ballots delivered to the center were brought in through the back and that Detroit employed out-of-state rental trucks to deliver them.  President Trump was apparently duped by a Twitter account purporting to be his older sister Elizabeth Trump Grau.  On Friday morning Trump shared an article on Twitter from right-wing site WayneDupree.com about a Twitter account supposedly belonging to his sister, and thanked her for her public support. The article claimed Trump Grau had issued a \"rare and bold statement\" on the election and that it \"prove[d] how much she believes in her brother.\" However, the article was based on tweets from a Twitter account which, according to the account itself, is a parody not actually belonging to Trump's sister. \"I would've clarified sooner that I was a parody but I certainly didn't anticipate President Trump himself taking notice of the account ... it's on me for not making that clear,\" the account wrote in a tweet later Friday.  A Twitter spokesperson said it suspended the account on Friday afternoon for violating its rules on platform manipulation and spam. Vice News reported that when it reached a woman who identified herself as Trump’s sister on Friday she told them, “I’m trying to delete it,” and “I don’t even belong to Twitter.” The article the President shared has been updated with a note that says: \"While this has not been officially “fact-checked” by social media executives and professionals, we’re hearing from many others that this is not actually the account of Ms. Elizabeth Trump, but is actually a parody account. If this is true, we deeply regret the error and apologize.\" The White House did not immediately respond to a request for comment.  After yesterday’s wild and fact-free press conference from President Donald Trump’s legal team, it’s clear that the campaign’s efforts to cast doubt and confusion over election results won't die down anytime soon.  One way Trump and his allies have tried to prove their baseless allegations of widespread  fraud is by claiming that thousands and thousands of dead people were on states' voter rolls across the country. CNN has already debunked viral allegations of dead people voting in Michigan and Georgia, two states which Trump won in 2016 and lost in 2020. The President and his allies have made similar efforts in Pennsylvania, where they’ve claimed that the identities of several deceased individuals were used to cast ballots in this election.  Laura Humphrey, a spokesperson for Pennsylvania’s Secretary of State told CNN, “There is no factual basis” for those claims and noted “[a]llegations of fraud and illegal activity have been repeatedly debunked and dismissed by the courts.”  On Wednesday, Trump escalated this narrative of voter fraud in Pennsylvania. The President tweeted a quote he attributed to the pro-Trump outlet One America News Network, which alleged tens of thousands of dead people were on the commonwealth’s voter roll.   “'Evidence of voter fraud continues to grow,” Trump’s tweet reads, “including 20,000 dead people on the Pennsylvania voters roll and many thousands all over the Country. Now, there has been an artificial number of votes in favor of Joe Biden.’”  Twitter attached a label to the tweet that says, \"This claim about election fraud is disputed.\" In October, the Public Interest Legal Foundation, which describes itself as an election integrity non-profit firm, filed a lawsuit in Pennsylvania federal court alleging that the state’s voter rolls included nearly 21,000 dead people.  The case was dismissed five days later on October 20. PILF then filed an amended lawsuit on Nov. 5 alleging that the state wasn’t properly maintaining its voter rolls. The secretary of state filed a motion to dismiss this week. “The original complaint was brought before a federal court -- and soundly rejected. The court found no deficiencies in how PA maintains its voter rolls, and the plaintiffs have no new allegations that any deceased person voted in the 2020 election,” Attorney General Josh Shapiro told CNN in an email. Facebook confirmed on Thursday that it took down a large private group dedicated to anti-vaccine content.  The company said the group was flagged for violating its policies on recidivism -- which stops group admins from creating another group similar to the one the company removed -- as well as violating its policies against QAnon.  NBC News previously reported on the anti-vaxxer Facebook group, which it reported played up stories of vaccine deaths and targeted grieving mothers. Still, plenty of anti-vaxxer groups remain on Facebook. A cursory search by CNN Business found at least a dozen Facebook groups advocating against vaccines, with membership ranging from a few hundred to tens of thousands of users.  One group dedicated to stories about supposed “injuries” after vaccines has nearly 50,000 members. For example, one woman linked her childhood vaccinations to her later having seizures, hearing loss, wild mood swings and vision problems. In their descriptions, these anti-vaxxer groups include false and dangerous claims that vaccines aren’t effective and some push conspiracy theories about impending Covid-19 vaccine. Public health experts say vaccines are extremely safe, and serious adverse reactions are very rare. Scientists have repeatedly and consistently debunked the most common anti-vaccine myth, the idea that there is a link between vaccinations and the development of autism in children. Reputable organizations such as the American Medical Association and the American Academy of Pediatrics say that vaccination for children is crucial to public health. Facebook groups related to vaccines all have an information box from Facebook that says: “This Group Discusses Vaccines. When it comes to health, everyone wants reliable, up-to-date information. Before joining this group, you might be interested in information that can help answer questions you may have about vaccines. Visit the website for the Centers for Disease Control and Prevention.” In a wild, tangent-filled and often contentious press briefing led by President Donald Trump's personal attorney Rudy Giuliani, the Trump campaign's legal team laid out its case for widespread voter fraud in the election. The roughly 90-minute briefing was overflowing with falsehoods and conspiracy theories. At no point did Trump's legal team offer any proof for their allegations of widespread fraud. Jenna Ellis, a legal adviser for the campaign, said the group was laying out an \"introductory statement\" with more to come, and called the team an \"elite strike force.\" Also working for the campaign, attorney Sidney Powell made extreme, baseless claims about communist Venezuela and George Soros supposedly interfering in the US election. Giuliani on multiple occasions made allegations citing individuals he said couldn't be revealed for their own safety and wellbeing. Many of their specific claims have already been refuted by federal election security experts and a wide, bipartisan array of election administrators across the country. Read more here The Georgia recount for the presidential election, which was scheduled to end yesterday, is expected to confirm Joe Biden's win and find no widespread fraud. But that likely won't be enough to stop President Donald Trump from spreading disinformation about the results. Throughout the recount, Trump has continued to tweet out falsehoods around Georgia ballots and his campaign has followed suit. On Wednesday, the Chairman of the Georgia Republican Party David Shafer tweeted that someone monitoring the recount found a \"9,626 vote error in the DeKalb County hand count,\" giving Biden 10,707 votes instead of the correct number of 1,081 votes.\" He also claimed the \"error\" could have given Biden's numbers a significant boost in the closely-contested state had it not been caught. The Trump campaign retweeted the post, feeding Trump's narrative that the recount is a \"joke\" and rife with fraud. Within hours, Twitter added a label to Shafer's tweet saying, \"this claim about election fraud is disputed,\" because it violated the company's civic integrity policy. Facts First: These claims are misleading and need context. State election officials say the county accurately reported its results after Election Day but that there was a mistake made during this week's recount. The error was caught, officials say, and was never at risk of affecting the vote totals reported for either Biden or Trump. Read more here William Hartmann, a Republican member of the Wayne County Board of Canvassers, who temporarily blocked certification of election results in the Michigan county on Tuesday, has recently shared conspiracy theories about the election and Covid-19 on Facebook, CNN has found. He also shared racist posts about President Barack Obama during his presidency.  Read more here Twitter launched its own version of disappearing posts this week, called Fleets, to some fanfare (and eye rolls). But it's had to pause the rollout as the feature has been plagued with glitches, calling into question whether the product was fully ready.  Unlike typical tweets, Fleets do not receive retweets, likes or public replies, with Twitter hoping they will reduce the pressure many people feel on social media. But ephemeral content will bring fresh challenges for Twitter, such as how it will effectively moderate misinformation, harassment and abuse on content that disappears after 24 hours.  The timing of Twitter's launch is curious – not only because it's adopting \"stories\" so many years after rivals – but also as it comes in the wake of a contentious election in the US. Ahead of the election, Twitter made several changes to its platform and created new policies to try to minimize the harmful impacts of misinformation. Though Joe Biden has been projected President-elect, that hasn’t curbed the flow of online misinformation or baseless claims of voter fraud, which are being pushed  by President Trump and his allies on Twitter.  The company said it labeled about 300,000 tweets for content that was disputed or potentially misleading during a two-week period covering the election, and its aggressive efforts to provide context on such content continue. How effectively and consistently Twitter will tackle misinformation or abuse in Fleets is an open question. Twitter spokesperson Aly Pavela said Fleets will be subject to the same rules as regular tweets. For example, if President Trump decides to Fleet misinformation, the Fleet would receive a similar fact-check label as a tweet would.  Twitter will rely on user flags to manage abuse on Fleets, as well as its automated systems. Users can report a Fleet as abusive or harmful, misleading about a political election or other civic event or say it expresses intentions of self-harm or suicide.  Extremism researcher Marc-Andre Argentino experimented with sharing a variety of misinformation and hateful content in Fleets, and most were not marked with a warning label.  For example, a Fleet that falsely said \"Vaccines don't work\" and one containing an untrue conspiracy theory about Covid-19, were left untouched. Meanwhile, Argentino's Fleet saying \"5g causes covid\" -- another baseless conspiracy theory -- had a warning before it.  The warning label said: \"Some or all of the content shared in this Fleet conflicts with guidance from public health experts regarding COVID-19.\" Users had to click through the warning before viewing the Fleet.  It's unclear why Twitter took action on the latter conspiracy theory, but not the former. Twitter's lengthy policies about Covid-19 misinformation say: \"We will continue to remove demonstrably false or potentially misleading content that has the highest risk of causing harm.\"  \"We are always listening to feedback and working to improve Twitter to make sure it’s safe for people to contribute to the public conversation,\" Pavela said. \"We’ll take enforcement action against any Twitter rule violations in Fleets accordingly.\" It's worth noting a lot of content beyond Fleets goes unmoderated on Twitter, even when it violates its rules, but because Fleets disappear so quickly, it will likely be harder for the company to take action fast enough. The company said its systems will store Fleets for a limited amount of time past their 24 hour expiration to give it more time to review user flags and potentially take action. However, by that point it would be too late to label misinformation.  There are also other concerns with Fleets raising questions about whether the product was ready to be fully rolled out. Beyond general glitches and lag, there is a loophole which allows someone to tag you in a Fleet even if you've blocked them, opening the door for potential harassment. (Twitter said it's working to fix this).  Late Wednesday, Twitter said it was \"slowing down\" the rollout of Fleets to fix \"performance and stability problems.\"  When asked on a call with reporters earlier this week about how the company will approach moderation as it rolls out Fleets and tests new audio-focused features, Christine Su, senior product manager at Twitter said: “It’s really important for us to be building controls and features that people can take with them to feel more comfortable and safe as they move through the variety of spaces that we’re building.” She added that the company is doing “a ton” behind the scenes with expanding its rules and policies to prevent abuse and harassment before it happens, although she didn’t elaborate further. “We’re going to continue to do that with every space that we’re working on,\" Su said.  President Donald Trump continues to baselessly claim that the election results will shift in his favor in Georgia, where the state plans to announce the results of the statewide audit around noon on Thursday.  Trump baselessly claimed the results would change after signature matching in a tweet and made accusations of widespread fraud, despite no credible evidence, in another tweet, both aimed at Gov. Brian Kemp, a Trump ally. But Georgia Secretary of State Raffensperger told CNN’s Jake Tapper Wednesday that once the audit ends, he believes Biden will carry the state and that they have “not seen widespread voter fraud.” The Republican leader also intimated that Trump lost Georgia because he questioned the mail-in ballot process in the fall, saying: “24,000 Republicans that actually voted absentee in the June primary did not come out in the Fall and vote. They did not vote absentee nor did they vote in early voting or the day of the election. 24,000… that’s the margin right there.” The Secretary of State plans to post county-by-county tallies with timestamp, so the public can view the results of the audit. Georgia’s voting systems implementation manager Gabriel Sterling said that the state has finished auditing virtually all ballots from the presidential race. About 5 million Georgians voted. The Secretary has until Friday to certify the results. Trump would have two business days after state certification to ask for a recount. Trump called on Georgia Gov. Brian Kemp to “get it done!” Trump tweeted: \"Thousands of uncounted votes discovered in Georgia counties. When the much more important signature match takes place, the State will flip Republican, and very quickly. Get it done! @BrianKempGA In a separate tweet, he said: \"Almost ZERO ballots rejected in Georgia this election. In years past, close to 4%. Not possible. Must have signature check on envelopes now. Very easy to do. Dems fighting because they got caught. Far more votes than needed for flip. Republicans must get tough! @BrianKempGA\" As of 10:30 am ET on Thursday, neither tweet was labeled by Twitter.  William Hartmann, a Republican member of the Wayne County Board of Canvassers, who temporarily blocked certification of election results in the Michigan county on Tuesday, has recently shared conspiracy theories about the election and Covid-19 on Facebook, CNN has found. He also shared racist posts about President Barack Obama during his presidency.  On Tuesday, he was one of two Republicans on the four-person Wayne County bipartisan canvassing board to temporarily block certification of votes based on dubious claims of voting irregularities in Detroit. The initial vote against certification drew the attention of the President, who posted a series of tweets praising the GOP members of the canvassing board for \"having courage.\"  After a few hours, however, Hartmann and his Republican colleague voted to certify the votes.  On Saturday, November 7th, the day major news outlets projected Joe Biden President-elect, Hartmann posted on Facebook, “I'm reading the news on how great things are now that Biden and Harris are in as declared by the MSM. What will happen if it doesn't happen once the official results are tallied? I wouldn't sell the farm yet.”  Later that day, he wrote, “I’m not really one to promote conspiracy theories” but told his Facebook friends to look up “hammer and scorecard” a conspiracy theory that has been widely debunked but did go viral after the election.  On November 9th, Hartmann furthered a conspiracy theory pushed by some Trump supporters that suggested the timing of the announcement of a Covid-19 vaccine was politically-motivated. “As predicted: Not even a week after the election and they've now got a covid vaccine that's 90% effective.” CNN has reached out to Hartmann for comment through social media, email and though phone numbers listed as being associated with him. In October, he shared a link to an OAN video that pushed a widely debunked conspiracy theory that claims hospitals are inflating the Covid-19 death-toll by falsely reporting deaths from the virus.  “Eye Opener. Do the math. How much were Hospitals overpaid by falsely reporting?” Hartmann wrote.  That post was labeled as false by Facebook’s fact-checkers. Hartmann has shared multiple videos from OAN on Facebook over the past few weeks. OAN is a conservative cable network that the President has been promoting heavily in recent days as it continues to share misinformation undermining the integrity of the election.  The relevance of Hartmann’s Facebook posts in light of the deadlock in Michigan were flagged earlier on Twitter by Del Quentin Wilber, a reporter for The Los Angeles Times.  When President Obama was in office, Hartmann’s shared a series of racist posts about the President on Facebook that were still online on Wednesday. The images in the posts equated Obama to a criminal and an Islamic terrorist. Facebook removed one of the posts – which equated Obama to an Islamic terrorist – after the company was contacted by CNN on Wednesday. Facebook spokesperson Andy Stone said the post was removed under Facebook’s hate speech policies. The company did not immediately provide comment about the other posts.  CNN's Mi Seon Lee contributed reporting Facebook and Twitter have faced immense scrutiny for their content moderation practices and efforts to clamp down on disinformation, including at Tuesday's Senate Judiciary Committee where the CEOs of both companies were questioned for over four hours.  But another big tech rival grappling with many of the same issues has been relatively absent from the conversation.  \"Google has been given a pass from today's hearing,\" Senator Richard Blumenthal of Connecticut said on Tuesday. \"It's been rewarded by this committee for its timidity, doing even less than [Facebook and Twitter] have to live up to its responsibilities.\" Google-owned YouTube was criticized for not doing enough to deal with misinformation during the election, applying a far less aggressive strategy than Facebook or Twitter did. The video platform placed an information panel at the top of search results related to the election, as well as below videos that talked about the election, but allowed some videos containing misinformation to stay online without labeling or fact-checking it. Blumenthal argued that tech companies have only taken \"baby steps\" to combat harmful misinformation on their platforms. Google did not immediately respond to a request for comment on Blumenthal's remarks. This isn't the first time Google has escaped — or avoided — scrutiny from lawmakers, though CEO Sundar Pichai did testify alongside his counterparts from Facebook and Twitter last month.  Back in 2018, the Senate Intelligence Committee set up an empty chair with a placard for Google next to Twitter CEO Jack Dorsey and Facebook COO Sheryl Sandberg during a hearing about foreign use of social media to influence US politics, in a swipe at the company's refusal to offer up Pichai or another high-level executive to testify. President Donald Trump continued to baselessly claim he won the election, re-upping the assertion in an all-caps tweet, on Wednesday morning. “...AND I WON THE ELECTION. VOTER FRAUD ALL OVER THE COUNTRY!” he wrote, along with a link to a New York Times story that said he received 10.1 million more votes across the US than he received four years ago.  That may be true, but amid unprecedented turnout, Joe Biden won by well over 5 million votes. And there is no credible evidence of widespread voter fraud.  More misinformation from Trump in morning tweets: Trump continued to spread more blatant misinformation on Twitter Wednesday morning, and multiple tweets have been flagged by Twitter. Press Secretary Kayleigh McEnany said Trump is too “hard at work” to spend Thanksgiving at Mar-a-Lago. He’s been bunkered at the White House with no public events firing off tweets, 12 as of 1:20 pm ET. For example, Trump tweeted: \"THEY WOULD’NT [sic] LET REPUBLICAN POLL WATCHERS INTO THE COUNTING ROOMS. UNCONSTITUTIONAL!!!\" The tweet is presumably referring to Pennsylvania, where the commonwealth’s Supreme Court ruled 5-2 that a Trump campaign ballot processing observer in Philadelphia had no right to stand any particular distance away from election workers, and it's up to counties to decide where poll watchers can stand. This claim on the Georgia recount, Twitter says, is disputed. Trump tweeted: \"The Georgia recount is a joke and is being done UNDER PROTEST. Even though thousands of fraudulent votes have been found, the real number is in matching signatures. Governor must open up the unconstitutional Consent Decree and call in the Legislature!\" Quoting a tweet on the Pennsylvania Supreme Court decision, he also writes: \"They didn’t even allow Republican Observers into the building to watch. A terrible insult to our Constitution!\" Trump also baselessly claimed the election was rigged with these false assertions: \"This was a rigged election. No Republican Poll Watchers allowed, voting machine 'glitches' all over the place (meaning they got caught cheating!), voting after election ended, and so much more!\" Twitter labeled all of the above tweets saying the claims about election fraud were \"disputed.\" President Donald Trump's campaign and Fox News host Tucker Carlson alleged last week that a vote cast by a Georgia woman named Deborah Jean Christiansen was fraudulent.  The allegation was false -- like two other voter fraud claims the Trump campaign and Carlson leveled against legal Georgia voters last week.  The campaign and Carlson said this vote was a fraud because Deborah Jean Christiansen died last year. In fact, the vote was legally cast by a living woman who also happens to be named Deborah Jean Christiansen, born in the same year and month but on a different day.  Christiansen answered the door when CNN showed up on Tuesday evening.  She said the false accusation from the Trump campaign is \"just ridiculous,\" part of an effort by a \"narcissist\" president to deny the obvious reality of his defeat. Christiansen, a retired mental health counselor who moved from Nebraska to Georgia in September, said she voted for Trump in 2016 but came to regret the decision, then voted for Joe Biden in 2020. Read more here. An elections security company has had to push back against a conspiracy theory that has been pushed by a prominent Republican congressman and two right-wing news networks despite, uh, having a lot of holes in it. As with many conspiracy theories, this one has different permutations and explanations. But the basic idea of the most extreme belief around this theory is this: The US Army or maybe the intelligence community raided (there was no raid) the Frankfurt, Germany offices of a company (that has no Frankfurt offices) that tallies all votes in US elections (it does not do any tallying of votes, much less conduct any official tally of all votes in the US, which no single company does).  Data on a server seized in that raid (no server was seized, there was no raid) showed that votes were switched (they weren't) and that Trump had secured a massive landslide of 410 Electoral College votes, winning California (which hasn't gone for a Republican since 1988 and which Hillary Clinton won by 30 percentage points in 2016) and Rhode Island (which has gone for a Republican only once since 1976) but somehow not Colorado (which was considered a swing state as recently as 2008). Read more here.  In a Senate hearing on Tuesday that stretched on for more than four hours, the CEOs of Facebook and Twitter sought to recalibrate their relationship with Congress, apologizing for past mistakes while trying to set the tone for future regulation of their industry that's expected to see a bigger push in 2021. It was the second time the CEOs had been summoned to testify in as many months. As expected, Facebook's Mark Zuckerberg and Twitter's Jack Dorsey faced their fair share of allegations by lawmakers of anti-conservative bias and failure to remove misinformation and hate speech. But this hearing lacked much of the grandstanding and attacks of the pre-election hearings. A broader theme of the hearing was to establish what responsibilities tech companies should have for moderating content, and what role the US government should play — a critical question that will inform a legislative effort on online content next year, once a new Congress is sworn in. Laying down baseline expectations for the outcome of that effort, leading members of the Senate Judiciary Committee said they did not think it's appropriate for the US government to get directly involved in online content moderation. Read more here President Donald Trump on Tuesday fired the Department of Homeland Security official who had rejected Trump's claims of widespread voter fraud. Trump announced on Twitter he was firing Chris Krebs, the director of the Cybersecurity and Infrastructure Security Agency, and directly tied it to Krebs' statement that said there \"is no evidence that any voting system deleted or lost votes, changed votes, or was in any way compromised.\" \"The recent statement by Chris Krebs on the security of the 2020 Election was highly inaccurate, in that there were massive improprieties and fraud,\" Trump said in a tweet that also repeated other baseless conspiracy theories about the election and was flagged by Twitter as \"disputed.\" \"Therefore, effective immediately, Chris Krebs has been terminated as Director of the Cybersecurity and Infrastructure Security Agency.\" Read more here \"I WON THE ELECTION!\" President Donald Trump tweeted just before midnight on Sunday night.  Trump did not win the election. So this was a fitting conclusion to his lie-filled weekend barrage of tweets, in which he continued to invent imaginary evidence in support of his attempt to deny Joe Biden's victory.  Almost nothing Trump is saying about the election is true; Twitter affixed a fact check label to more than 30 of his election-related tweets and retweets between Friday and Monday morning.  Read here for a preliminary breakdown of just some of the false claims he made during that period. It is an internet battle cry: Stop the Steal has swept across inboxes, Facebook pages and Twitter like an out-of-control virus, spreading misinformation and violent rhetoric -- and spilling into real life, like the protest planned for DC this weekend.  But while Stop the Steal may sound like a new 2020 political slogan to many, it did not emerge organically over widespread concerns about voting fraud in President Donald Trump's race against Joe Biden. It has been in the works for years.  Its origin traces to Roger Stone, a veteran Republican operative and self-described \"dirty trickster\" whose 40-month prison sentence for seven felonies was cut short by Trump's commutation in July.  Stone's political action committee launched a \"Stop the Steal\" website in 2016 to fundraise ahead of that election, asking for $10,000 donations by saying, \"If this election is close, THEY WILL STEAL IT.\" Read more here.  An app called Parler is seeing a flood of new signups, particularly from conservatives as Facebook, Twitter and other social networks have stepped up efforts to crack down on misinformation and prominent conservatives have claimed their voices are being disproportionately censored. Founded in 2018 by John Matze and Jared Thomson, Parler bills itself as \"unbiased social media\" and a place where people can \"speak freely and express yourself openly without fear of being 'deplatformed' for your views,\" according to its website and App Store description. It looks like a mashup of Twitter and Instagram, with its main feed, follower counts and ways to share posts and links. It's also rife with misinformation, including a stream of baseless allegations of voter fraud, such as false assertions that \"millions\" of votes were either lost or switched from Donald Trump to Joe Biden. Those who've been active on the alternative social network in recent weeks include Fox News host Sean Hannity, radio personality Mark Levin, far-right activist Laura Loomer, Senator Ted Cruz and Congressman Devin Nunes. Eric Trump also has an account verified by Parler as does Donald Trump's presidential campaign. Parler saw an influx of downloads following the US election. The app hit the number one spot overall on Apple's US App Store among free apps for the first time on Sunday -- ahead of names including TikTok and YouTube -- according to Apptopia which tracks mobile apps. Since last Friday, more than 4.5 million new people signed up for accounts, according to a letter from Parler CEO Matze.  But it's not just Parler that's getting a boost. The app of right-wing media outlet Newsmax has climbed the app charts recently and other social apps like MeWe and video-sharing platform Rumble are also gaining steam, both of which promise not to clamp down people's voices. Read more here.  A human error that briefly led to incorrect election results in a Michigan county has spiraled into a sprawling, baseless conspiracy theory suggesting that glitches in widely-used voting software led to millions of miscast ballots. Conservative media figures, social media users, and President Donald Trump have spread rumors about problems with Dominion Voting Systems, an election technology company that supplies software to many local governments. They've claimed that isolated reports about Election Night glitches raise concerns about election results in states around the country. \"DOMINION DELETED 2.7 MILLION TRUMP VOTES NATIONWIDE,\" Trump tweeted on Thursday, citing a report from the right-wing One America News Network. Without showing any evidence, he claimed that states using the company's technology had \"SWITCHED 435,000 VOTES FROM TRUMP TO BIDEN.\" Facts First: Trump's tweet is completely without evidence. There have been no credible reports that any issues with Dominion's technology affected vote counts. While one Georgia county experienced delays reporting its results due to apparent problems with the company's systems, other isolated issues that were allegedly connected to Dominion were actually caused by human error. Read more here Twitter said it applied contextual labels to approximately 300,000 tweets for content that was disputed or potentially misleading during a two-week period covering the election. The figure comes as part of a wider post-mortem assessment of the company's handling of political misinformation before and after Election Day. Twitter has witnessed a wave of misinformation as users including President Donald Trump — who has nearly 89 million followers — and his allies have spread false and misleading claims about the election and its outcome. As of the morning of November 7, 16 out of 43 of Trump's post-election tweets had been labeled. In addition to the labeling, Twitter said more than 450 of those tweets were also covered up by a warning message and were subject to sharing restrictions that limited how they could be retweeted. Roughly 3 out of 4 people who viewed those tweets did so after the labeling was applied, Twitter said in a blog post. The analysis focused on tweets about the US election from Oct. 27 to Nov. 11. \"We also want to be very clear that we do not see our job as done — our work here continues and our teams are learning and improving how we address these challenges,\" wrote Vijaya Gadde and Kayvon Beykpour, who respectively lead Twitter's legal and product teams. \"We'll be sharing a comprehensive report on the election early next year.\" The disclosure comes as Twitter rolls back certain preemptive policies that it put in place ahead of Election Day. Twitter said it found that removing recommendations to users for who they ought to follow had little meaningful impact on misinformation during the election, and the company will undo that change on Thursday. The company said it will also relax some of the restrictions surrounding what trending topics users may see under a curated tab on its website labeled \"For You.\" During the election, Twitter said, only topics that provided additional in-line context were permitted in that section of the site. That change is also being reversed. One election-related change that Twitter will be keeping going forward is an extra screen prompting users to quote tweet content instead of retweeting it. Twitter said its data showed that the limitation reduced sharing via quote tweets and retweets by 20%, and that it \"slowed the spread of misleading information by virtue of an overall reduction in the amount of sharing on the service.\" The company said it will continue to study the impact of the change and may revisit it in the future. Twitter did not immediately respond to CNN's request for data on how long it generally took Twitter to apply a label to misinformation, nor which accounts were primarily responsible for posting the tweets that ultimately got flagged. President Donald Trump wrongly claimed a video that showed election workers collecting legally cast ballots in Los Angeles the day after the election showed evidence of fraud. \"You are looking at BALLOTS,\" the President claimed in his video caption. \"Is this what our Country has come to?\" A woman heard in the video asks the workers why they are collecting the ballots when \"they already called the state.\" Facts First: This is the latest false insinuation -- and another baseless claim -- of mail-in voting fraud by Trump. The suggestion by the President is that the video shows ballots being collected in California a week after the election. But the video, originally posted on November 4, shows workers collecting legally cast ballots from a ballot box that the LA County Registrar says had been locked since election night. Read more here Before the election, much of the anxiety concerning misinformation on social media focused on Facebook and Twitter, amid worries that President Donald Trump could use his megaphone on those platforms to contest the election results.  But in the wake of Election Day, it’s YouTube that has emerged as one of the most troubling sources of misinformation.  CNN, The New York Times, Bloomberg and The Washington Post have all highlighted viral examples in recent days of misleading YouTube videos that question the election outcome. Much of the content is being spread by social media influencers with large followings; experts including former Facebook chief security officer Alex Stamos have said that social media power-users have played a key role in post-election misinformation ecosystems, because they can lift claims out of obscurity and “harden” them as part of a wider narrative. Like other platforms, YouTube seeks to elevate authoritative information and labels and demotes misleading content. But YouTube is different from Facebook and Twitter in that its primary format is video — a highly engaging medium where visuals can easily overpower YouTube’s gentle text-based reminders that the Associated Press called the race for Joe Biden. And video is much more difficult for automated systems to analyze than text or static images, which makes finding problematic content more challenging. The situation is also potentially exacerbated by YouTube’s own policies, which prohibit misinformation about how to vote but not about election results or ballot counting. It’s an enormous loophole that’s given misinformation peddlers free rein to spread the narrative that the election was illegitimate. As supporters of President Donald Trump continue to spread baseless allegations of voter fraud, a new theme is emerging in their attacks on the election's legitimacy. Widespread allegations that President-elect Joe Biden \"stole\" the election are now tinged with unfounded claims that media outlets are rescinding their calls of certain states or are changing their projections in ways that disfavor Biden. These claims are untrue. But they continue to circulate virally on social media and show how, for online platforms, the problem of misinformation is as serious as ever. In one prominent example, a YouTube video wrongly claiming Joe Biden is \"losing\" his status as US president-elect has racked up more than a million views as of Tuesday afternoon and has been shared widely in a top-performing Facebook groups devoted to politics. The main source cited by the video is a misinformed and now-removed tweet by Trump adviser Pam Bondi, who falsely claimed that the website RealClearPolitics had reversed its projection that Biden had won Pennsylvania's Electoral College votes. That claim has also been repeated by Trump's personal lawyer, Rudy Giuliani, among others. But RealClearPolitics's co-founder Tom Bevan publicly debunked the claim Monday evening. \"We never called Pennsylvania, and nothing has changed,\" Bevan tweeted. Read more here A very long election week made way for numerous fake claims to circulate on social media. From baseless assertions that thousands of deceased people in Michigan voted to a fake video of \"ballots\" burning that was shared by Eric Trump, misinformation went viral online. Here's the truth about some of the biggest misinformation stories from Election Week. Claims that dead people were voting went viral Prominent Republicans alleged that Democrats were using dead people to steal Michigan's Electoral College votes from Trump. A CNN analysis of the claim and the purported backing for it did not find a single instance of that happening. CNN examined 50 of the more than 14,000 names on the list by taking the first 25 names on the list and then 25 more picked at random. We ran the names through Michigan's Voter Information database to see if they requested or returned a ballot. We then checked the names against publicly available records to see if they were indeed dead. Of the 50, 37 were indeed dead and had not voted, according to the voter information database. Five people out of the 50 had voted -- and they are all still alive, according to public records accessed by CNN. The remaining eight are also alive but didn't vote. The sample CNN reviewed is not representative, but the trend was clear -- not a single one of the names examined was of a dead person voting. Right-wing media portrayed window covering at ballot center as nefarious Right-wing media outlets portrayed a move at a Detroit ballot-counting center as nefarious. These outlets reported on a decision by poll workers at the TCF Center in Detroit to partially cover windows with cardboard as they counted ballots inside and a group of apparent Trump supporters gathered outside. However, a city official told CNN Business that the measure at the center of controversy was taken to ensure private voter data wasn't inappropriately exposed to the public. Those concerns were compounded by the fact that protesters standing outside the ballot-counting area were taking photographs and recording video. A viral 'ballot' burning video shared by Eric Trump was fake A viral video that purports to show about 80 \"ballots,\" all for Donald Trump, being burned is fake, Virginia Beach city officials say. The video, which surfaced on Election Day, features a man with a plastic bag full of papers that look like ballots, which he doused with a flammable liquid and set aflame. The person, whose face is never shown, claims the 80 false \"ballots\" are \"all for President Trump\" on the video. But the ballots are not real. The city of Virginia Beach said the papers are clearly sample ballots, rather than official ballots, since they lack the \"bar code markings that are on all official ballots,\" according to a statement released last week. The statement showed an official ballot and compared it to a screenshot of the false video. Eric Trump, the President's son, retweeted the video last week. However, the account Eric Trump retweeted has now been suspended, so the video can no longer be seen on his feed. False rumors about Sharpies went viral False claims that using Sharpie pens could invalidate ballots in Arizona prompted a top Department of Homeland Security official last week to urge people to stop spreading disinformation online. Rumors began to spread on social media last Wednesday that voters in the battleground state of Arizona who used Sharpie pens on their ballots wouldn't have their votes counted, which was quickly dubbed \"#SharpieGate.\" That confusion prompted state officials, election monitors and a top Trump administration official to push on the rumors. The situation prompted a lawsuit, joined by the Trump campaign and the Republican National Committee, filed against Maricopa County election officials. A Michigan election map with false information went viral and landed in Trump's Twitter feed President Trump tweeted an image of an electoral map of Michigan that purported to show an unexplained jump overnight in the number of returned ballots in the state. The claim: According to the data in the map, 138,000 ballots had come in out of nowhere, and all of them were for Biden. The image was real. But the idea that it indicated fraud was absolutely false, though the people sharing it likely initially did not know that the data in the map was wrong. The image was a screenshot of a map on the website Decision Desk HQ, which tracks election results and has powered results data for media outlets like BuzzFeed News. After Trump's tweet on Wednesday, Decision Desk HQ said there had been an error in the data it had been sent from Michigan's Shiawassee County. \"Once we identified the error, we cleared the erroneous data and updated it with the correct data as provided by officials,\" Decision Desk HQ said in a statement to CNN. CNN's Konstantin Toropin, Holmes Lybrand, Annie Grayer, Donie O'Sullivan, Oliver Darcy, Mallory Simon, Geneva Sands, Bob Ortega, Ashley Fantz and Kara Scannell contributed reporting. Harrisburg, Pennsylvania — In the capital of Pennsylvania — the state that ultimately tipped the election in favor of President-elect Joe Biden — supporters of President Donald Trump gathered to protest the election result this weekend. The past four years in America have been an education in how grievances and misinformation on social media don't just stay online — they spill out onto the streets, can manifest as violence, and, as seen in Harrisburg, this weekend, be used in attempts to undermine the bedrock of American democracy: free and fair elections. Trump supporters here gathered under the banner \"Stop the Steal,\" convinced the election had been stolen. One woman told me she had seen so much \"evidence\" that the election had been rigged she would support a total re-vote. \"When you have video footage of people taking bags of ballots and showing that they are for Donald Trump and lighting them on fire,\" she said, \"there's a problem.\" But the video she cited as evidence of a rigged American election is not real. Read more here To hear some people tell it -- including a handful of prominent Republicans, such as members of President Trump's family and supporters like former House Speaker Newt Gingrich and former acting Director of National Intelligence Richard Grenell -- you might think that Democrats were using dead people to steal Michigan's Electoral College votes from Trump. But, like much of the misinformation circulated online this week by some Trump supporters, the claim falls apart under scrutiny. A CNN analysis of the claim and the purported backing for it did not find a single instance of that happening. One of the supposed pieces of evidence was a list that circulated on Twitter Thursday evening allegedly containing names, birth dates, and zip codes for registered voters in Michigan. The origin of the list and the identity of the person who first made it public are not known. CNN examined 50 of the more than 14,000 names on the list by taking the first 25 names on the list and then 25 more picked at random. We ran the names through Michigan's Voter Information database to see if they requested or returned a ballot. We then checked the names against publicly available records to see if they were indeed dead. Of the 50, 37 were indeed dead and had not voted, according to the voter information database. Five people out of the 50 had voted -- and they are all still alive, according to public records accessed by CNN. The remaining eight are also alive but didn't vote. The sample CNN reviewed is not representative, but the trend was clear -- not a single one of the names examined was of a dead person voting. Read more here Twitter will no longer hide false or misleading tweets about US election results behind warning labels, as it did with several of President Donald Trump’s tweets this week.  “With the election now called by multiple sources per our public guidelines, we will no longer apply warnings on Tweets commenting on the election outcome,” a Twitter spokesperson said in a statement.  Twitter labeled more than a third of Trump’s tweets since polls closed on Tuesday evening, hiding them behind warnings that stated “some or all of the content shared in this Tweet is disputed and might be misleading about an election or other civic process” and forcing users to click through to view the tweet.  While those warnings will remain up, they will not be applied to any new tweets.  Aside from hiding offending tweets behind warning labels, Twitter had restricted how such tweets could be shared, including removing replies and likes, and only allowing users to quote tweet — which allows users to share a tweet with their own comments attached — rather than retweet.  Those restrictions will no longer apply to new tweets, the spokesperson confirmed.  Twitter continues to place labels on some tweets. “This claim about election fraud is disputed,” read a label appended to Trump’s tweet earlier on Saturday that claimed “observers were not allowed into the counting rooms” and “millions of mail-in ballots were sent to people who never asked for them.”  “We will continue to apply labels to provide additional context on Tweets regarding the integrity of the process and next steps where necessary,” the spokesperson added.  Trump is still protected from some of the more stringent actions Twitter might take against general users — such as removal of tweets — because of his status as a world leader. Twitter’s public interest policy states that it will allow tweets from elected and government officials to stay up “given the significant public interest in knowing and being able to discuss their actions and statements.” Trump’s personal account will lose those protections on January 20 when he leaves office. (Official accounts such as @POTUS and @FLOTUS are taken over by the new administration when there is a change in power.) “Twitter’s approach to world leaders, candidates, and public officials is based on the principle that people should be able to choose to see what their leaders are saying with clear context,\" the spokesperson said. \"This policy framework applies to current world leaders and candidates for office, and not private citizens when they no longer hold these positions.\" Social media platforms quickly updated their websites and apps to reflect projections of Joe Biden’s election victory Saturday morning.  Within minutes of the race being called by national news outlets, Facebook updated its voting information center with a post identifying Biden as the winner. Instagram and Facebook both now show a box near the top of the feed that says \"A Presidential Winner Has Been Projected. Joe Biden is the projected winner of the 2020 US Presidential Election.\"  Twitter has added labels it is appending to new election misinformation, with language that reads \"official sources called this election differently.\" Clicking through on the label directs users to a page describing Biden as the winner.  On tweets posted prior to the projection of Biden's victory, such as President Donald Trump’s tweet on Saturday falsely claiming victory, the label reads that \"official sources may not have called the race when this was Tweeted\" and also links to the page describing Biden's win. YouTube updated its label on election-related videos, too. It says: \"The AP has called the Presidential race for Joe Biden. See more on Google.\"  Twitter has applied warning labels to more than a third of President Donald Trump’s tweets since the final polls closed Tuesday evening, reflecting how Trump and his allies continue to spout misinformation on social media days after Americans cast their ballots. As of 10 a.m. Eastern on Saturday morning, 16 out of 43 Trump tweets, or 37%, had been labeled by Twitter cautioning users that “some or all of the content shared in this Tweet is disputed and might be misleading about an election or other civic process.” That figure does not begin to capture the overall universe of Trump allies and family members, many of whose own posts on social media have also been labeled by online platforms. A top election security official reiterated Friday that the Department of Homeland Security and its cyber arm do not print or audit ballots, debunking unverified reports circulating online claiming the agency detected millions of counterfeit ballots while monitoring results. “Contrary to #disinfo floating around, CISA doesn’t print or audit ballots! We offer cyber support to state and local elex officials. Don’t fall for these efforts to confuse and undermine confidence in the election,” Chris Krebs, director of DHS’ Cybersecurity and Infrastructure Security Agency, tweeted.  Krebs linked to the agency’s “Rumor vs. Reality” page which states:  Reality: The Department of Homeland Security (DHS) and the Cybersecurity and Infrastructure Security Agency (CISA) do not design or audit ballots, which are processes managed by state and local election officials. Rumor: DHS or CISA printed paper ballots with security measures and is auditing results as a countermeasure against ballot counterfeiting. The tweet from Krebs comes as officials continue to grapple with the flood of online disinformation in the wake of Election Day, including a variety of conspiracies about widespread fraud that have been embraced by President Donald Trump and many of his allies.  One of the false narratives that has picked up traction online in recent days claimed DHS identified a “staggering” amount of fraud identifiers on votes in support of former Vice President Joe Biden while reviewing millions of ballots coming from key states like Arizona and Michigan. The dubious online report cites a DHS press release that “is not public.” Krebs made clear Friday that this is disinformation intended to undermine the democratic process. He also pointed out that “local election offices have security and detection measures in place that make it highly difficult to commit fraud through counterfeit ballots.”   “While the specific measures vary, in accordance with state and local election laws and practices, ballot security measures can include signature matching, information checks, barcodes, watermarks, and precise paper weights,” according to the DHS rumor page posted by Krebs.  “DHS and CISA operate in support of state and local election officials, and do not administer elections or handle ballots. CISA’s role in election security includes sharing information, such as cyber threat indicators, with state and local election officials, as well as providing technical cybersecurity services (e.g. vulnerability scanning) upon the request of those officials,” it says.  Officials from Delaware County, Pennsylvania say a video circulating online that supposedly contains evidence of voter fraud has been taken out of context and is misleading.  The video, which has been shared at least hundreds of times and viewed tens of thousands of times on Twitter alone, purports to show a poll worker marking a ballot with a writing implement.   County officials called the video “manipulated” in a statement explaining that it is normal for election workers to transcribe actual votes on damaged ballots onto fresh ones to ensure that voting machines can count them accurately.   \"The video was taken from the official live stream provided by Delaware County,” said the statement from Delaware County public relations director Adrienne Marofsky. “However, the circulated video is zoomed in to crop out the surrounding area, including the bipartisan observers who were not more than six feet away and does not give the full picture of the process.” A fake Twitter account posing as the Associated Press attempted to call the presidential election for Joe Biden on Friday morning before being suspended.  The fake account, @APMyWrist, racked up hundreds of likes and retweets before it was removed. AP reporter Ken Sweet tweeted in response that the Associated Press has not called the election and urged users to follow the correct, verified AP account, @AP_Politics.   Several AP impostor accounts have sought to spread misinformation this week. One even drew a retweet from Monica Lewinsky. A sudden burst of the accounts prompted a public advisory by the Cybersecurity and Infrastructure Security Agency on Wednesday.   Twitter permanently suspended an account belonging to former White House chief strategist Steve Bannon after he suggested Thursday morning that Dr. Anthony Fauci and FBI Director Christopher Wray should be beheaded. His comments were made in a video posted to his Facebook, YouTube, and Twitter accounts. Bannon falsely claimed President Trump had won reelection, despite several key states still being too close to call, and said that he should fire both Fauci and Wray. He then said he would go further: \"I'd put the heads on pikes. Right. I'd put them at the two corners of the White House as a warning to federal bureaucrats. You either get with the program or you are gone.\" The comments came during a livestream of Bannon's \"War Room: Pandemic\" online show. The video was live on Bannon's Facebook page for about 10 hours Thursday and had been viewed almost 200,000 times before Facebook removed it, citing its violence and incitement policies. CNN has reached out to Bannon for comment. Earlier Thursday evening YouTube removed the video for violating its policy against \"inciting violence.\" Twitter said it had permanently suspended the account of Bannon's \"War Room\" podcast for glorifying violence. Bannon's comments came as other supporters of President Trump also used violent and militaristic rhetoric to back Trump's baseless claims of a rigged election and to condemn his perceived political opponents. In a tweet Thursday, Donald Trump Jr. called for his father \"to go to total war over this election.\" \"It's time to clean up this mess & stop looking like a banana republic!\" he added. Trump Jr. also repeated multiple baseless claims undermining the integrity of the election in the tweet, which was labeled by Twitter as \"disputed and might be misleading.\" During the campaign, he had touted baseless rigged-election claims to recruit an \"army\" for his dad, as CNN has previously reported. CNN has reached out to a spokesperson for Trump Jr. for comment. Read more here. Three of the top 10 hashtags used in Twitter posts about the 2020 election on Thursday promoted unsubstantiated allegations of voter fraud, according to a new report from nonpartisan nonprofit Advance Democracy. Among the hashtags were “stopthesteal”, “#mailfraud” and “#voterfraud.” On Wednesday, there were no hashtags in the top 10 referencing election fraud. While there were about 6 million fewer posts about the election on Twitter on Thursday afternoon compared to the previous day, “there has been a dramatic increase in disinformation,” the report said. A Twitter spokesperson said it has been \"proactively monitoring\" the hashtag \"#stopthesteal\" and related tweets since Tuesday morning, and it has taken down some tweets that violate its policies.  Of the 10 most shared links about the 2020 election on Twitter on Thursday, seven were to right-wing websites, per the report. The top shared links were to articles on websites including Breitbart News, The Gateway Pundit, and The Federalist. On Wednesday, there were no links to right-wing sites in the top-10 most shared links related to the election. Many of the top links were articles questioning the integrity of the Presidential election, such as one from The Federalist headlined “Yes, Democrats Are Trying To Steal The Election In Michigan, Wisconsin, And Pennsylvania.” That link was shared on Twitter by President Trump’s personal attorney Rudy Giuliani. Twitter applied a label to the tweet that read, “Learn about US 2020 election security efforts” and linked out to its Civic Integrity policy. Other tweets sharing the link to The Federalist story also had the same label applied to them.  The most shared link about the 2020 election on Thursday was to an informational page from Democrats.org explaining the extra steps voters in Georgia may need to take to fix their absentee ballot and ensure their vote is accepted. Georgia is among the states with a razor-thin margin between the presidential candidates. Followers of the QAnon conspiracy theory are still making a dent in the election conversation, too. The report found that QAnon-related accounts were responsible for almost 10% of the amplification of the hashtags “#voterfraud” & “#trump2002”, and more than 6% of the amplification of the hashtags for “#stopthesteal” and “#mailfraud”. (QAnon is a dangerous conspiracy theory and virtual cult that began in late 2017.)  In July, Twitter removed thousands of accounts linked to the QAnon conspiracy group and said it would \"permanently suspend accounts Tweeting about these topics\" and \"coordinating abuse around individual victims.\" Despite the crackdown, Advance Democracy found more than 95,200 active QAnon-related accounts on Twitter as of Thursday.  Twitter on Thursday said it has \"reduced impressions\" on QAnon-related tweets by more than 50%.  Advance Democracy is defining “posts” as tweets, retweets, quote tweets, or replies. Posts were determined to be related to the 2020 election if they included terms or hashtags like election, vote, mail-in, ballots, “#howtostealanelection”, “#voterfraud” and so on. Facebook will roll out additional, temporary measures to limit election misinformation on its platform in response to an increased number of misleading claims, the company said Thursday.  Content on Facebook and Instagram will be demoted by the company’s automated systems if the systems determine that it may contain misinformation, “including debunked claims about voting,\" Facebook spokesman Andy Stone said in a statement to CNN Business. Users will face an additional hurdle when they share posts that Facebook has labeled with further context, Stone said. Users who attempt to share labeled content will now see an additional message that encourages them to visit Facebook’s voting information center.  \"We are also limiting the distribution of Live videos that may relate to the election on Facebook,” Stone added.   “As vote counting continues,” Stone said, \"we are seeing more reports of inaccurate claims about the election. While many of these claims have low engagement on our platform, we are taking additional temporary steps, which we’ve previously discussed, to keep this content from reaching more people.”  Facebook’s head of global affairs, Nick Clegg, has previously said the company has prepared multiple “break-glass” tools and options in the event of a chaotic US election. Thursday’s announcement appears to make use of them.  The statement did not provide a timeframe for the rollout, and Facebook didn’t immediately respond to a question from CNN Business seeking clarification. But the New York Times, which was first to report the news, said that the rollout could begin as soon as Thursday.   Baseless claims of election fraud made by President Donald Trump and his allies this week have turned up the heat on tech companies, which have for years largely allowed dubious and debunked claims to thrive on their platforms.  This week, Twitter and Facebook have increasingly labeled posts that seek to undermine the validity of the election results; YouTube, however, has largely lagged behind. Detroit officials are debunking a video that falsely implies election fraud occurred when a man pulled a red wagon containing a box into a vote-counting center early Wednesday. City officials shot down the allegations made in the video in a statement to CNN on Thursday. \"There was no election equipment -- no ballots or ballot boxes -- transported in red wagons,\" city attorney Lawrence Garcia wrote. And if that wasn't enough, a local TV station said the man who appears in the video is one of their photographers and was bringing a case of camera equipment into the TCF Center, where election workers were counting votes. CNN affiliate WXYZ posted a photograph of a red gear wagon. Investigative reporter Ross Jones tweeted, \"The 'ballot thief' was my photographer.\" The video was posted with an article on Texas Scorecard, a conservative website that describes itself as a site dedicated to being \"always trustworthy, with the facts in context\" and \"relentlessly pro-citizen, unabashedly pro-liberty.\" The video has been picked up by other conservative media, and racked up millions of views. Eric Trump, Donald Trump's son, called attention to the video by tweeting a link to it on Wednesday evening. Read more here Right-wing media outlets, which have parroted President Donald Trump's dangerous rhetoric aimed at undermining the integrity of the US election, have portrayed a move at a Detroit ballot-counting center as nefarious. But a city official poured cold water on the assertions, explaining to CNN Business that the measure at the center of controversy was taken to ensure private voter data wasn't inappropriately exposed to the public. Fox News hosts sow distrust in legitimacy of election Reports from pro-Trump outlets such as Fox News, Breitbart, and The Gateway Pundit spotlighted a decision by poll workers at the TCF Center in Detroit to partially cover windows with cardboard as they counted ballots inside and a group of apparent Trump supporters gathered outside. The reports were widely shared and found their ways to large audiences. On Thursday, for instance, a Breitbart article shared by Trump had even ascended to become the top link on all of Facebook when ranked by interactions for the previous 24-hour period, according to CrowdTangle, an analytics firm owned by Facebook. The reports from right-wing outlets and personalities implied that poll workers were hiding improper activity from the public. But Lawrence Garcia, an attorney for the City of Detroit, said that the windows were partially blocked because of concern voter information could be wrongfully revealed to the public. Those concerns were compounded by the fact that protesters standing outside the ballot-counting area were taking photographs and recording video. Read more here Twitter restricted the sharing of a tweet from Donald Trump Jr. on Thursday evening in which he called for his father to “to go to total war over this election.” The tweet repeated multiple baseless claims undermining the integrity of the election and was labeled by Twitter as “disputed and might be misleading.” “It’s time to clean up this mess & stop looking like a banana republic!,” wrote Trump Jr.  During the campaign, the President’s son touted baseless rigged-election claims to recruit an “army” for his dad, as CNN has previously reported.  Twitter labeled Trump Jr.’s Thursday evening tweet with the following: “Some or all of the content shared in this Tweet is disputed and might be misleading about how to participate in an election or another civic process.” Facebook on Thursday shut down a group that had gathered hundreds of thousands of members and had been involved in coordinating protests against the legitimacy of the election.  Facebook only took action on the pro-Trump “Stop The Steal” group after it had already gone viral across its platform. Generally, the group was focused on baseless allegations of voter fraud.  “In line with the exceptional measures that we are taking during this period of heightened tension, we have removed the Group 'Stop the Steal,' which was creating real-world events,” a Facebook spokesperson said.   The spokesperson added, “The group was organized around the delegitimization of the election process, and we saw worrying calls for violence from some members of the group.\"  Fox Business anchor Maria Bartiromo tweeted several baseless claims about ballot counts in battleground states. In one tweet this morning, Bartiromo shared misinformation about an alleged dump of more than 100,000 votes in Michigan, which CNN determined was false. The claim, which was also tweeted by President Trump, originates from an electoral map of Michigan that purported to show an unexplained jump overnight in the number of returned ballots in the state. The charge: According to the data in the map, 138,000 ballots had come in out of nowhere, and all of them were for Biden. The image was real. But the idea that it indicated fraud was absolutely false, though the people sharing it likely initially did not know that the data in the map was wrong.  The image was a screenshot of a map on the website Decision Desk HQ, which tracks election results and has powered results data for media outlets like BuzzFeed News. After Trump's tweet on Wednesday, Decision Desk HQ said there had been an error in the data it had been sent from Michigan's Shiawassee County. \"Once we identified the error, we cleared the erroneous data and updated it with the correct data as provided by officials,\" Decision Desk HQ said in a statement to CNN. A clerk with the Shiawassee County Clerk's Office confirmed to CNN that that a typing error had been made when votes were being entered for Biden, and that the error was corrected within 30 minutes. Decision Desk HQ is known as a reliable source of information but it did not explain why it took hours to make a statement about the error. Bartiromo also tweeted a false claim regarding the use of sharpies invalidating ballots in Arizona. CNN reported that election officials said ballots marked with Sharpies will be counted in Arizona.   The tweet had garnered more than 50,000 likes and 30,000 retweets at the time of writing. Twitter has not labeled Bartiromo’s tweets as misinformation though the earlier tweets from others regarding the Michigan maps had been labeled as misinformation. Twitter did not immediately respond to a request for comment about the tweets. Marjorie Taylor Greene is accusing Twitter of anti-conservative censorship after the social media platform placed contextual labels on nearly two dozen of the GOP congresswoman-elect tweets since the final polls closed on Tuesday.  Greene, who won her race in Georgia, is headed to Congress as one of the country’s most visible promoters of the QAnon conspiracy theory.  As of this writing, 54% of Greene’s tweets since the election — 19 out of 31 — have been labeled by Twitter as potentially misleading. Several of the flagged tweets accuse Democrats of trying to steal the election; others target the “Fake News Media” for allegedly lying about poll numbers and vote results.  In response, Greene posted a video on Thursday to social media that showed label after label on her Twitter account.   “Twitter censored me ALL day yesterday,” she claimed. “Sign your Official STOP THE STEAL PETITION.”  Twitter declined to comment on Greene’s allegations. But the company labeled that post, too, and referred CNN to the platform's civic integrity policy which prohibits the posting of misleading information about civic processes. Greene made similar allegations on her Facebook page. After CNN inquired about the posts, Facebook added labels to some of Greene’s content. Facebook didn’t immediately respond to a request for comment. In the months leading up to the election, major social platforms issued seemingly endless updates on how they would address election-related misinformation on their platforms. Now that the election is underway, there have been major differences in the major tech platforms' approaches to moderating misinformation and impacting its spread. Twitter (TWTR) has been the most aggressive in labeling and addressing false and misleading content while Facebook and YouTube have applied a lighter touch. The three platforms have taken varying approaches. Twitter has gone as far as reducing users' ability to share misleading posts, while Facebook is slapping labels on misinformation, but not hindering sharing. YouTube is taking arguably the least aggressive action, by relying on a single label -- which reminds people that US election results may not be final -- on any and all content related to the election. Twitter has been labeling and restricting how tweets can be shared, including several from President Trump. For example, Twitter placed a label on a tweet from the President in which he baselessly claimed \"We are up BIG, but they are trying to STEAL the Election.\" \"Some or all of the content shared in this Tweet is disputed and might be misleading about how to participate in an election or another civic process,\" the label on that Trump tweet read. Twitter has also restricted how such tweets can be shared, including removing replies and likes, and only allowing users to quote tweet -- which allows users to share a tweet with their own comments attached -- rather than retweet. (Twitter is also applying other labels to tweets that, by its standards, are prematurely calling election results for either candidate. One of its labels reads: \"Official sources may not have called the race when this was Tweeted.\") On the exact same post from Trump on its platform, Facebook (FB) used vague language in its label and, unlike Twitter, didn't restrict how it can be viewed or shared. Facebook's label reads: \"Final results may be different from initial vote counts, as ballot counting will continue for days or weeks.\" By Wednesday morning it was one of the most highly engaged with posts on Facebook, according to data from Crowdtangle, an analytics company that Facebook itself owns. Read more here YouTube is letting a video containing misinformation about the election stay up on its platform without a fact-check or label noting that it is misinformation -- exposing the limits of what the social media platforms are doing to counter the spread of potentially dangerous false claims about election results. In a video posted to YouTube by far-right news organization One America News Network on Wednesday, an anchor says, “President Trump won four more years in office last night.”  No credible outlet has yet called the election for either candidate. The video also baselessly claims that Democrats are “tossing Republican ballots, harvesting fake ballots, and delaying the results to create confusion.” The video had been viewed more than 340,000 times as of late Wednesday night on the East Coast.  While the video -- like others related to the election -- has a label on it saying results may not be final, YouTube said the video does not violate its rules and would not be removed. (YouTube has placed an information panel at the top of search results related to the election, as well as below any videos that talk about the election -- whether they contain misinformation or not).  “Our Community Guidelines prohibit content misleading viewers about voting, for example content aiming to mislead voters about the time, place, means or eligibility requirements for voting, or false claims that could materially discourage voting. The content of this video doesn't rise to that level,” said Ivy Choi, a YouTube spokesperson. However, YouTube said it has stopped running ads on the video — while admitting the video has false information. “We remove ads from videos that contain content that is demonstrably false about election results, like this video,” Choi said. The company said it did remove several livestreams on Election Day that violated its spam, deceptive practices and scams policies.  CNBC was the first to report on the video.  The informational panel says election “results may not be final,” It’s also taking similar measures to past elections, such as promoting content from authoritative news sources in search results.  The OAN anchor in the video shared the YouTube link to her personal Twitter account with the comment, \"Trump won. MSM hopes you don’t believe your eyes.\" Twitter said that according to its policy on Civic Integrity, the tweet isn't eligible for a label indicating it might contain a premature call of election results because the original account has fewer than 100,000 followers and the tweet has not hit levels of engagement that would otherwise make it eligible. However, it was retweeted by OAN's official account, which has 1.1 million followers.  A viral video that purports to show about 80 \"ballots,\" all for Donald Trump, being burned is fake, Virginia Beach city officials say. The video, which surfaced on Tuesday, features a man with a plastic bag full of papers that look like ballots, which he doused with a flammable liquid and set aflame. The person, whose face is never shown, claims the 80 false \"ballots\" are \"all for President Trump\" on the video. Though the location is not discussed on the video, the races on the papers are from Virginia Beach, Virginia. However, the ballots are not real. The city of Virginia Beach said the papers are clearly sample ballots, rather than official ballots, since they lack the \"bar code markings that are on all official ballots,\" according to a statement released on Tuesday afternoon. The statement showed an official ballot and compared it to a screenshot of the false video. Christine Lewis, Virginia Beach's deputy registrar, pointed out to CNN that her office was quick to highlight the deception in an effort to prevent the spread of misinformation. City communications director Julie Hill added that police and fire investigators are now looking into the matter. Despite being debunked on Tuesday, the video continued to be shared on social media. The video eventually made its way to right-wing media sites like the Gateway Pundit, which posted a version of the clip on Wednesday afternoon. Eric Trump shared the video around at 3:40pm on Wednesday. The version Eric Trump shared had about 1.2 million views alone. CNN found three other accounts that posted the same video that had more than 115,000 combined views. Eric Trump shared the video by retweeting an account that posted it. The account Eric Trump retweeted has now been suspended, which means the video can no longer be seen on Eric Trump's feed. The Gateway Pundit did not immediately respond to a request for a comment. Twitter flagged and labeled a tweet sent by President Donald Trump Wednesday evening that prematurely claimed victory in Georgia, North Carolina and Pennsylvania and added a “disputed” label to a follow-up tweet in which the President claimed, without evidence, “a large number of secretly dumped ballots” in Michigan. In a 16-hour period since the last polls in 2020 US Presidential election closed at 1 a.m., five out of nine tweets posted by the President have been flagged by Twitter. Many of the tweets received a contextual label after Trump sought to delegitimize the election process and made unverified claims of widespread voter fraud. In a response to CNN, a Trump campaign spokesman said, \"Silicon Valley continues its relentless censorship of the President of the United States.\" Twitter didn’t immediately respond to a request for comment.  \"WHAT IS THIS ALL ABOUT?\" President Trump asked in a tweet on Wednesday morning. He had shared an image of an electoral map of Michigan that purported to show an unexplained jump overnight in the number of returned ballots in the state. The charge: According to the data in the map, 138,000 ballots had come in out of nowhere, and all of them were for Biden. The claim had been going viral in parts of the right all morning. A headline on one right-wing website read, \"Voter Fraud in Michigan -- Massive Dump of Over 200,000 Ballots for Biden All the Sudden Appear Overnight.\" At least 14,000 tweets had included the image. The image was real. But the idea that it indicated fraud was absolutely false, though the people sharing it likely initially did not know that the data in the map was wrong. The image was a screenshot of a map on the website Decision Desk HQ, which tracks election results and has powered results data for media outlets like BuzzFeed News. After Trump's tweet on Wednesday, Decision Desk HQ said there had been an error in the data it had been sent from Michigan's Shiawassee County. \"Once we identified the error, we cleared the erroneous data and updated it with the correct data as provided by officials,\" Decision Desk HQ said in a statement to CNN. A clerk with the Shiawassee County Clerk's Office confirmed to CNN that that a typing error had been made when votes were being entered for Biden, and that the error was corrected within 30 minutes. Read more here Fake Twitter accounts impersonating the Associated Press sowed disinformation online Wednesday by attempting to call election results prematurely, prompting national security officials to issue warnings about the behavior.  Screenshots of one of the accounts showed impostors appearing to call Michigan for Joe Biden. As of this write, the AP has not called Michigan for either candidate. CNN has called Michigan for Joe Biden.  CNN was unable to independently view the impersonator accounts before Twitter removed them from the platform.  AP spokesperson Patrick Maks tells CNN, “These are bogus accounts not affiliated with AP.” The Department of Homeland Security’s Cybersecurity and Infrastructure Security Agency said it has witnessed multiple reports of social media accounts pretending to be legitimate news outlets calling election results, and that it had anticipated the tactic. “Don’t fall for it!” tweeted CISA director Chris Krebs, linking to an agency guide telling voters that “malicious actors can use fake personas and impersonate real accounts.” “Most media accounts on platforms will have a checkmark, so if they’re not verified, dig deeper!” Krebs said in a follow-up tweet. The tweets mark Krebs’ first public warning of a specific threat affecting the current election.  The accounts in question \"were in violation of our impersonation policy,” a Twitter spokesperson told CNN. \"They are permanently suspended.” Twitter said it has not witnessed any large-scale attempts to impersonate media outlets but that it will suspend any account that attempts to do so. Homeland Security officials responsible for election security have repeatedly said, as recently as mid-day Tuesday, that it’s not their responsibility to address any comments made by candidates about the election. Since that time President Donald Trump has made a false claim of victory and claims of fraud before the votes were counted.  Acting Homeland Security Secretary Chad Wolf said at a press briefing Tuesday the department would rely on state and local officials to make sure that their ballots are counted. “We're gonna let the campaigns do what they do, and the folks here at CISA [Cybersecurity and Infrastructure Security Agency] are going to stay focused on their mission,” Wolf said in response to CNN’s question. Asked Tuesday evening about the federal government’s plan for possible premature claims of victory by a candidate on social media, a senior CISA official referred back to the acting secretary. “I think Acting Secretary Wolf addressed this one pretty clearly and head-on this morning. You know, that's a campaign issue. We are focused on the cybersecurity aspects of the vote. And what's going on out there right now,” the official said.  CISA Director Chris Krebs was asked last week about the president’s attacks on the validity of some ballots as he showed reporters the CISA war room where they would coordinate with partners to safeguard the election. “It’s not my job to fact check any candidate, certainly on the presidential ticket,” Krebs told reporters, according to the Washington Post. CNN previously reported that when election disinformation comes from Trump, national security officials' hands are tied. None of the federal agencies charged with protecting the election -- the Federal Bureau of Investigation, the Department of Homeland Security and the Office of the Director of National Intelligence, among others -- have been empowered or seemed able to deal with one of the most serious election issues they grapple with daily when it's coming from the White House. Meanwhile, administration officials have called for patience as votes are counted. “Voters should be patient while waiting for the outcome of this year's elections. Rest assured, however, our partners at the state and local level, are working around the clock to make sure that each vote is counted properly,” Wolf said Tuesday morning.  Krebs has been leading the calls for patience for months. Krebs previously cautioned that results on election night are never official and that the volume of mail-in ballots due to the coronavirus pandemic will slow down the counting. \"Let's let the official process, the official results, play itself out,\" Krebs said last month.  Twitter labeled two more tweets from the President this morning as “disputed” and possibly “misleading.” The company has restricted how the tweets can be shared.  In the tweets, the President baselessly questions the integrity of the on-going ballot counts in several states.  Three Trump tweets have been flagged by Twitter since midnight eastern.  “As votes are still being counted across the country, our teams continue to take enforcement action on Tweets that prematurely declare victory or contain misleading information about the election broadly,” a Twitter spokesperson said Wednesday morning. “This is in line with our Civic Integrity Policy and our recent guidance on labeling election results,” they added. Continuing, “Last night, we took quick action to limit engagement on a number of Tweets that may have needed more context or violated the Twitter Rules. Our teams continue to monitor Tweets that attempt to spread misleading information about voting, accounts engaged in spammy behavior, and Tweets that make premature or inaccurate claims about election results. Our teams remain vigilant and will continue working to protect the integrity of the election conversation on Twitter.” Twitter and Facebook applied labels to posts from President Donald Trump overnight which included baseless claims undermining the integrity of the election. But the two companies have very different approaches, with Twitter taking far more punitive action against the President.  As Trump continues to post online in the hours and days ahead, it is possible the social media companies will take action on more of his posts.  Twitter labeled a tweet that Trump sent early Wednesday morning in which he baselessly claimed, \"We are up BIG, but they are trying to STEAL the Election.” Twitter is hiding the tweet behind the label and restricting how it can be shared, including removing the ability for people to directly retweet the post.  \"Some or all of the content shared in this Tweet is disputed and might be misleading about how to participate in an election or another civic process,” the Twitter label reads.  On the exact same post on its platform, Facebook uses vague language in its label -- and, unlike Twitter, it is not restricting how it can be viewed or shared.  In fact, on Wednesday morning it was one of the most popular posts on Facebook, according to data from Crowdtangle, an analytics company that Facebook itself owns.  The Facebook label says: “Final results may be different from initial vote counts, as ballot counting will continue for days or weeks.” Facebook also labeled another post from Donald Trump in which he said, \"I will be making a statement tonight. A big WIN!\"  “Votes are still being counted. The winner of the 2020 US Presidential Election has not been projected,” the label says. A Facebook spokesperson also pointed to a message the company is showing on the top of users’ feeds: “Once President Trump began making premature claims of victory, we started running top-of-feed notifications on Facebook and Instagram so that everyone knows votes are still being counted and the winner has not been projected,” the spokesperson said.  “The winner of the 2020 US Presidential Election has not been projected yet,” the message reads in part.  Of course, Trump and his supporters view any action that calls out or restricts his posts in this way as Big Tech censorship.  Twitter has placed a label on a tweet by President Trump in which he baselessly claimed \"We are up BIG, but they are trying to STEAL the Election.” \"Some or all of the content shared in this Tweet is disputed and might be misleading about how to participate in an election or another civic process,” the Twitter label reads.  Twitter has also restricted how the tweet can be shared. The same language was also posted to the President’s Facebook page. The social network placed a label on it that reads: \"Final results may be different from initial vote counts, as ballot counting will continue for days or weeks.\"  Unlike Twitter, however, Facebook did not place any restrictions on the sharing of Trump's post. In a statement, a Facebook spokesperson said: \"Once President Trump began making premature claims of victory, we started running top-of-feed notifications on Facebook and Instagram so that everyone knows votes are still being counted and the winner has not been projected. We also started applying labels to both candidates’ posts automatically with this information.\" Twitter and Facebook on Tuesday suspended accounts with tens of thousands of followers for violating their policies, as the platforms scramble to combat misinformation on election day. A Twitter spokesperson said the accounts were suspended for violating its rules on \"spam and platform manipulation.\" The accounts Twitter barred included SVNewsAlerts, which was created in May this year and had more than 78,000 followers as of Monday according to the WayBack Machine internet archive. Other suspended accounts included FJNewsReporter and Crisis_Intel, Twitter spokesperson Lauren Alexander confirmed to CNN Business.  Facebook also suspended accounts linked to the pages of SV News and FJ News for inauthentic behavior, company spokesperson Andy Stone confirmed.  Both companies declined to comment on exactly how many accounts they suspended. The moves were first reported by Reuters. Twitter is applying labels to tweets that, by its standards, are prematurely calling election results for either candidate.  “Official sources may not have called the race when this was Tweeted,” the label reads.  The social network previously explained its new rules in a blog post: \"To determine the results of an election in the US, we require either an announcement from state election officials, or a public projection from at least two authoritative, national news outlets that make independent election calls. Tweets which include premature claims will be labeled and direct people to our official US election page.\" With this type of label, Twitter is not indicating the tweet contains potential misinformation. Instead, it is meant to give people reading the tweet context and help them parse projections as the night goes on.  When people try to share the tweet, they are first prompted to \"find out more\" and are directed to Twitter's official election page. Labeled tweets can only be quote tweeted, not retweeted. Users can still reply or like a labeled tweet. (Quote tweets append a user's commentary to the original tweet.) Here's one of the first tweets that Twitter labeled (CNN would call Florida for President Trump hours later):  Marjorie Taylor Greene, a Republican businesswoman known for espousing conspiratorial and bigoted views, won her House race on Tuesday to represent northwest Georgia, CNN projects. Greene brings a history of prejudice and a proclivity for amplifying conspiracies. She said that George Soros, a Holocaust survivor, collaborated with Nazis. She called \"Q\" a \"patriot\" who is \"worth listening to.\" She said that the deadly White supremacist rally held in 2017 in Charlottesville was an \"inside job\" to \"further the agenda of the elites.\" QAnon believers have embraced a number of different and often contradictory theories, but the basic false beliefs underlying the far-right conspiracy theory are claims about a cabal of politicians and A-list celebrities engaging in child sex abuse, and a “deep state” effort to undermine President Trump. The FBI has warned such fringe views amount to a domestic terror threat. However, Greene has since distanced herself from QAnon. In August, she told Fox News that QAnon \"wasn't part of my campaign\" and that once she \"started finding misinformation,\" she \"chose another path.\" Want to know more about QAnon? Here's some of our previous coverage: 'It's like a parasite': How a dangerous virtual cult is going global\nHe went down the QAnon rabbit hole for almost two years. Here's how he got out\nAnalysis: A CNN reporter went to two different QAnon events. Here's what he found\nTwitter tries to catch the QAnon horse that bolted\nThree years later, Facebook says it will ban QAnon  --CNN's Alex Rogers contributed reporting Twitter has suspended the account of David Icke, a prominent UK conspiracy theorist who popularized the false idea that a shape-shifting lizard-like species exerts control over human society by garnering political power to manipulate the world.  A Twitter spokesperson confirmed Icke's account has been permanently suspended for violating the platform's rules about COVID misinformation. The spokesperson would not elaborate on what Tweet caused the suspension or how many followers he had.  Facebook removed Icke's page in May for publishing \"health misinformation that could cause physical harm,\" the BBC reported at the time.  Earlier this year, the Center for Countering Digital Hate (CCDH) called on social media platforms to take down Icke's various accounts. The campaign said he has denied the existence of Covid-19, falsely linked the virus to 5G networks and claimed that people with healthy immune systems are safe from contracting the virus.  \"He has been using them to spread racism, medical misinformation and conspiracy theories for years,\" CCDH wrote about Icke and his use of social platforms. \"In the face of this global pandemic that has already claimed hundreds of thousands of lives, it is more urgent than ever that accounts spreading harmful misinformation are prevented from doing so.\"  Twitter on Tuesday also suspended DeAnna Lorraine, a former GOP congressional candidate who has spread the QAnon conspiracy theory, for repeated violations of the platform’s rules.  While Twitter wouldn't provide more details, a person familiar with the matter cited a tweet by Lorraine Tuesday morning baselessly warning that an election loss by President Donald Trump would result in an influx of millions of violent people into the United States --CNN's Brian Fung contributed reporting  Pennsylvania, which could be critical in determining who wins the presidency, has emerged as an early focus of online misinformation on Election Day, with much of it coming from the right.  The most prominent topic being discussed concerns allegations, which are for the most part either unsubstantiated or just plain false, of perceived unfairness toward Republican poll-watchers, with the implication that something untoward may be going on that people don't want the poll-watchers to see. There have been no substantiated reports of mistreatment of poll-watchers. Pennsylvania's 20 Electoral College votes are hotly contested — \"this is the most important state this election cycle,\" CNN's Harry Enten wrote in an analysis of close contests Tuesday. The focus on it from Trump supporters may reflect some anxiety over that: Enten noted that \"Trump likely can't win without it.\" The fact that results in the state may not be known with any certainty Tuesday night has likely contributed to the intense focus on the state as well. Philadelphia, which is heavily Democratic, has been a particular focus of attention. The Philadelphia District Attorney's Office on Tuesday called out tweets from a Republican operative and from a Newsmax columnist as being \"deliberately deceptive.\" The tweets alleged a sign in support of Democratic nominee Joe Biden was a violation of election rules because of its proximity to a polling location. The false tweets had been shared more than 10,000 times on Twitter as of Tuesday afternoon. \"Members of our Election Task Force have investigated this allegation. This polling place is located in an interior room and the sign in question is further than 10 feet from it. This tweet is deliberately deceptive,\" the DA's office tweeted. Read more here Cutting through the noise of social media and figuring out what's true and false can be tough. These steps can make it easier.  Twitter labeled a tweet from President Trump “disputed” and restricted its sharing on the eve of the election after he criticized a Supreme Court decision to allow counting of ballots received up to three days after Election Day in Pennsylvania. In the tweet posted Monday evening, Trump baselessly claimed the court’s decision would \"allow rampant and unchecked cheating and will undermine our entire systems of laws.” Adding, \"It will also induce violence in the streets. Something must be done!” Twitter placed a label on the tweet and removed the ability for the post to be retweeted. The label reads, \"Some or all of the content shared in this Tweet is disputed and might be misleading about how to participate in an election or another civic process.” The same message from Trump was also posted to his Facebook page.  Facebook placed a label on the post but did not restrict how it could be shared. Facebook’s label also did not specifically call out the claims as being false. It reads “Both voting by mail and voting in person have a long history of trustworthiness in the US. Voter fraud is extremely rare across voting methods.”  Neither company labeled the tweet as inciting violence. Despite a crackdown by Twitter, there were more than 93,700 QAnon-related accounts still on the platform as of October 15, according to new data from non-partisan nonprofit Advance Democracy. In July, Twitter removed thousands of accounts linked to the QAnon conspiracy group and said it would \"permanently suspend accounts Tweeting about these topics\" and \"coordinating abuse around individual victims.\" Last month, Facebook said it would ban any pages, groups and Instagram accounts representing QAnon, and YouTube has also taken similar actions to limit its spread. QAnon believers have embraced a number of different and often contradictory theories, but the basic false beliefs underlying the far-right conspiracy theory are claims about a cabal of politicians and A-list celebrities engaging in child sex abuse, and a “deep state” effort to undermine President Trump. Even with efforts to combat QAnon content, accounts associated with the group are among the most active on Twitter in battleground states ahead of Election Day. \"QAnon continues to have a substantial influence on the stories and narratives promoted on social media -- and that’s especially true when it comes to conversations about this election. These accounts are promoting right-wing fringe conspiracy theories, election disinformation, and divisive content at alarming rates,\" said Daniel J. Jones, president of Advance Democracy, and a former FBI analyst and Senate investigator.  \"To date, through our work to deamplify content and accounts associated with QAnon we have reduced impressions on QAnon-related tweets by more than 50%, meaning our users are seeing less unhealthy content on their feeds as a direct result of this cross functional effort,\"  a Twitter spokesperson told CNN Business. \"As always, Tweets are subject to all of the Twitter Rules and we will continue to take the necessary additional enforcement actions when shared content violates our policies.\" Highlights: QAnon is inserting itself into the election conversation: About 4.1% of Texas-based posts about the 2020 election came from QAnon-related accounts (that's 718,900 posts); 3.5% of the Florida-based posts (541,400), and 3.7% of the North Carolina-based posts (194,600). Meanwhile, 2.3% of Pennsylvania-based posts (159,700) about the 2020 election came from QAnon-related accounts.\nHow the analysis worked: Posts were determined to be about the 2020 election if they included terms or hashtags such as: voting, election, mail-in, “#riggedelection,” “#votersuppression” and so on. Locations were defined as any tweet, retweet, quote tweet, or reply by an account whose location is set to that state, along with every post geotagged in the state or accounts with references to certain towns or cities in that state in their Twitter bios. The report analyzed Twitter activity from January 1 to October 15, and its analysis only included accounts that remained active on Twitter as of October 20.\nIn the report, Advance Democracy said its definition of “QAnon-related” accounts was “extremely conservative” because it includes only those Twitter accounts with an explicit reference to QAnon in their Twitter bio, such as hashtags like #QAnon or terms associated with the conspiracy movement including “the great awakening” or “where we go one we go all.” As a result, it believes the proportion of the conversation on Twitter connected to those who align themselves with QAnon is likely much higher than what its report found. \"The shift over time of election results as different types of ballots are fully counted is my biggest source of concern right now,\" one employee who works on countering misinformation for a major social media platform said on Saturday. \"If it isn't a landslide one way or the other, every race that leans one direction and goes another is a potential flashpoint for offline violence.\" The days -- and possibly weeks -- after Election Day will be a huge test for platforms like Facebook, Twitter, and Google's YouTube. Doctored videos that could potentially be spread by anyone; fake accounts that could pop up anywhere; and tweets from President Trump himself could all contribute to undermining the result of the election and perhaps even stoke offline violence. CNN Business spoke to more than a dozen people who are either employees at the major social media platforms working on the teams countering misinformation and extremism or people who work directly with those teams at the companies. CNN Business granted them anonymity so they could speak about their work more freely. \"My biggest fear at this point is something totally unexpected happening that no one predicted,\" one Big Tech employee said. \"This year we've all been preparing and working through scenarios for every possibility that we can think of, but this year has taught me not everything can be predicted.\" Read more here On Sunday, Richard Grenell, President Donald Trump's former ambassador to Germany and former acting director of national intelligence, tweeted two photos side by side: one of former Vice President Joe Biden standing on an airplane without a mask and one of Biden standing outdoors while wearing a mask. \"Washington, DC phony! @JoeBiden doesn't wear a mask on a plane - but wears one OUTSIDE!?\" wrote Grenell, a prominent Trump campaign ally and a paid Republican National Committee senior adviser. Grenell had more than 671,000 Twitter followers as of Monday. Grenell's tweet was retweeted more than 16,000 times. And prominent right-wing talk radio host Mark Levin, who had about 2.6 million followers as of Monday, generated an additional 12,800-plus retweets by sharing Grenell's tweet on Sunday and adding his own accusation that Biden is a \"fraud.\" Facts First: The tweets by Grenell and Levin are egregiously deceptive: they create the false impression that the photo of Biden without a mask on a plane was taken during the coronavirus pandemic. The photo was actually taken in November 2019, before the pandemic. Read more here A deceptively edited video of Joe Biden making it appear the Democratic presidential nominee forgot what state he was in was viewed more than one million times on Twitter over the weekend. In the video, Biden addresses a crowd — saying, \"Hello, Minnesota!\" The event did, indeed, take place in St Paul, Minnesota. In the unedited, original video, signs in front of and behind Biden on the stage read \"Text MN to 30330\" — making it clear the event was in Minnesota. However in the false video, the on-stage signs were edited to read \"Tampa, Florida,\" and \"Text FL to 30330.\" The video was shared on Twitter by a person who accused Biden of forgetting what state he was in. Read more here Facebook will expand its action against QAnon by restricting #SaveOurChildren, one of the hashtags supporters of the conspiracy theory often append to their social media posts. Starting Friday, the company will be \"limiting the distribution\" of the hashtag, spokesperson Emily Cain said in a statement to CNN Business, meaning that posts using the hashtag will have their visibility reduced in the News Feed and people clicking on the hashtag will not be able to see the aggregated results. Instead, they will see a link to a list of \"credible child safety resources,\" Cain added.  Save The Children is a respected humanitarian organization that has been around for more than 100 years, but QAnon followers have hijacked and bastardized the name \"Save The Children\" as a way to spread baseless conspiracy theories about prominent Democrats, including former Vice President Joe Biden.  Posts about the conspiracy theory often include the hashtags #SaveTheChildren or #SaveOurChildren. Facebook said it will only be limiting the distribution of the latter for now, and will continue to monitor different hashtags and other methods by which QAnon supporters might try to continue evading detection. Searching for #SaveTheChildren shows a prompt from Facebook asking if you're looking for the humanitarian organization with a link to its website. You also have the option of proceeding to the search results. Other similar hashtags show a link to a page with child safety resources in addition to the regular search results. Children need to be \"saved,\" Qanon followers believe, from a cabal of evil Democrats. It is essentially the same conspiracy theory that was pushed as part of \"Pizzagate\" in 2016 which falsely alleged a Washington DC pizza shop was at the center of a child sex trafficking ring. The \"Save The Children\" charity has nothing to do with the QAnon and has publicly sought to distance itself from the conspiracy theory and its followers. Other child protection organizations have said these conspiracy theories are creating dangerous distractions from the real issue of child exploitation. Facebook announced a ban on QAnon earlier this month, three years after the conspiracy theory first began. Twitter and YouTube have also imposed varying degrees of restrictions on QAnon content.  But the platforms have allowed QAnon content to grow and spread for years. There are now multiple Republicans running for Congress who have expressed support for QAnon. In August, President Donald Trump praised QAnon followers for supporting him. \"I don't know much about the movement other than I understand they like me very much, which I appreciate,\" Trump said in the White House briefing room. Last year an FBI office warned that Q adherents are a domestic terrorism threat. -- CNN Business' Donie O'Sullivan contributed to this report Staffers at Wikipedia's parent organization and the volunteer editors who maintain its millions of pages have a plan to ensure that election-related entries aren't improperly edited. Last week, the Wikipedia community placed “extended protections” on the 2020 United States presidential election page, which means only experienced volunteers with at least 500 edits and 30 days on the platform can make changes. Other pages related to the election and presidential candidates already have protections, like the articles for Hunter Biden, the son of Democratic presidential nominee Joe Biden, Jared Kushner, President Donald Trump’s son-in-law, and the pages for both the Trump and Biden campaigns.  Generally, anyone can go into an article and make a change, however, there are varying levels of protections for what Wikipedia calls contested pages, which range from political topics to more obscure subjects over which editors disagree. There are over 70 English-language articles about the 2020 election, according to the Wikimedia Foundation, Wikipedia's parent. It said more articles may be protected as Election Day nears. Editors will be monitoring a list of relevant articles on Election Day and beyond. If someone makes an edit to those pages, over 500 people will get an email alerting them that there could be something worth checking. Wired previously reported that editors have been actively discussing what measures they are considering for election night on a public page.  Since late August, some Wikimedia staff have been running through different scenarios of what could happen on its site during the election, such as how it would handle malicious content or a coordinated attack by multiple accounts making edits across several Wikipedia pages on Election Day. “We are under no illusions that we will prevent every bad edit from making it onto the site,\" said Wikimedia chief of staff Ryan Merkley, who leads its new internal US election task force. \"We think our responsibility is to make sure that we are as prepared to respond and that we can do it as swiftly as possible and ideally prevent its spread broadly.” Ahead of Election Day, Instagram has moved to temporarily restrict a popular way to browse posts. Instagram announced that it will temporarily hide the \"Recent\" tab from showing up on all hashtag pages — whether they're related to politics or not. The company said it hopes the move will help prevent the spread of misinformation and harmful content related to the election.  Hashtag pages will still work, they'll just only show \"Top Posts\" as determined by the platform's algorithms. This may include some recent posts. An Instagram spokesperson said the change was rolled out Thursday evening, and there is no specific timeline for when the action will end. Other social platforms have also implemented similar temporary changes ahead of Election Day. For example, Twitter is encouraging users to quote tweet rather than to retweet, hoping people will add context or a reaction before spreading information.  Twitter labeled a video from the Russian-state controlled broadcaster RT as election misinformation on Thursday. RT is registered with the US Justice Department as an agent of the Russian government. It is the first time Twitter has taken action against RT for US election misinformation in this way, Twitter confirmed to CNN. The four-minute video posted by RT was titled \"Questions mount amid voter fraud, rigging claims ahead of #USelection.\" Twitter deactivated the retweet featured on the video, to reduce how much it can be shared, and slapped a label over it that read, \"Some or all of the content shared in this Tweet is disputed and might be misleading about how to participate in an election or another civic process.” The Kremlin uses RT to spread English-language propaganda to American audiences, and was part of Russia’s election meddling in 2016, according to US intelligence agencies. A report released by the US intelligence community in 2017 said RT has historically \"portrayed the US electoral process as undemocratic” and amplifies false narratives claiming that \"US election results cannot be trusted.” The four-minute video that RT posted Thursday touches on many of these themes. It raises concerns about “fraud” and echoes many of the lies President Donald Trump has spread about mail-in voting. Their segment cites Fox News, which has championed many of Trump’s attacks against the electoral process. It highlights isolated incidents of ballot mishaps, many of which have already been deemed by local authorities to be accidents and errors — and not fraud. Earlier this year, an internal intelligence bulletin issued by the Department of Homeland Security said Russia was amplifying disinformation about mail-in voting as part of a broader effort \"to undermine public trust in the electoral process.\" Facebook has hired a network of fact-checkers across America. CNN talks to two who have received threats for simply doing their jobs during the 2020 election cycle. Ted Cruz yelled. His Democratic colleague Brian Schatz called the hearing in which he was speaking \"a sham.\" Committee chair Roger Wicker couldn't pronounce the last name of Google's CEO. Just another day on Capitol Hill for Big Tech. In a contentious hearing on Wednesday, the CEOs of Facebook (FB), Google (GOOG) and Twitter (TWTR) were questioned by Senators on the Commerce Committee over their content moderation policies. Some demanded more transparency while others sought explanations on a few specific cases in which content was removed or labeled by platforms. Though the hearing was meant to focus on a crucial law, known as Section 230, that protects the companies' ability to moderate content as they see fit, Senators strayed from the brief and confronted the executives on other topics, including antitrust and election interference. Schatz and other senators slammed the timing of hearing, which comes less than a week before the US election. \"This is bullying and it is for electoral purposes,\" Schatz said. \"Do not let the United States Senate bully you into carrying water for those who want to spread misinformation.\" Cruz angrily went after Twitter CEO Jack Dorsey, pressing him on the platform's decision to restrict content posted by the New York Post. He concluded by shouting at Dorsey: \"Mr. Dorsey, who the hell elected you and put you in charge of what the media are allowed to report and what the American people are allowed to hear, and why do you persist in behaving as a Democratic super PAC silencing views to the contrary of your political beliefs?\" CNN Business will cover the hearing live. You can read our updating coverage here.  TikTok said Wednesday it will reduce the distribution of claims of election victory before official results are confirmed by authoritative sources.  Eric Han, TikTok’s US head of safety, announced that premature claims of victory surrounding the 2020 election will be restricted if the Associated Press has not declared a result. Han also said the company is working with third-party fact-checkers who are “on expedited call during this sensitive time.\" \"Out of an abundance of caution, if claims can't be verified or fact-checking is inconclusive, we'll limit distribution of the content,” Han added in a blog post. \"We'll also add a banner pointing viewers to our election guide on content with unverifiable claims about voting, premature declarations of victory, or attempts to dissuade people from voting by exploiting COVID-19 as a voter suppression tactic.\" The policy is similar to ones previously announced by other social media companies like Facebook and Twitter. One of Facebook's top executives in India — where it has more users than anywhere else — has resigned months after being linked to allegations of political bias and hate speech against the platform.  Ankhi Das, Facebook's head of public policy in India, allowed a politician from the country's ruling party to remain on its platform even though his anti-Muslim posts flouted its rules against hate speech, current and former Facebook employees told the Wall Street Journal in August. Das reportedly opposed banning the politician (which Facebook ultimately did weeks later) because doing so would hurt Facebook's business in the country. \"Ankhi has decided to step down from her role in Facebook to pursue her interest in public service,\" Ajit Mohan, the company's vice president and managing director in India, said in a statement. \"We are grateful for her service and wish her the very best for the future.\" Facebook has long faced controversies over harmful misinformation and hate speech in India, whose 600 million-plus internet users are increasingly important to its business as it's locked out of China and looks for future growth.  The Indian government has repeatedly called on Facebook to do more to curb misinformation, particularly on its mobile messaging platform WhatsApp, after viral hoaxes in 2018 were linked to more than a dozen lynchings. WhatsApp misinformation may be finding its way into the upcoming US presidential election, with Reuters reporting that misleading messages about Democratic candidate Joe Biden have been making the rounds on the private messaging service — particularly within the Indian-American community.  WhatsApp counts India as its largest market, with around 400 million users.  A misleading video clip of Democratic presidential candidate Joe Biden has been spreading on social media without any warning labels since Saturday after having been promoted by members of President Donald Trump's inner circle.  In the 24-second clip from an interview with the podcast Pod Save America, which is hosted by four former members of the Obama administration, Biden is heard saying, in part, that \"we have put together, I think, the most extensive and inclusive voter fraud organization in the history of American politics.\" The clip was first posted by RNC Research, a Twitter account operated by the Republican National Committee. It's clear in context that Biden is talking about an effort to combat voter suppression and provide resources for those seeking to vote, not an organized effort to perpetrate voter fraud.  The clip is part of a longer response by the former Vice President to a two-part question from host Dan Pfeiffer about Biden's message to people who haven't voted and those who already have. In his response, Biden encouraged people to \"make a plan exactly how you're going to vote, where you're going to vote, when you're going to vote. Because it can get complicated, because the Republicans are doing everything they can to make it harder for people to vote, particularly people of color, to vote...\" He continued a few sentences later: \"We have put together, I think, the most extensive and inclusive voter fraud organization in the history of American politics. What the President is trying to do is discourage people from voting by implying that their vote won't be counted, it can't be counted, we're going to challenge it...\" Biden goes to explain that his campaign has arranged for legal assistance for people who feel their right to vote has ben challenged. On Saturday evening, White House Press Secretary Kayleigh McEnany posted the shortened clip from her personal Twitter account saying: \"BIDEN ADMITS TO VOTER FRAUD!\" Fact-checking website Snopes debunked the claim as false.  McEnany's post has been retweeted more than 32,000 times. The clip has been viewed 7.9 million times on Twitter. Eric Trump also posted the video on both Twitter and Facebook without any false commentary. President Trump's verified YouTube account also posted the clip, with the title: “Joe Biden brags about having 'the most extensive and inclusive VOTER FRAUD organization' in history.” It's been viewed nearly 500,000 times. A Twitter spokesperson said it will not label the tweets by McEnany or Eric Trump. The social network did not provide further detail.  Facebook did not immediately respond to requests for comment, but the platform has not added any information labels or fact-checking resources to the clip.  According to Twitter's rules, users may not \"deceptively share synthetic or manipulated media that are likely to cause harm.\" However, it's unclear if a clip taken out of context, but not technologically manipulated, would fall into this category. Facebook's manipulated media policy states users should not post video that has been \"edited or synthesized ... in ways that are not apparent to an average person, and would likely mislead an average person to believe that a subject of the video said words that they did not say.\" A YouTube spokesperson said the video does not violate its rules.  “While the video shared with us by CNN does not violate our Community Guidelines, we have robust policies prohibiting deceptive practices such as technically manipulating content in a way that misleads users (beyond clips taken out of context) and may pose egregious harm.\" said Ivy Choi, a YouTube spokesperson. The Trump campaign did not respond to a request for comment. Biden's national press secretary TJ Ducklo said: \"The President of the United States has already demonstrated he’s willing to lie and manipulate our country’s democratic process to help himself politically, which is why we have assembled the most robust and sophisticated team in presidential campaign history to confront voter suppression and fight voter fraud however it may present itself.\" When asked if the RNC stood by the clipped video, and if it’s the official position of the RNC that Biden was endorsing and explicitly encouraging voter fraud, RNC Rapid Response Director Steve Guest said: “You should ask Joe Biden if he stands by the words he uttered, not us for sharing them. It's not the RNC's responsibility to clarify for the Biden campaign their candidate’s repeated blunders.\" Facebook announced its latest crackdown on foreign actors trying to interfere in the US election.  On Tuesday, Facebook said it took down three different networks, two of which targeted the United States. The other originated in and targeted Myanmar.  Facebook said it identified and removed these networks before they were able to build up a substantial audience. The people within each network worked with each other and used fake accounts to mislead people about who they were, according to a blog post announcing the takedowns from Nathaniel Gleicher, Facebook's head of security policy.  The company announced it took action against three distinct networks. The first network consisted of two Facebook pages and 22 Instagram accounts and was taken down for violating Facebook's policy against foreign interference, which covers accounts from outside a particular country trying to influence behavior in that country. These accounts and pages were run by individuals from Mexico and Venezuela and targeted the United States. They posted in Spanish and English about US news and current events, including \"memes and other content about humor, race relations and racial injustice, feminism and gender relations, environmental issues and religion,\" Gleicher said.  Facebook also removed 12 Facebook accounts, 6 pages and 11 Instagram accounts for government interference, with the company saying it found links to individuals associated with the Iranian government. That network started in Iran and primarily targeted the United States and Israel.  Facebook said the accounts focused on Saudi Arabia's activities in the Middle East and also spread claims about an alleged massacre. A third network, comprising 9 Facebook accounts, 8 pages, two groups and two Instagram accounts, originated in Myanmar and targeted local audiences there. Its posts, mainly in Burmese, included criticism of Myanmar's armed forces, Facebook said. The removals are part of Facebook's effort to crack down on \"coordinated inauthentic behavior\" and widespread misinformation, particularly leading up to the US presidential election.  Last month, the company said it had identified and shut down a network of fake accounts that included fictitious personas it said were tied to Russian military intelligence.  While those accounts had not been primarily targeting the United States, Facebook pointed to concerns that similar accounts could be used in Russian influence operations as the November 3 election draws closer. \"In recent weeks, government agencies, technology platforms and security experts have alerted the public to expect attempts to spread false information about the integrity of the election,\" Gleicher said in his blog post on Tuesday. \"We’re closely monitoring for potential scenarios where malicious actors around the world may use fictitious claims, including about compromised election infrastructure or inaccurate election outcomes, to suppress voter turnout or erode trust in the poll results.\" With one week to go before Election Day, YouTube announced more changes in hopes of preventing misinformation about election results. In a blog post on Tuesday, YouTube said that starting on Election Day, it would place an information panel at the top of search results related to the election, as well as below videos that talk about the election. The box will say that election results may not be final, and it will direct users to Google's feature that tracks election results in real time.  Some of the other efforts YouTube outlined are repeats from previous years. For example, YouTube parent company Google will be working with the Associated Press to display authoritative election results. YouTube also said it would continue promoting what it considers to be authoritative news sources, including CNN and Fox News, when users search for election news.  Google previously announced it would temporarily stop running election ads after Election Day.  With Election Day fast approaching, Twitter is trying to get ahead of election-related misinformation by showing a series of prompts to all users in the US starting Monday.  The prompts address topics that are likely to be the subject of election misinformation. The first prompt says that voting by mail is safe and secure, while the second tells people that there could be a delay in election results this year.  Twitter said both prompts will link to Twitter Moments that give more context and offer the latest authoritative information on the topic from experts, journalists and other reliable news sources.  More than 60 million Americans have already cast their ballots ahead of Election Day, both by voting early in person and by mail.  President Donald Trump has repeatedly cast doubt on the security and reliability of mail-in voting, but experts say there is no evidence of widespread fraud in US elections. Some of Trump's social media posts have received warning labels from Twitter and Facebook, such as one post urging North Carolina residents to show up to polling places even if they have already submitted a mail-in ballot, a practice state election officials have explicitly advised against. The move is part of a broader push by Twitter to tackle misinformation, including placing warnings or labels on tweets and encouraging users to quote tweet rather than retweet.  President Donald Trump is trying to invent his own reality about coronavirus. On Saturday at a North Carolina rally, he claimed the media would no longer report on the pandemic after Election Day. He implied that news organizations are trying to drum up fear about the pandemic to get former Vice President Joe Biden elected. But facts are facts: Cases are rising sharply and the American public is increasingly at odds with the president's views on the coronavirus. More then three-quarters -- 78% -- of Americans remain concerned about getting infected with Covid-19, according to an ABC News/Ipsos Poll released Sunday. And 61% of Americans say they disapprove of Trump's response to Covid-19, according to the same poll. That's why Trump's denial of the importance of coronavirus and attempts to change the subject aren't working, according to CNN's chief media correspondent Brian Stelter. Read more here You might see people sharing the hashtag #SavetheChildren on social media. But much of this online activity has nothing to do with the respected and real Save the Children charity. Its name has been hijacked by followers of the QAnon conspiracy theory. Facebook's court-like Oversight Board for appealing content decisions will now begin receiving cases, officials said Thursday, marking the launch of what CEO Mark Zuckerberg promised two years ago would be an independent accountability mechanism for the world's largest social media platform. Under the rollout, users of Facebook (FB) and Instagram will be able to challenge Facebook's decisions to remove content that they have posted once they have exhausted the company's internal review process. The ability to escalate cases to the board will be rolled out to users gradually. \"We recognize there are many who want the board to start hearing cases as soon as possible,\" said Thomas Hughes, director of the Oversight Board. \"We have all shared that ambition ... our first principle has always been to ensure we take the correct steps to get this right.\" The announcement comes days before a US election in which tech companies' handling of misinformation, hate speech and other content has been deeply scrutinized. While the Oversight Board may receive cases related to election content, it will be up to board members to decide whether to act on them — not Facebook. Read more here Twitter has officially rolled out its changes to the Retweet button 13 days from the US election. The move, CNN Business' Kaya Yurieff reported earlier this month, is part of an attempt to clamp down on the spread of misinformation on the platform. Now, according to a Tweet from Twitter, when a user hits the Retweet button on a Tweet, they have the choice to either add context with a comment -- a Quote Tweet -- or leave the comment space blank and hit Retweet without one. Twitter hopes this move will encourage people to add their own thought or reaction before spreading a Tweet. \"Though this adds some extra friction for those who simply want to Retweet, we hope it will encourage everyone to not only consider why they are amplifying a Tweet, but also increase the likelihood that people add their own thoughts, reactions and perspectives to the conversation,\" Twitter said in the blog post announcing the changes on Oct 9. Here's what it looks like: I spent my last two Saturdays going to two very different QAnon events. One, in Los Angeles, was a march through Hollywood that portrayed itself as an anti-pedophilia protest. Its organizers were careful not to explicitly embrace the QAnon conspiracy theory even as they implicitly signaled they support it and repeated its disinformation — much like what President Donald Trump did during an NBC town hall last week. The other event, \"Q Con Live,\" took place in a conference room at a resort in Scottsdale, Arizona. It was a meeting of some of QAnon's most passionate peddlers — but it could have easily been mistaken for a grassroots meeting to help re-elect the President. What both showed is that for many of its supporters QAnon is not just a set of conspiracy theories. For them, it's a way to distract themselves from the failures of a President they see as the hero of a fight against an all-encompassing villainy, to elevate themselves by casting his critics and political opponents as those villains, and to not have to pay attention to all of the US' very real problems, like Covid-19 and systemic racism. A march in Hollywood \"Pedophiles, you are on notice! - Q\" one person's sign at the event in Hollywood said. Along with other material, including a QAnon symbol, the sign featured a picture of Trump heroically pointing, with the words \"And I mean you Hollywood\" added underneath. And then there was a hashtag: #SaveTheChildren. Read more here What makes people want to believe in QAnon? How can they ever leave the virtual cult?  Those are questions we’ve asked ourselves a lot as the conspiracy theory keeps gaining in popularity around the globe. We spoke to Jitarth Jadeja, a 32-year old from Australia, who believed in the conspiracy theory for two years. He told us what made QAnon so attractive for him, and how it disconnected him from the reality.  But what may be the most important insight is what he had to say about how to get believers to leave QAnon. \"It has to start with empathy and understanding, and allowing them to keep their dignity. Because otherwise, what's their incentive?\" Read more here. YouTube said on Wednesday that it will prohibit content that claims an individual or group is involved in conspiracy theories like QAnon and Pizzagate that have been used to justify violence in the real world. Rather than flat-out prohibit content that discusses a conspiracy theory like QAnon, YouTube will prohibit content that threatens or harasses someone by suggesting they are part of harmful conspiracies, YouTube said in a blog post. QAnon believers have embraced a number of different and often contradictory theories, but the basic false beliefs underlying the far-right conspiracy theory are claims about a cabal of politicians and A-list celebrities engaging in child sex abuse, and a \"deep state\" effort to undermine President Trump.  Vague discussion of QAnon ideas is not covered by the new policy, such as falsely saying there is a cabal of Washington insiders and celebrities involved in sex trafficking. Still, YouTube said it would look for a variety of signals in such videos. For example, if someone is named or an image of a person is shown anywhere in the video, YouTube would take it down under its new policy.  YouTube said it believes Wednesday's update will have a significant impact on the remaining QAnon content on the platform. In the past YouTube has struggled to enforce its policies effectively and even when it has banned content, it continues to appear on the platform.  The update is YouTube's latest effort to curb the most egregious content coming from QAnon followers, while stopping short of a ban on QAnon. In fact, it remains resistant to any such blanket ban, even as Facebook has banned QAnon pages, groups and Instagram accounts representing QAnon, while TikTok has banned QAnon accounts and removed QAnon content. In a recent interview with CNN's Poppy Harlow, YouTube CEO Susan Wojcicki wouldn't say whether the platform would ban QAnon. \"We're looking very closely at QAnon,\" Wojcicki said. \"We already implemented a large number of different policies that have helped to maintain that in a responsible way.\" Wojcicki pointed to changes made to YouTube's recommendation system, which she said have reduced viewership of QAnon content by more than 80%. YouTube also said it's taken down tens of thousands of QAnon videos and removed hundreds of QAnon-related channels.  Watch the interview here: Twitter has recently suspended a slew of fake accounts pretending to be Black supporters of President Donald Trump. Many have tweeted this identical phrase: \"YES IM BLACK AND IM VOTING FOR TRUMP.\" A Twitter spokesperson told CNN the accounts violated rules against platform manipulation and spam, which ban users from tweeting to \"artificially amplify or suppress information,\" among other activities. It's unclear how many fake accounts were taken down. Twitter did not immediately respond to questions about the number of accounts.  Read more here.  As both presidential campaigns step up efforts to court Latino voters, misinformation campaigns are also taking aim at Latinos, especially in Florida, where they make up 20 percent of the electorate, according to Pew Research. The rampant misinformation has led to tensions and strife for some in Florida’s Latino community, as many struggle to make sense of it all weeks before the U.S. presidential elections.  According to an expert from Equis Labs, networks on social media are coordinating attacks targeting candidates on the left and social movements, like Black Lives Matter. False claims have been shared thousands of times, the expert told CNN. Conspiracy theories have not only ended up on Spanish-language radio and popular messaging apps among Latinos, but some are also being echoed by the Trump campaign. See more: These days, it’s not so easy to tell what’s true and what’s false on the internet.  From trolls to Russian bots, there are a lot of tools being used to destabilize US elections, and they are counting on regular Americans to click and share their false information.  In Wednesday's episode of the CNN Election 101 podcast, Kristen Holmes and former CIA analyst Cindy Otis help you figure out how to spot disinformation, and stop it from spreading. You can now listen here. YouTube on Wednesday said it would take down videos that include misinformation about Covid-19 vaccines. The policy will apply to any claims that go against expert consensus from local health officials or the World Health Organization. For example, YouTube said it would remove claims that a vaccine would kill people or cause infertility, or that microchips would be implanted in people who get the vaccine.  The company noted it's already taken action on other types of coronavirus-related misinformation, such as content that disputes the existence of the virus. The company said it's removed over 200,000 videos containing dangerous or misleading information about Covid-19 since February.  YouTube's announcement comes a day after Facebook said it would no longer allow ads that discourage people from getting vaccinated.  Facebook announced Tuesday that it will no longer allow ads that discourage people from getting vaccinated.  Prominent proponents of anti-vaccine misinformation have for years been using Facebook and Instagram to spread their message, which can have dangerous and even deadly consequences.  \"Today, we’re launching a new global policy that prohibits ads discouraging people from getting vaccinated. We don’t want these ads on our platforms,\" Kang-Xing Jin, Facebook’s head of health, and Rob Leathern, a Facebook director of product management, wrote in a post on Tuesday.  \"Ads that advocate for or against legislation or government policies around vaccines – including a Covid-19 vaccine – are still allowed,\" they wrote.  The company said it will be rolling out the ad ban in the coming days.  Jesselyn Cook, a reporter at HuffPost, highlighted after Facebook’s announcement the type of paid anti-vaccine ads running on Facebook as of Tuesday. Facebook is expanding its hate speech policy to include content that \"denies or distorts the Holocaust,\" a major shift for the platform, which has repeatedly come under fire for its inaction on hateful and false information. In announcing the policy change, Monika Bickert, Facebook's vice president of content policy, wrote in a blog post that the decision was \"supported by the well-documented rise in anti-Semitism and the alarming level of ignorance about the Holocaust.\" She cited a recent survey that found almost a quarter of adults in the US between the ages of 18 and 39 believed the Holocaust was a myth. Facebook (FB) will now direct users to credible information if they search for content related to Holocaust denial on its platform. CEO Mark Zuckerberg has previously said that while he finds Holocaust denial \"deeply offensive,\" he had maintained that Facebook should not police content. \"At the end of the day, I don't believe that our platform should take that down because I think there are things that different people get wrong,\" Zuckerberg said in a 2018 interview with Recode's Kara Swisher. \"I don't think that they're intentionally getting it wrong.\" In a Facebook post following Monday's announcement, Zuckerberg noted that his thinking has evolved after seeing data showing an increase in anti-Semitic violence. \"I've struggled with the tension between standing for free expression and the harm caused by minimizing or denying the horror of the Holocaust,\" he wrote, \"...but with the current state of the world, I believe this is the right balance.\" Facebook has had a patchy record when it comes to monitoring dangerous or erroneous information. While it has removed some posts from President Trump that violated its policies, the platform has so far taken no action on a post by Trump that claimed, without evidence, that he is immune to coronavirus. Read more here Facebook said Thursday it had banned a company it believes ran fake accounts for the conservative group Turning Point USA. Facebook said the marketing firm Rally Forge, working on behalf of Turning Point USA, ran a campaign that relied upon fake accounts that posted criticism of former Vice President Joe Biden and praise for President Donald Trump. According to Facebook, that campaign included tactics like commenting on the Facebook pages of major national American media outlets. The alleged activity was first identified through an investigation by The Washington Post, which prompted Facebook to look into the group. \"Many of these accounts used stock profile photos and posed as right-leaning individuals from across the US. In 2018, some of these accounts posed as left-leaning individuals to comment on content as well. This activity was centered primarily around commenting on news articles posted by news organizations and public figures, rather than posting their own content,\" Facebook said in a report published Thursday. Facebook added in the report, \"The most recent activity included creating what we call 'thinly veiled personas' whose names were slight variations of the names of the people behind them and whose sole activity on our platform was associated with this deceptive campaign.\" Read more here Twitter is rolling out a series of changes ahead of the US election next month in an attempt to clamp down on the spread of misinformation. On Friday, Twitter said that users, including political candidates, cannot claim an election win before it is authoritatively called. Twitter's new criteria for that requires either an announcement from state election officials or a public projection from at least two authoritative, national news outlets. Twitter did not identify the outlets, though news organizations like CNN, the Associated Press, ABC News, and Fox News would fit the bill. Previously, Twitter said candidates would be prohibited from claiming victory \"before election results have been certified.\" This caveat immediately drew the attention of election experts, because Twitter was drawing a red line that was noticeably out of step with how results are processed. The results publicly reported by election officials and news outlets on election night are always preliminary. Weeks later, the results are formally \"certified\" by state officials. With Friday's adjustment, Twitter is smoothing out its policies for Election Night, and eliminating a potentially major hiccup. Such tweets claiming a premature win will receive a misleading information label and users will be directed to Twitter's official US election page for more details. Warnings that block interactions Twitter is also now adding more warnings and restrictions to tweets with labels, for example, people will have to tap through a warning to see such tweets, and they will only be able to \"quote tweet.\" Likes, regular retweets and replies will not be available, and those tweets won't be recommended by Twitter. Quote tweets append a tweet to a user's commentary about it. Twitter had previously added these warnings to tweets in a few situations, but it is now expanding their use. This will apply to tweets from US political figures, including candidates and campaign accounts, US-based accounts with more than 100,000 followers, or any tweets that rack up significant engagement. \"We expect this will further reduce the visibility of misleading information, and will encourage people to reconsider if they want to amplify these Tweets,\" Twitter wrote in a blog post on Friday. Starting next week, when users try to retweet anything with a misleading information label, they'll see a prompt directing them to authoritative information about the topic before they are able to go through with a retweet. Misleading content shared by Trump and his team is often defended as humor. But his supporters aren't always in on the joke. Prior to the first Presidential debate, a baseless conspiracy theory inundated many Americans. The Trump campaign, Fox News, and a slew of Trump-supporting Facebook pages all fueled speculation that Democratic presidential candidate Joe Biden might wear a secret earpiece to assist him in his debate against President Trump. \"I thought Biden had somebody in his ear,\" said one Trump supporter the morning after the first presidential debate. Her belief was shored up, she said, by video she had viewed of Biden supposedly adjusting a wire during the debate. She was on her way to a Trump rally in Duluth, Minnesota and was referring to a YouTube video she was sent by a friend who is serving with the military overseas. In fact, the video does not show Biden wearing a wire; it shows a crease briefly forming on Biden's shirt after he reached into his coat to itch his shoulder. But when false evidence emerged to support the baseless earpiece claim, it took off like wildfire. One version of the video that was flagged by fact-checkers as false on Facebook had been shared more than 22,000 times and viewed 800,000 times by Thursday night. Read more here With less than four weeks to go before a pivotal US election, Facebook has sought to reassure the public it has learned from its 2016 mistakes. On Wednesday, the company rolled out a new policy against voter intimidation and announced it will temporarily suspend political ads after polls close on Election Day. But a new report from activist researchers shows that in the past year alone, Facebook has failed to act on hundreds of posts that racked up millions of impressions and contain claims that the social media giant has previously identified as false or misleading — raising fresh questions about the company's readiness for a potential wave of misinformation following Nov. 3. The report outlines how purveyors of misinformation have successfully evaded Facebook's content review systems — both human and automated — by taking simple steps such as reposting claims against different-colored backgrounds, changing fonts and re-cropping images. The resulting posts appear to be just different enough to have escaped enforcement. The posts include false claims about President Donald Trump and Vice President Joe Biden as well as false information about mail-in voting and the coronavirus. The tactics mean that even as Facebook (FB) demotes and applies warning labels to certain posts that have been rated as false by third-party fact-checkers, variations on those same posts continue to replicate virally across the platform unhindered, said Avaaz, the activist group that produced the research. Read more here President Trump's bout with coronavirus, and his continued and frequently dishonest downplaying of it, isn't just a problem for his re-election campaign. It's also putting Big Tech in an uncomfortable position, on a collision course with the President over what they've portrayed as strict rules regarding misinformation about the virus. For the past few months, both Facebook and Twitter have been applying labels to some of Trump's posts when they contain election misinformation. Beyond fitting with the philosophical positions the companies have taken about being in favor of nearly unfettered free speech and not wanting to be the arbiters of truth, their strategy of applying labels rather than removing posts is a politically prudent one — the companies can claim they are doing something without being accused of silencing the President. But — in trying to tackle false claims about the virus — the companies have made the problem of Covid-19 disinformation coming from the President more complicated for themselves. Both companies say they may entirely remove any posts about the virus that could result in harm. In August, both Facebook and Twitter removed videos posted by Trump and his campaign of an interview Trump gave to Fox News in which he falsely claimed that children are \"almost immune\" to the virus. Read more here A television ad attacking Facebook CEO Mark Zuckerberg for his company's handling of hate and misinformation will air during Wednesday's vice presidential debate coverage, the group behind the ad — Accountable Tech — tells CNN Business. The ad includes footage of Zuckerberg telling Congress that Facebook has a responsibility to be a positive force in the world and that as founder he has ultimate responsibility for it. It then shows media headlines about Facebook's (FB) recent high-profile failures, including its failure to remove the page of a militia in Kenosha, Wisconsin, and its struggle to get a handle on Qanon, a conspiracy theory that the FBI has labeled as a potential domestic terrorist threat. \"Our democracy is on the line. Hold Facebook and Mark Zuckerberg accountable,\" a message at the end of the ad reads. \"This VP debate will draw the nation's attention to the precarious state of our democracy, from the erosion of truth to the extreme tribalism. Mark Zuckerberg and Facebook have turbocharged all of that, and they need to be held accountable,\" Nicole Gill, the executive director and a co-founder of Accountable Tech, told CNN Business. Jesse Lehrich, the group's other co-founder, said that it had purchased a six-figure ad buy across cable, streaming services, and digital. The ad buy includes spots during CNN's debate coverage on cable and during Fox News' morning show \"Fox & Friends\" on streaming services, he said. Accountable Tech has not disclosed its funders and did not do so when CNN Business asked. As a 501(c)(4) group it is not obliged to make that information public. Facebook has found itself at the center this year's elections campaign, being attacked by both Republicans and Democrats. Jen O'Malley Dillion, Democratic presidential candidate Joe Biden's campaign manager, wrote in a letter to Zuckerberg last week that his company's refusal to remove voter misinformation shared by President Donald Trump amounted to the company becoming the \"nation's foremost propagator of disinformation about the voting process.\" On Tuesday, soon after Facebook removed a post from Trump that claimed falsely that the flu is more lethal than Covid-19, Trump posted on Facebook and Twitter, \"REPEAL SECTION 230!!!\" Section 230 is shorthand for the part of US law that gives tech companies immunity for almost all of their decisions regarding content moderation. Facebook said Tuesday it will ban any pages, groups, and Instagram accounts representing the conspiracy theory QAnon from its platform. The move comes three years after the far-right conspiracy theory began. During those years QAnon adherents have embraced a number of different and often contradictory theories, but the basic false beliefs underlying QAnon are claims about a cabal of politicians and A-list celebrities engaging in child sex abuse, and a \"deep state\" effort to undermine President Trump. Last year an FBI office warned that Q adherents are a domestic terrorism threat. Facebook's move will be welcomed by some, but the platform has allowed the conspiracy to grow and spread for years. There are now multiple Republicans running for Congress who have expressed support for QAnon. Read more here", "Section": "tech", "Writers": ["Donie O'Sullivan", "Kaya Yurieff"], "URL": "https://www.cnn.com/tech/live-news/social-media-misinformation-october/index.html", "MainKeyWord": "Hong Kong", "AdditionalKeyWord": "Thailand", "Source": "CNN"}